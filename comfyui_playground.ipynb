{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Control Board {display-mode: \"form\"}\n",
    "\"\"\"Interactive launchpad with tabs for the main notebook workflows.\"\"\"\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from src.config import PlaygroundConfig\n",
    "from src.download import DownloadManager\n",
    "from src.env import get_env_summary\n",
    "from src.notebook_ui import control_board, toast\n",
    "from src.queue import is_paused, list_items, purge_completed, retry_item, set_paused\n",
    "\n",
    "cfg = PlaygroundConfig.load()\n",
    "cfg.ensure_directories()\n",
    "\n",
    "# Environment tab content\n",
    "env_summary = get_env_summary(cfg)\n",
    "\n",
    "# Downloads tab widgets\n",
    "manifest_dropdown = widgets.Dropdown(description=\"Manifest\")\n",
    "reload_manifests = widgets.Button(description=\"Reload\", button_style=\"info\")\n",
    "queue_button = widgets.Button(description=\"Queue downloads\", button_style=\"success\")\n",
    "manifest_output = widgets.Output(layout=widgets.Layout(max_height=\"220px\", overflow_y=\"auto\"))\n",
    "progress_label = widgets.HTML()\n",
    "\n",
    "def _manifest_options():\n",
    "    files = sorted(cfg.manifests_dir.glob(\"*.json\"))\n",
    "    if not files:\n",
    "        return [(\"No manifests\", \"\")]\n",
    "    return [(f.name, str(f)) for f in files]\n",
    "\n",
    "def _refresh_manifests(_=None):\n",
    "    manifest_output.clear_output()\n",
    "    progress_label.value = \"\"\n",
    "    options = _manifest_options()\n",
    "    manifest_dropdown.options = options\n",
    "    manifest_dropdown.value = options[0][1] if options and options[0][1] else \"\"\n",
    "\n",
    "reload_manifests.on_click(_refresh_manifests)\n",
    "_refresh_manifests()\n",
    "\n",
    "def _preview_manifest(change):\n",
    "    path = change[\"new\"]\n",
    "    manifest_output.clear_output()\n",
    "    if not path:\n",
    "        with manifest_output:\n",
    "            display(widgets.HTML(\"<b>No manifest selected.</b>\"))\n",
    "        return\n",
    "    data = json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
    "    rows = data.get(\"items\", [])\n",
    "    with manifest_output:\n",
    "        if not rows:\n",
    "            display(widgets.HTML(\"<b>Manifest is empty.</b>\"))\n",
    "        else:\n",
    "            df = pd.DataFrame(rows)\n",
    "            display(df.head(10))\n",
    "            display(widgets.HTML(f\"<small>Total items: {len(rows)}</small>\"))\n",
    "\n",
    "manifest_dropdown.observe(_preview_manifest, names=\"value\")\n",
    "\n",
    "def _queue_downloads(_):\n",
    "    path = manifest_dropdown.value\n",
    "    if not path:\n",
    "        toast(\"Select a manifest first\", level=\"warning\")\n",
    "        return\n",
    "    data = json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
    "    items = data.get(\"items\", [])\n",
    "    if not items:\n",
    "        toast(\"Manifest has no items\", level=\"warning\")\n",
    "        return\n",
    "    manager = DownloadManager()\n",
    "    def _progress(state):\n",
    "        downloaded = state.get(\"downloaded_bytes\", 0)\n",
    "        total = state.get(\"total_bytes\", -1)\n",
    "        if total and total > 0:\n",
    "            pct = downloaded / total * 100\n",
    "            progress_label.value = f\"{pct:.1f}% ({downloaded} / {total} bytes)\"\n",
    "        else:\n",
    "            progress_label.value = f\"{downloaded} bytes downloaded\"\n",
    "    manager.progress_callback = _progress\n",
    "    for item in items:\n",
    "        manager.add_item(item)\n",
    "    manager.run()\n",
    "    toast(f\"Downloaded {len(items)} manifest items\", level=\"success\")\n",
    "    progress_label.value += \" — done\"\n",
    "\n",
    "queue_button.on_click(_queue_downloads)\n",
    "\n",
    "downloads_panel = widgets.VBox([\n",
    "    manifest_dropdown,\n",
    "    widgets.HBox([reload_manifests, queue_button]),\n",
    "    manifest_output,\n",
    "    progress_label,\n",
    "])\n",
    "\n",
    "# Flow Studio tab widgets\n",
    "queue_stats = widgets.HTML()\n",
    "queue_output = widgets.Output(layout=widgets.Layout(max_height=\"220px\", overflow_y=\"auto\"))\n",
    "refresh_queue = widgets.Button(description=\"Refresh queue\", button_style=\"info\")\n",
    "retry_failed = widgets.Button(description=\"Retry failed\", button_style=\"warning\")\n",
    "purge_done = widgets.Button(description=\"Purge done\", button_style=\"danger\")\n",
    "pause_toggle = widgets.ToggleButton(value=is_paused(), description=\"Pause queue\")\n",
    "\n",
    "def _refresh_queue(_=None):\n",
    "    rows = list_items()\n",
    "    queue_stats.value = f\"<b>Queue:</b> {len(rows)} items | paused: {is_paused()}\"\n",
    "    queue_output.clear_output()\n",
    "    if not rows:\n",
    "        with queue_output:\n",
    "            display(widgets.HTML(\"<i>No items in queue.</i>\"))\n",
    "    else:\n",
    "        df = pd.DataFrame(rows)\n",
    "        with queue_output:\n",
    "            display(df.head(15))\n",
    "\n",
    "refresh_queue.on_click(_refresh_queue)\n",
    "\n",
    "def _retry(_):\n",
    "    for row in list_items(status=\"failed\"):\n",
    "        retry_item(row[\"id\"])\n",
    "    toast(\"Retried failed queue items\", level=\"success\")\n",
    "    _refresh_queue()\n",
    "\n",
    "def _purge(_):\n",
    "    purge_completed()\n",
    "    toast(\"Purged completed queue items\", level=\"warning\")\n",
    "    _refresh_queue()\n",
    "\n",
    "def _pause(change):\n",
    "    set_paused(change[\"new\"])\n",
    "    toast(f\"Queue paused: {change['new']}\", level=\"info\")\n",
    "    _refresh_queue()\n",
    "\n",
    "retry_failed.on_click(_retry)\n",
    "purge_done.on_click(_purge)\n",
    "pause_toggle.observe(_pause, names=\"value\")\n",
    "_refresh_queue()\n",
    "\n",
    "flow_panel = widgets.VBox([\n",
    "    queue_stats,\n",
    "    widgets.HBox([refresh_queue, retry_failed, purge_done, pause_toggle]),\n",
    "    queue_output,\n",
    "])\n",
    "\n",
    "voice_panel = widgets.VBox([widgets.HTML(\"<b>Voice benchmarks</b>: run the Audio Pipeline Benchmark Suite cells below to populate results.\")])\n",
    "\n",
    "utilities_panel = widgets.VBox([widgets.HTML(\"Use Maintenance Utilities section for pruning, diagnostics, and backups.\")])\n",
    "\n",
    "board = control_board(env_summary, downloads_panel, flow_panel, voice_panel, utilities_panel)\n",
    "display(board)\n",
    "toast(\"Control board ready. Expand accordion sections below in order.\", level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0110d91",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Control Board](#control-board)\n",
    "2. [Setup & Environment](#setup-environment)\n",
    "3. [Downloads & Manifests](#downloads-manifests)\n",
    "4. [Flow Studio](#flow-studio)\n",
    "5. [Voice Lab](#voice-lab)\n",
    "6. [Maintenance Utilities](#maintenance-utilities)\n",
    "7. [Advanced Playbooks](#advanced-playbooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378da89b",
   "metadata": {},
   "source": [
    "### <a id=\"control-board\"></a>Control Board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97375cb",
   "metadata": {},
   "source": [
    "# ComfyUI Playground Refresh\n",
    "This notebook orchestrates installs, diagnostics, queue control, and creative workflows for ComfyUI when running inside Google Colab (Drive-backed).\n",
    "- **Start Here:** Review the Control Board in Cell 2 for live status and shortcuts.\n",
    "- **Playbook:** Each accordion section ends with a \"Run next\" checklist so you always know the next action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea90989",
   "metadata": {},
   "source": [
    "# README — ComfyUI Colab Playground\n",
    "\n",
    "Purpose\n",
    "- Quick Colab playground to install and run ComfyUI from Google Drive, expose it via Cloudflare (cloudflared), and run demo flows and job scaffolds for T2I, T2V, I2V, and LORA workflows.\n",
    "\n",
    "Key env vars\n",
    "- `CIVITAI_API_TOKEN` — used for Civitai API downloads (keep secret).\n",
    "- `HUGGINGFACE_TOKEN` — optional, for Hugging Face access if needed.\n",
    "- `COMFYUI_API_KEY` — optional bearer token used by demo cells when calling the ComfyUI API via the public tunnel. If set, demo cells will send Authorization: Bearer <token> and programmatic demos will auto-enable API mode.\n",
    "\n",
    "Endpoint & health guidance (important)\n",
    "- Before running any programmatic demo cell, run the \"Endpoint & Health-check helper\" cell (below Options) and then run the \"ComfyUI health-check\" (Cell 1) to confirm which endpoint will be used.\n",
    "- Demos prefer `localhost:8188` if ComfyUI is reachable locally; otherwise they will use the Cloudflare public URL parsed into `COMFYUI_PUBLIC_URL`.\n",
    "- If you expose the GUI via Cloudflare, secure it by setting `COMFYUI_API_KEY` (the notebook will include the Authorization header automatically when present).\n",
    "\n",
    "How to use\n",
    "1. Mount Drive (run the Drive cell).\n",
    "2. Set options: enable `INSTALL_COMFYUI` and `START_CLOUDFLARED` as needed in the Options cell.\n",
    "3. Run the install cell (creates venv in Drive), then run the venv torch-check cell that prints torch versions from the venv.\n",
    "4. Start ComfyUI using the venv python (the install cell prints the command). Then run the Tunnel cell to obtain the public URL if needed.\n",
    "5. Run the Endpoint helper and the health-check cell to confirm connectivity. Only then run programmatic demo cells.\n",
    "\n",
    "Notes\n",
    "- Colab sessions are ephemeral; running persistent runners is best done on a VM (instructions included). Save models/flows to Drive to persist them.\n",
    "- Model downloads that require login are intentionally commented/guarded to avoid accidental requests.\n",
    "- The notebook caches wheels in `DRIVE_ROOT/ComfyUI/wheel_cache` to reduce repeated downloads between sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9442ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Workflow Playbook {display-mode: \"form\"}\n",
    "\"\"\"Accordion summarising the key notebook phases with next steps.\"\"\"\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from src.notebook_ui import accordion_from_sections, checklist\n",
    "\n",
    "setup_steps = checklist([\n",
    "    \"Run the Drive Mount cell\",\n",
    "    \"Configure toggles in Options\",\n",
    "    \"Execute Install / Update ComfyUI\",\n",
    "])\n",
    "\n",
    "storage_details = widgets.HTML(\"<b>Storage:</b> Drive root is managed under config.yaml; see Maintenance section for pruning utilities.\")\n",
    "setup_panel = widgets.VBox([setup_steps, storage_details])\n",
    "\n",
    "downloads_steps = checklist([\n",
    "    \"Review manifests under Drive manifests/\",\n",
    "    \"Use Download Manager cell to queue assets\",\n",
    "    \"Monitor progress via Control Board → Downloads tab\",\n",
    "])\n",
    "downloads_panel = widgets.VBox([downloads_steps])\n",
    "\n",
    "flow_steps = checklist([\n",
    "    \"Select template in Flow Studio UI\",\n",
    "    \"Compose flow JSON via src.flows\",\n",
    "    \"Submit job to queue\",\n",
    "])\n",
    "flow_panel = widgets.VBox([flow_steps])\n",
    "\n",
    "voice_steps = checklist([\n",
    "    \"Configure STT/TTS providers in Voice Lab\",\n",
    "    \"Run benchmark cell to capture latency\",\n",
    "    \"Link outputs into Flow Studio\",\n",
    "])\n",
    "voice_panel = widgets.VBox([voice_steps])\n",
    "\n",
    "maintenance_steps = checklist([\n",
    "    \"Rotate manifests and configs\",\n",
    "    \"Run diagnostics bundle exporter\",\n",
    "    \"Prune stale artifacts via utilities\",\n",
    "])\n",
    "maintenance_panel = widgets.VBox([maintenance_steps])\n",
    "\n",
    "advanced_steps = checklist([\n",
    "    \"Launch LoRA / Kohya training\",\n",
    "    \"Trigger Wan2.1 T2V/I2V pipelines\",\n",
    "    \"Persist session profile JSON\",\n",
    "])\n",
    "advanced_panel = widgets.VBox([advanced_steps])\n",
    "\n",
    "sections = {\n",
    "    \"Setup & Environment\": setup_panel,\n",
    "    \"Downloads & Manifests\": downloads_panel,\n",
    "    \"Flow Studio\": flow_panel,\n",
    "    \"Voice Lab\": voice_panel,\n",
    "    \"Maintenance Utilities\": maintenance_panel,\n",
    "    \"Advanced Playbooks\": advanced_panel,\n",
    "}\n",
    "\n",
    "accordion = accordion_from_sections(sections)\n",
    "accordion.selected_index = 0\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0cce6b",
   "metadata": {},
   "source": [
    "# ComfyUI Playground — Google Colab (final)\n",
    "\n",
    "Extended notebook: Drive-backed ComfyUI install, tunnel support, T2I/I2I/T2V/I2V scaffolds, multi-LORA workflows, and Kohya-SS training wiring.\n",
    "\n",
    "Set these env vars before running model downloads: `CIVITAI_API_TOKEN` (preferred), `HUGGINGFACE_TOKEN` (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd864b4e",
   "metadata": {},
   "source": [
    "### <a id=\"setup-environment\"></a>Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25465b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive root: /content/drive/MyDrive/ComfyUI\n",
      "CIVITAI token set? True\n"
     ]
    }
   ],
   "source": [
    "#@title Configuration (edit if needed)\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/ComfyUI'  #@param {type: 'string'}\n",
    "MODELS_DIR = DRIVE_ROOT + '/models'\n",
    "LORAS_DIR = MODELS_DIR + '/loras'\n",
    "GGUF_DIR = MODELS_DIR + '/gguf'\n",
    "ARTIFACTS_DIR = DRIVE_ROOT + '/artifacts'\n",
    "CONFIG_DIR = DRIVE_ROOT + '/config'\n",
    "import os\n",
    "CIVITAI_API_TOKEN = os.environ.get('CIVITAI_API_TOKEN', '')\n",
    "HUGGINGFACE_TOKEN = os.environ.get('HUGGINGFACE_TOKEN', '')\n",
    "print('Drive root:', DRIVE_ROOT)\n",
    "print('CIVITAI token set?', bool(CIVITAI_API_TOKEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a81bd0d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#@title Mount Google Drive (run once per session)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mMounting Drive...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#@title Mount Google Drive (run once per session)\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "print('Mounting Drive...')\n",
    "drive.mount('/content/drive')\n",
    "for p in [DRIVE_ROOT, MODELS_DIR, LORAS_DIR, GGUF_DIR, ARTIFACTS_DIR, CONFIG_DIR]:\n",
    "  Path(p).mkdir(parents=True, exist_ok=True)\n",
    "sentinel = Path(DRIVE_ROOT) / '.copilot_sentinel'\n",
    "if not sentinel.exists():\n",
    "  sentinel.write_text('created by comfyui_playground')\n",
    "print('Drive layout ensured')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e9b27",
   "metadata": {},
   "source": [
    "## Options — toggles (set before running heavy cells)\n",
    "\n",
    "Edit the booleans below to control installs, updates and which demo mode the notebook uses (programmatic vs manual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Options\\nINSTALL_COMFYUI = True  #@param {type:'boolean'}\\nUPDATE_COMFYUI = False  #@param {type:'boolean'}\\nSTART_CLOUDFLARED = True  #@param {type:'boolean'}\\nSTART_LOCALTUNNEL = False  #@param {type:'boolean'}\\nUSE_COMFYUI_API = False  #@param {type:'boolean'}\\nRUN_DEMOS = True  #@param {type:'boolean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d786ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Endpoint & Health-check helper\n",
    "# Defines CURRENT_INSTANCE, COMFYUI_API_BASE, COMFYUI_API_KEY, HEADERS and health_check()\n",
    "import os, socket, requests\n",
    "\n",
    "LOCAL_HOST = 'http://127.0.0.1:8188'\n",
    "CF_URL = os.environ.get('COMFYUI_PUBLIC_URL', '')\n",
    "\n",
    "def localhost_reachable(timeout=0.3):\n",
    "    try:\n",
    "        host, port = '127.0.0.1', 8188\n",
    "        with socket.create_connection((host, port), timeout):\n",
    "            return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "COMFYUI_IS_LOCAL = localhost_reachable()\n",
    "if COMFYUI_IS_LOCAL:\n",
    "    CURRENT_INSTANCE = LOCAL_HOST\n",
    "else:\n",
    "    CURRENT_INSTANCE = CF_URL or LOCAL_HOST\n",
    "\n",
    "COMFYUI_API_BASE = CURRENT_INSTANCE.rstrip('/')\n",
    "COMFYUI_API_KEY = os.environ.get('COMFYUI_API_KEY', '')\n",
    "\n",
    "# Prepare headers if an API key exists (Authorization: Bearer <key>)\n",
    "HEADERS = {}\n",
    "if COMFYUI_API_KEY:\n",
    "    HEADERS['Authorization'] = f'Bearer {COMFYUI_API_KEY}'\n",
    "\n",
    "# Simple health check helper\n",
    "def health_check(timeout=1.0):\n",
    "    try:\n",
    "        r = requests.get(COMFYUI_API_BASE + '/', timeout=timeout)\n",
    "        return r.status_code, r.text[:200]\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "print('Endpoint helper initialized — CURRENT_INSTANCE =', CURRENT_INSTANCE)\n",
    "print('COMFYUI_IS_LOCAL =', COMFYUI_IS_LOCAL)\n",
    "print('COMFYUI_API_KEY set?', bool(COMFYUI_API_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ComfyUI health-check (run after endpoint helper)\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "if 'COMFYUI_API_BASE' not in globals():\n",
    "    print('Endpoint helper not initialized — run the previous cell first')\n",
    "else:\n",
    "    status, info = globals().get('health_check', lambda *a, **k: (None, 'no health_check'))()\n",
    "    if status is None:\n",
    "        display(Markdown(f\"**Health check failed** — error: `{info}`\"))\n",
    "    else:\n",
    "        display(Markdown(f\"**ComfyUI responded with status `{status}`** — preview: `{info}`\"))\n",
    "    print('CURRENT_INSTANCE =', globals().get('COMFYUI_API_BASE'))\n",
    "    print('COMFYUI_IS_LOCAL =', globals().get('COMFYUI_IS_LOCAL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee67c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenance Utilities (invoke via control board)\n",
    "from src.maintenance import prune_artifacts, rotate_manifest_backups, validate_env_vars\n",
    "from src.config import PlaygroundConfig\n",
    "\n",
    "cfg = PlaygroundConfig.load()\n",
    "\n",
    "print('Pruned artifacts (24h):', prune_artifacts(config=cfg))\n",
    "print('Rotated manifests:', rotate_manifest_backups(config=cfg))\n",
    "print('Env vars ready:', validate_env_vars(['CIVITAI_API_TOKEN', 'COMFYUI_API_KEY'], config=cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e1763",
   "metadata": {},
   "source": [
    "## Install / Update ComfyUI (idempotent)\n",
    "\n",
    "Clones ComfyUI into Drive and creates a venv under the ComfyUI folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install or update ComfyUI (venv in Drive, cached wheels)\n",
    "\"\"\"\n",
    "This cell creates a persistent venv under DRIVE_ROOT/ComfyUI/venv, caches downloaded wheels\n",
    "into DRIVE_ROOT/ComfyUI/wheel_cache to avoid repeated downloads, installs core deps into\n",
    "that venv (torch wheel selection with fallbacks), optionally installs xformers non-fatally,\n",
    "clones ComfyUI and ComfyUI-Manager into Drive, and runs the Manager colab-deps script\n",
    "if present.\n",
    "\n",
    "Run this cell once (or set UPDATE_COMFYUI=True to pull latest and re-run installs).\n",
    "\"\"\"\n",
    "import os, subprocess, sys, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure DRIVE_ROOT is available (set in the notebook's config cell)\n",
    "DRIVE_ROOT = os.environ.get('DRIVE_ROOT', '/content/drive/MyDrive/ComfyUI')\n",
    "COMFY_DIR = Path(DRIVE_ROOT)/'ComfyUI'\n",
    "VENV_DIR = COMFY_DIR/'venv'\n",
    "PY = VENV_DIR/'bin'/'python'\n",
    "PIP = VENV_DIR/'bin'/'pip'\n",
    "WHEEL_CACHE = COMFY_DIR/'wheel_cache'\n",
    "\n",
    "# Options from the options cell - fall back to defaults if not set\n",
    "INSTALL_COMFYUI = globals().get('INSTALL_COMFYUI', True)\n",
    "UPDATE_COMFYUI = globals().get('UPDATE_COMFYUI', False)\n",
    "\n",
    "print('Drive root:', DRIVE_ROOT)\n",
    "print('Install requested?', INSTALL_COMFYUI, 'Update requested?', UPDATE_COMFYUI)\n",
    "\n",
    "if not INSTALL_COMFYUI:\n",
    "  print('Skipping install per options')\n",
    "else:\n",
    "  # Create directories\n",
    "  Path(DRIVE_ROOT).mkdir(parents=True, exist_ok=True)\n",
    "  WHEEL_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "  COMFY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  # Clone or update ComfyUI\n",
    "  if not (COMFY_DIR/'main.py').exists():\n",
    "    print('Cloning ComfyUI into Drive...')\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/ComfyUI/ComfyUI.git', str(COMFY_DIR)], check=True)\n",
    "  elif UPDATE_COMFYUI:\n",
    "    print('Updating ComfyUI...')\n",
    "    subprocess.run(['git', '-C', str(COMFY_DIR), 'pull'], check=True)\n",
    "  else:\n",
    "    print('ComfyUI present; skipping clone/pull')\n",
    "\n",
    "  # Create venv if missing\n",
    "  if not VENV_DIR.exists():\n",
    "    print('Creating venv at', VENV_DIR)\n",
    "    import venv\n",
    "    venv.create(VENV_DIR, with_pip=True)\n",
    "  else:\n",
    "    print('Using existing venv at', VENV_DIR)\n",
    "\n",
    "  # Helper to run commands using the venv python/pip\n",
    "  def venv_run(cmd, **kwargs):\n",
    "    print('>', ' '.join(cmd))\n",
    "    return subprocess.run(cmd, **kwargs)\n",
    "\n",
    "  # Ensure pip/setuptools/wheel are up to date in venv\n",
    "  venv_run([str(PIP), 'install', '--upgrade', 'pip', 'setuptools', 'wheel'], check=True)\n",
    "\n",
    "  # Install core Python packages (pure python / small wheels)\n",
    "  core_pkgs = [\n",
    "    'accelerate', 'einops', 'safetensors>=0.4.2', 'aiohttp', 'pyyaml', 'Pillow', 'scipy',\n",
    "    'tqdm', 'psutil', 'tokenizers>=0.13.3', 'kornia>=0.7.1', 'soundfile', 'sentencepiece', 'spandrel',\n",
    "    'transformers>=4.28.1', 'opencv-python'\n",
    "  ]\n",
    "  try:\n",
    "    venv_run([str(PIP), 'install', '--upgrade'] + core_pkgs + ['--cache-dir', str(WHEEL_CACHE)], check=True)\n",
    "  except subprocess.CalledProcessError as e:\n",
    "    print('Core package install failed:', e)\n",
    "\n",
    "  # Torch wheel strategy: try common CUDA wheels then CPU fallback\n",
    "  torch_candidates = [\n",
    "    ('cu121', 'https://download.pytorch.org/whl/cu121'),\n",
    "    ('cu122', 'https://download.pytorch.org/whl/cu122'),\n",
    "    ('cpu',   'https://download.pytorch.org/whl/cpu')\n",
    "  ]\n",
    "  installed_torch = False\n",
    "  for tag, index_url in torch_candidates:\n",
    "    try:\n",
    "      print(f'Trying torch wheel for {tag} (index: {index_url})')\n",
    "      venv_run([str(PIP), 'install', 'torch', 'torchvision', 'torchaudio', '--index-url', index_url, '--cache-dir', str(WHEEL_CACHE)], check=True)\n",
    "      installed_torch = True\n",
    "      print('Installed torch for', tag)\n",
    "      break\n",
    "    except subprocess.CalledProcessError:\n",
    "      print('Torch wheel install failed for', tag)\n",
    "\n",
    "  if not installed_torch:\n",
    "    print('Warning: torch installation failed for all candidates — verify CUDA/runtime and consider manual wheel selection')\n",
    "\n",
    "  # Optional installs that may fail depending on CUDA/toolchain — non-fatal\n",
    "  optional_pkgs = ['torchsde']\n",
    "  for pkg in optional_pkgs:\n",
    "    try:\n",
    "      venv_run([str(PIP), 'install', pkg, '--cache-dir', str(WHEEL_CACHE)], check=True)\n",
    "    except subprocess.CalledProcessError:\n",
    "      print(pkg, 'install failed (non-fatal)')\n",
    "\n",
    "  # Attempt xformers but continue on failure\n",
    "  try:\n",
    "    print('Attempting xformers (optional). This may fail for some CUDA/pytorch combos.')\n",
    "    venv_run([str(PIP), 'install', 'xformers!=0.0.18', '--cache-dir', str(WHEEL_CACHE)], check=True)\n",
    "    print('xformers installed')\n",
    "  except subprocess.CalledProcessError as e:\n",
    "    print('xformers install failed (non-fatal):', e)\n",
    "\n",
    "  # Clone/Update ComfyUI-Manager in custom_nodes if requested (guarded)\n",
    "  CN_DIR = COMFY_DIR/'custom_nodes'/'ComfyUI-Manager'\n",
    "  if not CN_DIR.exists():\n",
    "    (COMFY_DIR/'custom_nodes').mkdir(parents=True, exist_ok=True)\n",
    "    print('Cloning ComfyUI-Manager...')\n",
    "    venv_run(['git', 'clone', 'https://github.com/ltdrdata/ComfyUI-Manager', str(CN_DIR)], check=True)\n",
    "  else:\n",
    "    print('ComfyUI-Manager present; pulling latest')\n",
    "    venv_run(['git', '-C', str(CN_DIR), 'pull'], check=True)\n",
    "\n",
    "  # Run Manager colab-dependencies script if present — use venv python\n",
    "  colab_dep = CN_DIR/'scripts'/'colab-dependencies.py'\n",
    "  if colab_dep.exists():\n",
    "    print('Running ComfyUI-Manager colab-dependencies.py with venv python (guarded)')\n",
    "    try:\n",
    "      venv_run([str(PY), str(colab_dep)], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "      print('Manager colab-deps failed (non-fatal):', e)\n",
    "  else:\n",
    "    print('No ComfyUI-Manager colab-dependencies script found')\n",
    "\n",
    "  print('\\nInstall complete. To start ComfyUI (headless) with the venv run:')\n",
    "  print(f'{PY} {COMFY_DIR}/main.py --headless --port 8188')\n",
    "\n",
    "  # After install: print venv torch versions for quick verification\n",
    "  try:\n",
    "    print('\\nVerifying torch inside venv:')\n",
    "    venv_run([str(PY), '-c', 'import torch; print(torch.__version__, torch.version.cuda)'])\n",
    "  except Exception as e:\n",
    "    print('Failed to inspect torch in venv (non-fatal):', e)\n",
    "\n",
    "# End install cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a8499",
   "metadata": {},
   "source": [
    "## Model manager — prefilled Civitai downloads (comment/uncomment to use)\n",
    "\n",
    "Each block includes a title comment and any special notes (NSFW, login required). Use `CIVITAI_API_TOKEN` environment variable for API downloads. If a model requires web login or is private, you'll need to download via the browser or the Civitai web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30032e8",
   "metadata": {},
   "source": [
    "### <a id=\"downloads-manifests\"></a>Downloads & Manifests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80374b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Model download examples (prefilled)\n",
    "# NOTE: Set CIVITAI_API_TOKEN in env before uncommenting wget lines.\n",
    "# Example: import os; os.environ['CIVITAI_API_TOKEN']='your_token'\n",
    "\n",
    "# 1) Model ID 1624818 — SafeTensor API download (may require login)\n",
    "# wget pattern (SafeTensor fp16):\n",
    "# !wget \"https://civitai.com/api/download/models/1624818?type=Model&format=SafeTensor&size=full&fp=fp16&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{LORAS_DIR}\"\n",
    "\n",
    "# 2) CyberRealistic Pony (ID 443821) — checkpoint (SafeTensor). See recommended settings in model page.\n",
    "# !wget \"https://civitai.com/api/download/models/443821?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/cyberrealistic\"\n",
    "\n",
    "# 3) Doggy-Style (ID 1741501) — NSFW, login required. Use web UI if API returns login required.\n",
    "# (if available via API):\n",
    "# !wget \"https://civitai.com/api/download/models/1741501?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/wan\"\n",
    "\n",
    "# 4) WAN POV Cowgirl insertion (ID 2048863) — NSFW\n",
    "# !wget \"https://civitai.com/api/download/models/2048863?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
    "\n",
    "# 5) QWEN-4 play LoRA (ID 2004155) — LoRA (may be LORA format). Check model page for exact file names and formats.\n",
    "# !wget \"https://civitai.com/api/download/models/2004155?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{LORAS_DIR}\"\n",
    "\n",
    "# 6) WAN-22 I2V (ID 2031069) — NSFW video-capable model; may have GGUF or special instructions.\n",
    "# !wget \"https://civitai.com/api/download/models/2031069?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
    "\n",
    "# 7) PENIS LoRA / TAZ (ID 1476909) — NSFW LoRA. Login required for NSFW models on some pages.\n",
    "# !wget \"https://civitai.com/api/download/models/1476909?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{LORAS_DIR}\"\n",
    "\n",
    "# 8) POV Insertion WAN 2x (ID 1855263) — NSFW, video/wan style.\n",
    "# !wget \"https://civitai.com/api/download/models/1855263?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
    "\n",
    "# 9) Oral Insertion WAN (ID 1874153) — NSFW\n",
    "# !wget \"https://civitai.com/api/download/models/1874153?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
    "\n",
    "# 10) WAN-2221 POV Missionary (ID 1331682) — NSFW\n",
    "# !wget \"https://civitai.com/api/download/models/1331682?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
    "\n",
    "# 11) CyberRealistic (ID 15003) — photorealistic SD base; recommended settings in page.\n",
    "# !wget \"https://civitai.com/api/download/models/15003?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/cyberrealistic\"\n",
    "\n",
    "# 12) ChilloutMix (ID 6424) — popular blended model (may require SafeTensor format).\n",
    "# !wget \"https://civitai.com/api/download/models/6424?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/chilloutmix\"\n",
    "\n",
    "# 13) WAN-22 Experimental (ID 1307155) — your provided WAN model link (GGUF/SafeTensor examples).\n",
    "# GGUF example (preferred for Wan2 runners):\n",
    "# !wget \"https://civitai.com/api/download/models/1307155?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
    "# Safetensor (alternate):\n",
    "# !wget \"https://civitai.com/api/download/models/1307155?type=Model&format=SafeTensor&size=full&fp=fp16&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/wan\"\n",
    "\n",
    "# --- New additions requested by user ---\n",
    "# Add model 1064836 (user link: https://civitai.com/models/1064836?modelVersionId=993999)\n",
    "# NOTE: Many NSFW models require login; keep this line commented until you set CIVITAI_API_TOKEN or download manually.\n",
    "# !wget \"https://civitai.com/api/download/models/1064836?modelVersionId=993999&format=SafeTensor&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/model_1064836\"\n",
    "\n",
    "# Add model 652699 (user link: https://civitai.com/models/652699?modelVersionId=993999)\n",
    "# This appears to be a LoRA (Amateur Photography) — save into LORAS_DIR\n",
    "# !wget \"https://civitai.com/api/download/models/652699?modelVersionId=993999&format=SafeTensor&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{LORAS_DIR}\"\n",
    "\n",
    "print('Prefilled Civitai download blocks added as comments. Uncomment the lines you want to execute and ensure CIVITAI_API_TOKEN is set if required.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Per-model metadata: Civitai model 652699 — 'Amateur Photography' LoRA\n",
    "# This model is a LoRA with recommended settings pulled from the model page where available.\n",
    "MODEL_652699 = {\n",
    "  'model_id': 652699,\n",
    "  'modelVersionId': 993999,\n",
    "  'type': 'LoRA',\n",
    "  'gated': False,\n",
    "  'download_template': f'!wget \"https://civitai.com/api/download/models/652699?modelVersionId=993999&format=SafeTensor&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{{LORAS_DIR}}\"',\n",
    "  'recommended_settings': {\n",
    "    'distilled_cfg_scale': 3.5,\n",
    "    'sampler': 'DEIS with DDIM',\n",
    "    'steps': 20,\n",
    "    'resolution': '896x1152 or 880x1184 / 1328x1776',\n",
    "    'hires_fix_upscaler': '4x_NMKD-Superscale-SP_178000_G',\n",
    "    'hires_steps': 10,\n",
    "    'hires_denoise': 0.3,\n",
    "    'lora_weight': 0.8,\n",
    "    'usage_tip': 'Try EasyCache (skip 2 steps) for faster results with little quality loss.'\n",
    "  },\n",
    "  'notes': 'Typical use: apply this LoRA at ~0.8 weight during sampling / hi-res steps. Adjust per prompt.'\n",
    "}\n",
    "print('Model metadata for 652699 registered. Inspect MODEL_652699 for recommended settings.')\n",
    "\n",
    "# Example: to download after setting CIVITAI_API_TOKEN, copy and run MODEL_652699['download_template'] (uncomment).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e92a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Per-model metadata: Civitai model 1064836 (user-supplied)\n",
    "# Guarded metadata and a download template. This model page is NSFW/gated — you may need to login or use the API token.\n",
    "MODEL_1064836 = {\n",
    "  'model_id': 1064836,\n",
    "  'modelVersionId': 993999,\n",
    "  'type': 'image/checkpoint',\n",
    "  'gated': True,\n",
    "  'notes': 'NSFW-gated content. If the API download fails, download via web UI and upload to Drive. Example settings may be on model page.' ,\n",
    "  'download_template': f'!wget \"https://civitai.com/api/download/models/1064836?modelVersionId=993999&format=SafeTensor&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{{MODELS_DIR}}/model_1064836\"',\n",
    "  'recommended_settings': {},\n",
    "}\n",
    "print('Model metadata for 1064836 registered. Inspect MODEL_1064836 for download template and notes.')\n",
    "\n",
    "# Usage: if you set CIVITAI_API_TOKEN via the secure cell above, copy the download_template and run it (uncomment) to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3822c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIVITAI_API_TOKEN set in-memory for this session (not displayed).\n"
     ]
    }
   ],
   "source": [
    "#@title Set CIVITAI_API_TOKEN (secure, in-memory)\n",
    "# Use this to set the CIVITAI token for the session without printing it.\n",
    "import os, getpass\n",
    "try:\n",
    "    token = getpass.getpass('Enter CIVITAI_API_TOKEN (input hidden): ')\n",
    "except Exception:\n",
    "    # Fallback for environments where getpass may not hide input\n",
    "    token = input('Enter CIVITAI_API_TOKEN (visible input): ')\n",
    "\n",
    "if token:\n",
    "    os.environ['CIVITAI_API_TOKEN'] = token\n",
    "    # also expose a session variable for notebook code to read\n",
    "    CIVITAI_API_TOKEN = token\n",
    "    print('CIVITAI_API_TOKEN set in-memory for this session (not displayed).')\n",
    "else:\n",
    "    print('No token entered — token not set')\n",
    "\n",
    "# Reminder: token is only stored in the notebook process memory and in os.environ for the session.\n",
    "# Do NOT paste your token in chat. Restarting the runtime will clear it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a6c8e",
   "metadata": {},
   "source": [
    "### <a id=\"flow-studio\"></a>Flow Studio\n",
    "\n",
    "Use the Control Board → Flow Studio tab to inspect queue status and launch templates. The cells below mirror the original manual workflows for exercising flow composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Flow regression tests (optional smoke check)\n",
    "\"\"\"Run the lightweight pytest suite to confirm flow templates compose and validate.\"\"\"\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Running pytest -q test_flows_regression.py...\\n\")\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pytest\", \"test_flows_regression.py\", \"-q\"],\n",
    "    cwd=str(Path.cwd()),\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\nFlow regression tests passed.\")\n",
    "else:\n",
    "    print(\"\\nFlow regression tests failed — inspect the pytest output above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6368c642",
   "metadata": {},
   "source": [
    "## Launch ComfyUI and Tunnelling (cloudflared/localtunnel)\n",
    "\n",
    "Start ComfyUI headless then create a public URL with cloudflared or localtunnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af892f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Start ComfyUI (headless) — Drive-backed\n",
    "import subprocess, time, os\n",
    "from pathlib import Path\n",
    "COMFY_DIR = Path(DRIVE_ROOT)/'ComfyUI'\n",
    "VENV = COMFY_DIR/'venv'\n",
    "PY = str(VENV/'bin'/'python')\n",
    "proc = None\n",
    "COMFYUI_PUBLIC_URL = None\n",
    "\n",
    "if Path(PY).exists() and INSTALL_COMFYUI:\n",
    "  # Ensure we run ComfyUI from the Drive copy so files and models persist\n",
    "  print('Starting ComfyUI from Drive...')\n",
    "  proc = subprocess.Popen([PY, str(COMFY_DIR/'main.py'), '--headless', '--port', '8188'], cwd=str(COMFY_DIR), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "  # don't block — the tunnel cell will parse the public URL; give process a moment to warm up\n",
    "  time.sleep(2)\n",
    "  if proc.poll() is None:\n",
    "    print('ComfyUI started, PID:', proc.pid)\n",
    "  else:\n",
    "    print('ComfyUI process exited early — check logs')\n",
    "else:\n",
    "  print('ComfyUI not installed or SKIPPED; ensure INSTALL_COMFYUI=True and rerun')\n",
    "\n",
    "# Export so subsequent tunnel cell can set/use it\n",
    "os.environ['COMFYUI_PUBLIC_URL'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Start cloudflared and parse URL — prefer Cloudflare public address\n",
    "import subprocess, time, re, os\n",
    "from pathlib import Path\n",
    "CLOUDFLARED = '/usr/local/bin/cloudflared'\n",
    "COMFYUI_PUBLIC_URL = os.environ.get('COMFYUI_PUBLIC_URL','')\n",
    "\n",
    "if START_CLOUDFLARED:\n",
    "  if not os.path.exists(CLOUDFLARED):\n",
    "    print('Installing cloudflared...')\n",
    "    subprocess.run(['wget','-q','-O','/usr/local/bin/cloudflared','https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64'], check=True)\n",
    "    subprocess.run(['chmod','+x','/usr/local/bin/cloudflared'], check=True)\n",
    "  print('Launching cloudflared tunnel to http://localhost:8188 — parsing public URL from stdout')\n",
    "  p = subprocess.Popen([CLOUDFLARED, 'tunnel', '--url', 'http://localhost:8188'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "  url = None\n",
    "  start = time.time()\n",
    "  while time.time() - start < 30:\n",
    "    line = p.stdout.readline()\n",
    "    if not line:\n",
    "      time.sleep(0.1)\n",
    "      continue\n",
    "    print(line.strip())\n",
    "    # Handle multiple possible formats\n",
    "    m = re.search(r'(https://[a-z0-9.-]+\\\\.trycloudflare\\\\.com)', line)\n",
    "    if m:\n",
    "      url = m.group(1)\n",
    "      break\n",
    "    # older formats may contain 'https://' directly\n",
    "    m2 = re.search(r'https://[a-z0-9.-]+', line)\n",
    "    if m2 and '.trycloudflare' in m2.group(0):\n",
    "      url = m2.group(0)\n",
    "      break\n",
    "  if url:\n",
    "    print('Found Cloudflare public URL:', url)\n",
    "    COMFYUI_PUBLIC_URL = url\n",
    "    os.environ['COMFYUI_PUBLIC_URL'] = url\n",
    "  else:\n",
    "    print('Could not parse a public URL from cloudflared output after timeout')\n",
    "else:\n",
    "  print('Cloudflared start skipped')\n",
    "\n",
    "# Print the effective public URL for the user and downstream cells\n",
    "print('COMFYUI_PUBLIC_URL =', os.environ.get('COMFYUI_PUBLIC_URL',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Start localtunnel (if preferred)\n",
    "import subprocess, shutil, time, re, os\n",
    "if START_LOCALTUNNEL:\n",
    "  if not shutil.which('node'):\n",
    "    !curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -\n",
    "    !sudo apt-get install -y nodejs\n",
    "  if not shutil.which('lt'):\n",
    "    !npm install -g localtunnel\n",
    "  proc = subprocess.Popen(['lt', '--port', '8188'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "  url = None\n",
    "  start = time.time()\n",
    "  while time.time() - start < 20:\n",
    "    line = proc.stdout.readline()\n",
    "    if not line:\n",
    "      time.sleep(0.2)\n",
    "      continue\n",
    "    print(line.strip())\n",
    "    m = re.search(r'https?://[\\w\\.-]+\\.loca\\.lt', line)\n",
    "    if m:\n",
    "      url = m.group(0)\n",
    "      break\n",
    "  if url:\n",
    "    print('localtunnel URL:', url)\n",
    "  else:\n",
    "    print('Could not parse localtunnel URL')\n",
    "else:\n",
    "  print('Localtunnel start skipped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79a339",
   "metadata": {},
   "source": [
    "## Demos: T2I / I2I (programmatic + fallback)\n",
    "\n",
    "These cells try the programmatic ComfyUI API when `USE_COMFYUI_API` is True. If the API endpoints differ, I can update the endpoints according to your ComfyUI instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Simple T2I demo (placeholder or API — uses shared endpoint helper)\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Image\n",
    "from pathlib import Path\n",
    "import requests, base64, os\n",
    "\n",
    "# Use shared endpoint vars populated by the Endpoint helper cell\n",
    "COMFYUI_API_BASE = globals().get('COMFYUI_API_BASE', 'http://127.0.0.1:8188')\n",
    "COMFYUI_API_KEY = globals().get('COMFYUI_API_KEY', os.environ.get('COMFYUI_API_KEY', ''))\n",
    "HEADERS = globals().get('HEADERS', {})\n",
    "\n",
    "# Auto-enable API mode if an API key is present\n",
    "if COMFYUI_API_KEY:\n",
    "    globals()['USE_COMFYUI_API'] = True\n",
    "\n",
    "model = widgets.Text(value='', description='Model path (optional)')\n",
    "prompt = widgets.Textarea(value='A fantasy landscape, cinematic lighting', description='Prompt')\n",
    "run = widgets.Button(description='Generate')\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "# Reminder: run the Endpoint helper and Cell 1 health-check before using this demo\n",
    "print('Reminder: run the Endpoint & Health-check helper and the ComfyUI health-check (Cell 1) before running demos')\n",
    "\n",
    "\n",
    "def call_comfy_api(prompt_text):\n",
    "  # Lightweight placeholder for calling a hypothetical ComfyUI API endpoint\n",
    "  try:\n",
    "    url = COMFYUI_API_BASE + '/api/generate'\n",
    "    print('Calling', url)\n",
    "    r = requests.post(url, json={'prompt': prompt_text}, headers=HEADERS or None, timeout=20)\n",
    "    if r.status_code == 200:\n",
    "      # assume API returns base64 PNG in 'image' field for this demo\n",
    "      data = r.json()\n",
    "      if 'image' in data:\n",
    "        imgdata = base64.b64decode(data['image'])\n",
    "        p = Path(ARTIFACTS_DIR)/'t2i_from_api.png'\n",
    "        p.write_bytes(imgdata)\n",
    "        return str(p)\n",
    "      else:\n",
    "        print('API returned JSON without image field')\n",
    "        return None\n",
    "    else:\n",
    "      print('API returned', r.status_code, r.text[:200])\n",
    "      return None\n",
    "  except Exception as e:\n",
    "    print('API call failed:', e)\n",
    "    return None\n",
    "\n",
    "\n",
    "def on_run(b):\n",
    "  with out:\n",
    "    clear_output()\n",
    "    print('Using API base:', COMFYUI_API_BASE)\n",
    "    print('Using headers:', HEADERS)\n",
    "    if globals().get('USE_COMFYUI_API', False):\n",
    "      path = call_comfy_api(prompt.value)\n",
    "      if path:\n",
    "        display(Image(path))\n",
    "        return\n",
    "    # fallback placeholder\n",
    "    print('Falling back to placeholder image (local)')\n",
    "    from PIL import Image as PILImage, ImageDraw\n",
    "    Path(ARTIFACTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    imgpath = Path(ARTIFACTS_DIR)/'t2i_placeholder.png'\n",
    "    img = PILImage.new('RGB', (512,512), (60,100,150))\n",
    "    d = ImageDraw.Draw(img)\n",
    "    d.text((10,10), prompt.value[:200], fill=(255,255,0))\n",
    "    img.save(imgpath)\n",
    "    display(Image(str(imgpath)))\n",
    "    print('Saved to', imgpath)\n",
    "\n",
    "run.on_click(on_run)\n",
    "display(model, prompt, run, out)\n",
    "\n",
    "print('CURRENT_INSTANCE =', COMFYUI_API_BASE)\n",
    "print('COMFYUI_API_KEY set?', bool(COMFYUI_API_KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fe7d5c",
   "metadata": {},
   "source": [
    "## Wan2.1 T2V / I2V scaffold (GGUF models)\n",
    "\n",
    "This prepares a job file for Wan2 runners and can launch a `wan2_runner.py` if present in Drive root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Wan2.1 T2V / I2V scaffold\n",
    "from pathlib import Path\n",
    "import json, subprocess, os\n",
    "\n",
    "# Use shared endpoint values if performing remote calls\n",
    "COMFYUI_API_BASE = globals().get('COMFYUI_API_BASE', 'http://127.0.0.1:8188')\n",
    "COMFYUI_API_KEY = globals().get('COMFYUI_API_KEY', os.environ.get('COMFYUI_API_KEY',''))\n",
    "HEADERS = globals().get('HEADERS', {})\n",
    "\n",
    "# Auto-enable API mode if an API key is present\n",
    "if COMFYUI_API_KEY:\n",
    "    globals()['USE_COMFYUI_API'] = True\n",
    "\n",
    "# Reminder: run the Endpoint helper and Cell 1 health-check before using this demo\n",
    "print('Reminder: run the Endpoint & Health-check helper and the ComfyUI health-check (Cell 1) before running demos')\n",
    "\n",
    "prompt = 'A cinematic pan across a neon city at dusk'\n",
    "job = {'prompt': prompt, 'frames': 32, 'steps_per_frame': 10, 'model': 'wan2-14b.gguf'}\n",
    "Path(ARTIFACTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "jobfile = Path(ARTIFACTS_DIR)/'wan2_job.json'\n",
    "jobfile.write_text(json.dumps(job, indent=2))\n",
    "print('Job file written to', jobfile)\n",
    "runner = Path(DRIVE_ROOT)/'wan2_runner.py'\n",
    "if runner.exists():\n",
    "  print('Found wan2_runner.py — launching in background')\n",
    "  p = subprocess.Popen(['python', str(runner), '--job', str(jobfile)])\n",
    "  print('Runner PID:', p.pid)\n",
    "else:\n",
    "  print('No wan2_runner.py found. Provide one or adapt the example Wan2 notebooks.')\n",
    "\n",
    "# If you'd like to POST the job to a remote runner endpoint, example (guarded):\n",
    "# if COMFYUI_API_BASE:\n",
    "#   import requests\n",
    "#   r = requests.post(COMFYUI_API_BASE + '/api/wan2/jobs', json=job, headers=HEADERS)\n",
    "#   print('Posted job, response', r.status_code, r.text[:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d603e1f",
   "metadata": {},
   "source": [
    "## Kohya-SS training scaffold (sd-scripts)\n",
    "\n",
    "Clones the `sd-scripts` repo and prepares an example training command. Running training inside Colab can exceed session limits; use a longer-running VM when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a43f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Kohya-SS (sd-scripts) clone + example command\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "KOYHA_DIR = Path(DRIVE_ROOT)/'kohya_ss'\n",
    "if not KOYHA_DIR.exists():\n",
    "  !git clone https://github.com/kohya-ss/sd-scripts.git \"$KOYHA_DIR\"\n",
    "else:\n",
    "  print('kohya_ss already cloned')\n",
    "Path(DRIVE_ROOT+'/datasets/lora_dataset').mkdir(parents=True, exist_ok=True)\n",
    "print('Place images into', DRIVE_ROOT+'/datasets/lora_dataset')\n",
    "print('Example training command:')\n",
    "print(f\"python train_network.py --output_dir={LORAS_DIR} --train_data_dir={DRIVE_ROOT}/datasets/lora_dataset --resolution=512,512 --network_train_unet_only --max_train_steps=1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fad6bd",
   "metadata": {},
   "source": [
    "---\n",
    "Notes:\n",
    "\n",
    "- Many Civitai pages for NSFW models require login. If an API download returns 'login required', use the web UI or your account to download the files and then upload them into Drive.\n",
    "- If you want, I can wire real ComfyUI API endpoints here — provide the exact endpoints and any auth headers, and I'll update the demo cells to call them programmatically.\n",
    "- Tell me if you'd like model-specific example workflows for each WAN model (T2V chains, I2V setups, LORA generator flows)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c09939",
   "metadata": {},
   "source": [
    "## API key and security wiring\n",
    "\n",
    "This section shows how to provide a COMFYUI_API_KEY environment variable and uses it in programmatic calls so the exposed Cloudflare URL is protected with a simple bearer token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Set COMFYUI_API_KEY (optional) — run this cell to set in-memory for the session\n",
    "import os\n",
    "# Option 1: set directly here (quick, not persistent)\n",
    "# os.environ['COMFYUI_API_KEY'] = 'your_secret_here'\n",
    "\n",
    "# Option 2: set via Colab UI or a secure Vault; the notebook reads os.environ['COMFYUI_API_KEY'] when making API calls\n",
    "print('COMFYUI_API_KEY set?', bool(os.environ.get('COMFYUI_API_KEY')))\n",
    "print('If you want, set os.environ[\\'COMFYUI_API_KEY\\']=\\'...\\' in a cell before running API calls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11667ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Copy Cloudflare public URL to clipboard\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "url = os.environ.get('COMFYUI_PUBLIC_URL', '')\n",
    "if url:\n",
    "  display(HTML(f\"<input type='text' value='{url}' id='cfurl' style='width:400px' /><button onclick=\\\"navigator.clipboard.writeText(document.getElementById('cfurl').value)\\\">Copy</button>\"))\n",
    "else:\n",
    "  print('No COMFYUI_PUBLIC_URL set. Run the cloudflared cell first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Wan2 background job runner scaffold (Drive-persistent)\n",
    "from pathlib import Path\n",
    "import time, json, subprocess, os\n",
    "JOBS_DIR = Path(DRIVE_ROOT)/'wan2_jobs'\n",
    "JOBS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Watching', JOBS_DIR)\n",
    "\n",
    "# Example runner loop (do NOT run continuously in Colab unless you want a background process)\n",
    "# This reads any job JSON files and prints the job; you can replace 'print' with a real runner call.\n",
    "for jobfile in JOBS_DIR.glob('*.json'):\n",
    "  try:\n",
    "    job = json.loads(jobfile.read_text())\n",
    "    print('Found job:', jobfile)\n",
    "    # Example: invoke a runner script if present\n",
    "    runner = Path(DRIVE_ROOT)/'wan2_runner.py'\n",
    "    if runner.exists():\n",
    "      print('Launching wan2_runner for', jobfile)\n",
    "      subprocess.Popen(['python', str(runner), '--job', str(jobfile)])\n",
    "    else:\n",
    "      print('Runner not found — job is persisted in Drive for later execution')\n",
    "  except Exception as e:\n",
    "    print('Failed to read job', jobfile, e)\n",
    "\n",
    "print('Scan complete — add job JSON files into', JOBS_DIR, 'to schedule runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83326cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ComfyUI graph-save helper (save flow to Drive)\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def save_graph(graph_json, name='flow_saved.json'):\n",
    "  p = Path(DRIVE_ROOT)/'flows'\n",
    "  p.mkdir(parents=True, exist_ok=True)\n",
    "  dest = p/name\n",
    "  dest.write_text(json.dumps(graph_json, indent=2))\n",
    "  print('Saved graph to', dest)\n",
    "\n",
    "# Example usage:\n",
    "# save_graph({'nodes':[], 'connections':[]}, name='example_flow.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Example ComfyUI workflow examples (saved flows)\n",
    "from pathlib import Path\n",
    "\n",
    "# Two tiny example flow JSONs you can expand in the ComfyUI flow editor\n",
    "example_t2i = {\n",
    "  'nodes': [\n",
    "    {'id': 'txt', 'type': 'TextInput', 'args': {'text': 'A fantasy landscape, soft volumetric light'}},\n",
    "    {'id': 'sampler', 'type': 'Sampler', 'args': {'name': 'ddim', 'steps': 20}},\n",
    "    {'id': 'out', 'type': 'ImageSaver', 'args': {'path': str(Path(ARTIFACTS_DIR)/'t2i_example.png')}}\n",
    "  ],\n",
    "  'connections': []\n",
    "}\n",
    "\n",
    "example_multi_lora = {\n",
    "  'nodes': [\n",
    "    {'id': 'seed', 'type': 'SeedInput', 'args': {'seed': 42}},\n",
    "    {'id': 'apply_lora', 'type': 'ApplyLora', 'args': {'paths': ['loraA.safetensors','loraB.safetensors'], 'weights': [0.6,0.4]}},\n",
    "    {'id': 'out', 'type': 'ImageSaver', 'args': {'path': str(Path(ARTIFACTS_DIR)/'multi_lora_example.png')}}\n",
    "  ],\n",
    "  'connections': []\n",
    "}\n",
    "\n",
    "# Save examples using the helper defined earlier\n",
    "try:\n",
    "  save_graph(example_t2i, name='workflow_t2i_example.json')\n",
    "  save_graph(example_multi_lora, name='workflow_multi_lora_example.json')\n",
    "  print('Saved example flows to', Path(DRIVE_ROOT)/'flows')\n",
    "except Exception as e:\n",
    "  print('Failed to save example flows (is the graph helper present?):', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945334b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Advanced flow: Photoreal T2I (tuned for model 1064836)\n",
    "# This flow is a richer starting point: prompt input -> conditioning -> sampler -> hi-res fix -> save\n",
    "from pathlib import Path\n",
    "flow_photoreal = {\n",
    "  'nodes': [\n",
    "    {'id': 'txt', 'type': 'TextInput', 'args': {'text': 'High-quality portrait, soft window lighting, 85mm lens'}},\n",
    "    {'id': 'cond', 'type': 'Conditioning', 'args': {}},\n",
    "    {'id': 'sampler', 'type': 'Sampler', 'args': {'name': 'euler_a', 'steps': 28}},\n",
    "    {'id': 'hires', 'type': 'HiResFix', 'args': {'upscale': 1.5, 'denoise': 0.35, 'method': '4x_NMKD-Superscale-SP_178000_G'}},\n",
    "    {'id': 'apply_lora', 'type': 'ApplyLora', 'args': {'path': str(Path(LORAS_DIR)/'amateur_photography.safetensors'), 'weight': 0.8}},\n",
    "    {'id': 'saver', 'type': 'ImageSaver', 'args': {'path': str(Path(ARTIFACTS_DIR)/'photoreal_example.png')}}\n",
    "  ],\n",
    "  'connections': [\n",
    "    ('txt','cond'), ('cond','sampler'), ('sampler','hires'), ('hires','apply_lora'), ('apply_lora','saver')\n",
    "  ]\n",
    "}\n",
    "# Save flow\n",
    "try:\n",
    "  save_graph(flow_photoreal, name='advanced_photoreal_1064836.json')\n",
    "  print('Saved advanced photoreal flow to', Path(DRIVE_ROOT)/'flows')\n",
    "except Exception as e:\n",
    "  print('Could not save flow (is save_graph defined?):', e)\n",
    "\n",
    "\n",
    "#@title Advanced flow: Wan2.1 video pipeline (uses image frames + LoRA)\n",
    "flow_wan2 = {\n",
    "  'nodes': [\n",
    "    {'id': 'seed_img', 'type': 'ImageInput', 'args': {'path': str(Path(ARTIFACTS_DIR)/'photoreal_example.png')}},\n",
    "    {'id': 'frame_gen', 'type': 'FrameGenerator', 'args': {'frames': 48, 'warp_strength': 0.6}},\n",
    "    {'id': 'apply_wan_lora', 'type': 'ApplyLora', 'args': {'paths': [str(Path(LORAS_DIR)/'wan_pose_lora.safetensors')], 'weights':[1.0]}},\n",
    "    {'id': 'video_encoder', 'type': 'Wan2VideoSaver', 'args': {'path': str(Path(ARTIFACTS_DIR)/'wan2_output.mp4'), 'fps': 24}}\n",
    "  ],\n",
    "  'connections': [('seed_img','frame_gen'), ('frame_gen','apply_wan_lora'), ('apply_wan_lora','video_encoder')]\n",
    "}\n",
    "try:\n",
    "  save_graph(flow_wan2, name='advanced_wan2_from_image.json')\n",
    "  print('Saved Wan2 pipeline flow to', Path(DRIVE_ROOT)/'flows')\n",
    "except Exception as e:\n",
    "  print('Could not save Wan2 flow:', e)\n",
    "\n",
    "print('Advanced flows added. Open them in ComfyUI flow editor and adapt nodes to your installed custom nodes (Manager may add nodes with different names).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf9462",
   "metadata": {},
   "source": [
    "## Advanced & Custom Workflows (model-tuned)\n",
    "\n",
    "This section contains richer ComfyUI flows tuned as starting points for the models you requested. These flows are templates — open them in ComfyUI's Flow Editor and tweak sampler, steps, seed and LoRA weights to match your runtime and model specifics.\n",
    "\n",
    "Below are two saved example flows: an image-focused T2I flow tuned for photographic realism, and a Wan2.1-ready video workflow that uses image frames plus LoRA application for pose/placement.\n",
    "\n",
    "Each flow is saved into `DRIVE_ROOT/flows` (see the example save cell earlier). After you start ComfyUI, load these JSON files in the Flow Editor and wire any custom nodes present in your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Extract workflows from showcase images (attempt)\n",
    "# This cell tries to download showcased images from Civitai model pages and\n",
    "# inspect their PNG tEXt chunks and surrounding HTML for embedded ComfyUI workflows.\n",
    "# It saves any JSON it finds to DRIVE_ROOT/flows/extracted_{model_id}_{i}.json\n",
    "\n",
    "import os, re, requests\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "import base64, io, json\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT', '/content/drive/MyDrive/ComfyUI')\n",
    "OUT_DIR = Path(DRIVE_ROOT)/'flows'/'extracted_images'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_pages = [\n",
    "  'https://civitai.com/models/1064836?modelVersionId=993999',\n",
    "  'https://civitai.com/models/652699?modelVersionId=993999'\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "# If CIVITAI_API_TOKEN is present, include it as a query token when downloading files, but for page scraping a logged-in session may be required\n",
    "CIVITAI_TOKEN = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "headers = {'User-Agent':'ComfyUI-Playground/1.0'}\n",
    "\n",
    "extracted = []\n",
    "\n",
    "for url in model_pages:\n",
    "  print('\\nProcessing', url)\n",
    "  try:\n",
    "    r = session.get(url, headers=headers, timeout=15)\n",
    "    if r.status_code != 200:\n",
    "      print('Failed to fetch page (status', r.status_code, ') — content may be gated; skipping')\n",
    "      continue\n",
    "  except Exception as e:\n",
    "    print('Request failed:', e)\n",
    "    continue\n",
    "\n",
    "  soup = BeautifulSoup(r.text, 'html.parser')\n",
    "  imgs = soup.find_all('img')\n",
    "  print('Found', len(imgs), 'images on page (will attempt to inspect common showcase images)')\n",
    "  count = 0\n",
    "  for img in imgs:\n",
    "    src = img.get('data-src') or img.get('src') or ''\n",
    "    if not src:\n",
    "      continue\n",
    "    # skip tiny icons and badges\n",
    "    if any(x in src for x in ['/avatar', '/badge', 'base-badge', 'width=32']):\n",
    "      continue\n",
    "    # normalize URL\n",
    "    if src.startswith('//'):\n",
    "      src = 'https:' + src\n",
    "    if src.startswith('/'):\n",
    "      src = 'https://civitai.com' + src\n",
    "\n",
    "    # Download image\n",
    "    try:\n",
    "      print('Downloading', src)\n",
    "      ir = session.get(src, headers=headers, timeout=20)\n",
    "      if ir.status_code != 200:\n",
    "        print('Failed to download image', ir.status_code)\n",
    "        continue\n",
    "    except Exception as e:\n",
    "      print('Image download failed:', e)\n",
    "      continue\n",
    "\n",
    "    # Save image temporarily\n",
    "    count += 1\n",
    "    fn = OUT_DIR/f\"img_{Path(src).stem}_{count}.png\"\n",
    "    try:\n",
    "      fn.write_bytes(ir.content)\n",
    "    except Exception:\n",
    "      # try jpg\n",
    "      fn = fn.with_suffix('.jpg')\n",
    "      fn.write_bytes(ir.content)\n",
    "\n",
    "    # Attempt to read PNG tEXt chunks via PIL info\n",
    "    try:\n",
    "      im = Image.open(fn)\n",
    "      info = im.info\n",
    "      keys = list(info.keys())\n",
    "      if keys:\n",
    "        print('Image info keys:', keys)\n",
    "      else:\n",
    "        print('No textual PNG info keys found')\n",
    "\n",
    "      # Search textual info for JSON or base64-encoded workflows\n",
    "      for k,v in info.items():\n",
    "        s = str(v)\n",
    "        # heuristics: look for 'Comfy' or '{\"nodes' or long base64\n",
    "        if 'Comfy' in s or '{\"nodes' in s or re.search(r'^[A-Za-z0-9+/=\\n]{200,}$', s):\n",
    "          print('Candidate workflow text in PNG info key', k)\n",
    "          cand = s\n",
    "          # if base64, try decode\n",
    "          try:\n",
    "            if re.match(r'^[A-Za-z0-9+/=\\n]+$', cand.strip()):\n",
    "              dec = base64.b64decode(cand)\n",
    "              try:\n",
    "                j = json.loads(dec.decode('utf-8'))\n",
    "                outp = OUT_DIR/f'extracted_{Path(url).stem}_{count}.json'\n",
    "                outp.write_text(json.dumps(j, indent=2))\n",
    "                extracted.append(str(outp))\n",
    "                print('Extracted JSON saved to', outp)\n",
    "              except Exception:\n",
    "                # not JSON after decode\n",
    "                pass\n",
    "          except Exception:\n",
    "            pass\n",
    "\n",
    "    except Exception as e:\n",
    "      print('Failed to inspect image via PIL:', e)\n",
    "\n",
    "    # Fallback: search surrounding HTML for long base64 or JSON blobs\n",
    "    parent_html = str(img.parent)\n",
    "    m = re.search(r'([A-Za-z0-9+/=\\n]{200,})', parent_html)\n",
    "    if m:\n",
    "      cand = m.group(1)\n",
    "      try:\n",
    "        dec = base64.b64decode(cand)\n",
    "        j = json.loads(dec.decode('utf-8'))\n",
    "        outp = OUT_DIR/f'extracted_{Path(url).stem}_{count}_html.json'\n",
    "        outp.write_text(json.dumps(j, indent=2))\n",
    "        extracted.append(str(outp))\n",
    "        print('Extracted JSON from surrounding HTML to', outp)\n",
    "      except Exception:\n",
    "        pass\n",
    "\n",
    "  if count == 0:\n",
    "    print('No candidate showcase images downloaded for this page — it may be gated or use JS rendering.')\n",
    "\n",
    "print('\\nExtraction complete — found', len(extracted), 'candidate workflows (saved to DRIVE_ROOT/flows/extracted_images)')\n",
    "for p in extracted:\n",
    "  print('-', p)\n",
    "\n",
    "print('\\nReminder: NSFW or gated pages may require a logged-in session; set CIVITAI_API_TOKEN or download images manually then run the local extractor on those images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4550a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Manifest resolver (follow redirects, capture filenames) — run after setting CIVITAI_API_TOKEN\n",
    "\"\"\"\n",
    "This cell reads the manifest saved at DRIVE_ROOT/manifests/civitai_model_manifests.json,\n",
    "performs a HEAD/GET to the API download URL (with CIVITAI token), follows redirects,\n",
    "and extracts the final filename from Content-Disposition if present.\n",
    "It updates the manifest with 'resolved_filename' and 'resolved_url' fields for each model.\n",
    "\n",
    "Note: run this only after mounting Drive and setting CIVITAI_API_TOKEN via the secure input cell.\n",
    "\"\"\"\n",
    "import os, requests, json\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_FILE = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "if not MANIFEST_FILE.exists():\n",
    "    print('Manifest file not found at', MANIFEST_FILE)\n",
    "else:\n",
    "    with open(MANIFEST_FILE,'r') as f:\n",
    "        manifest = json.load(f)\n",
    "\n",
    "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "    if not token:\n",
    "        print('CIVITAI_API_TOKEN not set. Use the secure input cell to set it for this session.')\n",
    "    else:\n",
    "        s = requests.Session()\n",
    "        s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "        updated = False\n",
    "        for mid, entry in manifest.items():\n",
    "            url = entry.get('download_url')\n",
    "            if not url:\n",
    "                print('No download_url for', mid)\n",
    "                continue\n",
    "            # substitute token placeholder if present\n",
    "            url = url.replace('$CIVITAI_API_TOKEN', token)\n",
    "            print('\\nResolving model', mid, '...')\n",
    "            try:\n",
    "                # Try HEAD first\n",
    "                r = s.head(url, allow_redirects=True, timeout=20)\n",
    "                if r.status_code >= 400:\n",
    "                    # try GET with stream to inspect headers\n",
    "                    r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
    "                    r.close()\n",
    "                # final URL after redirects\n",
    "                final_url = r.url\n",
    "                cd = r.headers.get('Content-Disposition','')\n",
    "                filename = None\n",
    "                if cd:\n",
    "                    m = re.search(r'filename\\*=UTF-8''(.+)|filename=\"?([^\";]+)\"?', cd)\n",
    "                    if m:\n",
    "                        filename = m.group(1) or m.group(2)\n",
    "                # fallback: try last path segment\n",
    "                if not filename:\n",
    "                    filename = final_url.split('/')[-1].split('?')[0]\n",
    "                entry['resolved_url'] = final_url\n",
    "                entry['resolved_filename'] = filename\n",
    "                print('Resolved:', filename)\n",
    "                updated = True\n",
    "            except Exception as e:\n",
    "                print('Failed to resolve', mid, e)\n",
    "\n",
    "        if updated:\n",
    "            MANIFEST_FILE.write_text(json.dumps(manifest, indent=2))\n",
    "            print('\\nManifest updated with resolved filenames at', MANIFEST_FILE)\n",
    "        else:\n",
    "            print('\\nNo updates applied to manifest.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf14062",
   "metadata": {},
   "source": [
    "## Manifest resolver & validation\n",
    "\n",
    "This mini-section adds a safe resolver that—when you run it in Colab after mounting Drive and setting `CIVITAI_API_TOKEN`—will:\n",
    "\n",
    "- Read `DRIVE_ROOT/manifests/civitai_model_manifests.json`.\n",
    "- For each manifest entry, perform a HEAD or GET with `allow_redirects=True` to follow the Civitai redirect and inspect the `Content-Disposition` header (the API typically redirects to the actual file URL and provides a filename).\n",
    "- Save the resolved filename and a final download URL into the manifest file as `resolved_filename` and `resolved_url` for each model.\n",
    "\n",
    "Run the resolver only in a session where you have set `CIVITAI_API_TOKEN` using the secure token cell. The resolver will not download the whole files — it follows redirects and inspects headers only (uses `stream=True` and closes the connection quickly).\n",
    "\n",
    "Security note: do not paste your token into this notebook's plaintext cells; use the secure input cell instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2251532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Per-model manifest parsing & download templates (guarded)\n",
    "\"\"\"\n",
    "Create a manifest of the provided Civitai model download URLs with probable file formats,\n",
    "recommended target directories, and guarded download commands that require\n",
    "CIVITAI_API_TOKEN to be set (use the secure token cell earlier).\n",
    "\n",
    "Run this cell after mounting Drive and setting CIVITAI_API_TOKEN (via the secure cell).\n",
    "\"\"\"\n",
    "import re, os, json\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_DIR = Path(DRIVE_ROOT)/'manifests'\n",
    "MANIFEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# List of URLs the user provided (de-duplicated)\n",
    "urls = [\n",
    "  'https://civitai.com/api/download/models/443821',\n",
    "  'https://civitai.com/api/download/models/1624818',\n",
    "  'https://civitai.com/api/download/models/1741501',\n",
    "  'https://civitai.com/api/download/models/2048863',\n",
    "  'https://civitai.com/api/download/models/2004155',\n",
    "  'https://civitai.com/api/download/models/2031069',\n",
    "  'https://civitai.com/api/download/models/1476909',\n",
    "  'https://civitai.com/api/download/models/1855263',\n",
    "  'https://civitai.com/api/download/models/1874153',\n",
    "  'https://civitai.com/api/download/models/1331682',\n",
    "  'https://civitai.com/api/download/models/15003',\n",
    "  'https://civitai.com/api/download/models/6424',\n",
    "  'https://civitai.com/api/download/models/1307155'\n",
    "]\n",
    "\n",
    "# Heuristics / prior knowledge mapping (from earlier notes and typical usage)\n",
    "# Use conservative guesses; if you know exact file names/formats update the manifest manually.\n",
    "format_suggestions = {\n",
    "  443821: {'formats':['SafeTensor'], 'target_dir':'{MODELS_DIR}/cyberrealistic'},\n",
    "  1624818: {'formats':['SafeTensor'], 'target_dir':'{LORAS_DIR}'},\n",
    "  1741501: {'formats':['SafeTensor'], 'target_dir':'{MODELS_DIR}/wan'},\n",
    "  2048863: {'formats':['GGUF','SafeTensor'], 'target_dir':'{GGUF_DIR}'},\n",
    "  2004155: {'formats':['SafeTensor','LoRA'], 'target_dir':'{LORAS_DIR}'},\n",
    "  2031069: {'formats':['GGUF','SafeTensor'], 'target_dir':'{GGUF_DIR}'},\n",
    "  1476909: {'formats':['SafeTensor'], 'target_dir':'{LORAS_DIR}'},\n",
    "  1855263: {'formats':['GGUF'], 'target_dir':'{GGUF_DIR}'},\n",
    "  1874153: {'formats':['GGUF'], 'target_dir':'{GGUF_DIR}'},\n",
    "  1331682: {'formats':['GGUF'], 'target_dir':'{GGUF_DIR}'},\n",
    "  15003: {'formats':['SafeTensor'], 'target_dir':'{MODELS_DIR}/cyberrealistic'},\n",
    "  6424: {'formats':['SafeTensor'], 'target_dir':'{MODELS_DIR}/chilloutmix'},\n",
    "  1307155: {'formats':['GGUF','SafeTensor'], 'target_dir':'{GGUF_DIR}'},\n",
    "}\n",
    "\n",
    "manifest = {}\n",
    "for u in urls:\n",
    "  m = re.search(r'/models/(\\d+)', u)\n",
    "  if not m:\n",
    "    continue\n",
    "  mid = int(m.group(1))\n",
    "  entry = {}\n",
    "  entry['model_id'] = mid\n",
    "  entry['download_url'] = u + '?CIVITAI_TOKEN=$CIVITAI_API_TOKEN'\n",
    "  sugg = format_suggestions.get(mid, None)\n",
    "  if sugg:\n",
    "    entry['suggested_formats'] = sugg['formats']\n",
    "    entry['recommended_dir_template'] = sugg['target_dir']\n",
    "  else:\n",
    "    entry['suggested_formats'] = ['SafeTensor','GGUF','Checkpoint','LoRA']\n",
    "    entry['recommended_dir_template'] = '{MODELS_DIR}'\n",
    "  # guarded wget template (comment before running) — you must set CIVITAI_API_TOKEN first\n",
    "  entry['download_template'] = f\"# !wget \\\"{entry['download_url']}\\\" --content-disposition -P \\\"{entry['recommended_dir_template']}\\\"\"\n",
    "  entry['notes'] = 'Set CIVITAI_API_TOKEN via the secure input cell and review the model page for NSFW gating or special instructions. If API returns a redirect or login-required, download via browser and upload to Drive.'\n",
    "  manifest[str(mid)] = entry\n",
    "\n",
    "# Save manifest JSON to Drive\n",
    "outp = MANIFEST_DIR/'civitai_model_manifests.json'\n",
    "outp.write_text(json.dumps(manifest, indent=2))\n",
    "print('Wrote manifest for', len(manifest), 'models to', outp)\n",
    "\n",
    "# Print a concise table for quick review\n",
    "for k,v in manifest.items():\n",
    "  print(f\"- Model {k}: suggested formats={v['suggested_formats']}, dir={v['recommended_dir_template']}\")\n",
    "  print('  Download template (commented):')\n",
    "  print('  ', v['download_template'])\n",
    "\n",
    "print('\\nReminder: uncomment and run the download_template commands only after setting CIVITAI_API_TOKEN with the secure token cell and verifying you have permission to download these models.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Collected and extracted workflows index\n",
    "# Lists any workflow JSONs extracted by the \"Extract workflows from showcase images\" cell\n",
    "from pathlib import Path\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "EX_DIR = Path(DRIVE_ROOT)/'flows'/'extracted_images'\n",
    "EX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "files = sorted([str(p) for p in EX_DIR.glob('*.json')])\n",
    "print('Found', len(files), 'extracted workflow JSON files in', EX_DIR)\n",
    "for f in files:\n",
    "    print('-', f)\n",
    "\n",
    "# If you have local images with embedded flows you want to inspect, upload them to Drive and re-run the extractor cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b47a9f1",
   "metadata": {},
   "source": [
    "### Public URL view and stop-tunnel helper\n",
    "Use the cell below to display the public Cloudflare URL and to stop the cloudflared process started in this session. Note: Stopping the process will close remote access to the ComfyUI GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44cf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Display public URL and stop cloudflared tunnel\n",
    "import os, signal, psutil\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "url = os.environ.get('COMFYUI_PUBLIC_URL','')\n",
    "print('Public URL:', url)\n",
    "\n",
    "def stop_cloudflared():\n",
    "  # find cloudflared process and terminate it\n",
    "  for p in psutil.process_iter(['pid','name','cmdline']):\n",
    "    try:\n",
    "      if 'cloudflared' in ' '.join(p.info.get('cmdline', [])):\n",
    "        print('Killing cloudflared PID', p.info['pid'])\n",
    "        p.kill()\n",
    "    except Exception:\n",
    "      continue\n",
    "\n",
    "display(HTML(\"<button onclick=\\\"google.colab.kernel.invokeFunction('notebook.stop_cloudflared', [], {})\\\">Stop cloudflared</button>\"))\n",
    "\n",
    "# register a callable so the button can call stop_cloudflared in Colab environments\n",
    "from google.colab import output\n",
    "output.register_callback('notebook.stop_cloudflared', stop_cloudflared)\n",
    "print('Stop button registered (Colab only)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df85decc",
   "metadata": {},
   "source": [
    "### Persistent runner example for remote VMs\n",
    "This cell shows an example `nohup`/`tmux` pattern you can run on a persistent VM to keep a `wan2_runner.py` or similar runner alive independent of Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Persistent runner example (bash commands for remote VM)\n",
    "\n",
    "# On a persistent VM (Ubuntu), save this script as run_wan2_runner.sh and run with nohup or inside tmux/screen\n",
    "# Example contents for run_wan2_runner.sh:\n",
    "script = r\"\"\"\n",
    "#!/usr/bin/env bash\n",
    "cd $DRIVE_ROOT\n",
    "# activate your python env or conda\n",
    "source ~/venv/bin/activate\n",
    "# Run the wan2 runner in background and log stdout/stderr\n",
    "nohup python wan2_runner.py --watch_dir \"$DRIVE_ROOT/wan2_jobs\" > wan2_runner.log 2>&1 &\n",
    "\"\"\"\n",
    "print(script)\n",
    "print('Save the script on your VM, make it executable and run it inside tmux or via systemd for production.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c573c9",
   "metadata": {},
   "source": [
    "### Model download test (safe sample)\n",
    "This cell demonstrates a guarded download: it runs only if `CIVITAI_API_TOKEN` is set and will download a small, non-NSFW sample model or asset. Update the `MODEL_ID` if you want a specific allowed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Model download test (requires CIVITAI_API_TOKEN)\n",
    "import os, subprocess\n",
    "from pathlib import Path\n",
    "MODEL_ID = 6424  # example: ChilloutMix (public blended), replace if you have another public allowed id\n",
    "if not os.environ.get('CIVITAI_API_TOKEN'):\n",
    "  print('CIVITAI_API_TOKEN not set — skipping download test')\n",
    "else:\n",
    "  L = Path(GGUF_DIR)\n",
    "  L.mkdir(parents=True, exist_ok=True)\n",
    "  url = f\"https://civitai.com/api/download/models/{MODEL_ID}?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN={os.environ.get('CIVITAI_API_TOKEN')}\"\n",
    "  print('Downloading to', L)\n",
    "  subprocess.run(['wget', '-q', '-O', str(L/f'model_{MODEL_ID}.safetensors'), url], check=True)\n",
    "  print('Download attempted — check', L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c5781",
   "metadata": {},
   "source": [
    "### Model-specific workflow templates (WAN models)\n",
    "Below are templates you can copy into new cells and adapt per model: T2V chains, I2V setups, and LORA generator flows. They are intentionally high-level so you can tweak scheduler/denoising parameters per model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23513dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title T2V chain template (WAN models) — adapt and run per model\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "\n",
    "# Use shared endpoint/header vars for optional remote submits\n",
    "COMFYUI_API_BASE = globals().get('COMFYUI_API_BASE', 'http://127.0.0.1:8188')\n",
    "COMFYUI_API_KEY = globals().get('COMFYUI_API_KEY', os.environ.get('COMFYUI_API_KEY',''))\n",
    "HEADERS = globals().get('HEADERS', {})\n",
    "if COMFYUI_API_KEY:\n",
    "    globals()['USE_COMFYUI_API'] = True\n",
    "\n",
    "# Reminder: run the Endpoint helper and Cell 1 health-check before using this demo\n",
    "print('Reminder: run the Endpoint & Health-check helper and the ComfyUI health-check (Cell 1) before running demos')\n",
    "\n",
    "job = {\n",
    "  'type': 't2v',\n",
    "  'model': 'wan2-14b.gguf',\n",
    "  'prompt': 'A dramatic fly-through of a neon city at dusk',\n",
    "  'frames': 48,\n",
    "  'steps_per_frame': 12,\n",
    "  'sampler': 'ddim',\n",
    "}\n",
    "Path(ARTIFACTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "jobfile = Path(ARTIFACTS_DIR)/'t2v_wan_job.json'\n",
    "jobfile.write_text(json.dumps(job, indent=2))\n",
    "print('T2V job written to', jobfile)\n",
    "print('Drop into', Path(DRIVE_ROOT)/'wan2_jobs' , 'or run your wan2 runner on your VM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title I2V template (use an initial image and a model) — adapt per model\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "\n",
    "# Use shared endpoint values for any remote calls\n",
    "COMFYUI_API_BASE = globals().get('COMFYUI_API_BASE', 'http://127.0.0.1:8188')\n",
    "COMFYUI_API_KEY = globals().get('COMFYUI_API_KEY', os.environ.get('COMFYUI_API_KEY',''))\n",
    "HEADERS = globals().get('HEADERS', {})\n",
    "if COMFYUI_API_KEY:\n",
    "    globals()['USE_COMFYUI_API'] = True\n",
    "\n",
    "# Reminder: run the Endpoint helper and Cell 1 health-check before using this demo\n",
    "print('Reminder: run the Endpoint & Health-check helper and the ComfyUI health-check (Cell 1) before running demos')\n",
    "\n",
    "job = {\n",
    "  'type': 'i2v',\n",
    "  'model': 'wan2-14b.gguf',\n",
    "  'init_image': str(Path(ARTIFACTS_DIR)/'seed_input.png'),\n",
    "  'frames': 32,\n",
    "  'strength': 0.8,\n",
    "  'steps_per_frame': 10\n",
    "}\n",
    "jobfile = Path(ARTIFACTS_DIR)/'i2v_wan_job.json'\n",
    "jobfile.write_text(json.dumps(job, indent=2))\n",
    "print('I2V job written to', jobfile)\n",
    "\n",
    "# Example guarded remote submit (uncomment to use):\n",
    "# if COMFYUI_API_BASE:\n",
    "#   import requests\n",
    "#   r = requests.post(COMFYUI_API_BASE + '/api/wan2/jobs', json=job, headers=HEADERS)\n",
    "#   print('Posted job, response', r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6caaf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title LORA generator flow template\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "\n",
    "# Shared endpoint/header vars for optional remote ops\n",
    "COMFYUI_API_BASE = globals().get('COMFYUI_API_BASE', 'http://127.0.0.1:8188')\n",
    "COMFYUI_API_KEY = globals().get('COMFYUI_API_KEY', os.environ.get('COMFYUI_API_KEY',''))\n",
    "HEADERS = globals().get('HEADERS', {})\n",
    "if COMFYUI_API_KEY:\n",
    "    globals()['USE_COMFYUI_API'] = True\n",
    "\n",
    "# Reminder: run the Endpoint helper and Cell 1 health-check before using this demo\n",
    "print('Reminder: run the Endpoint & Health-check helper and the ComfyUI health-check (Cell 1) before running demos')\n",
    "\n",
    "job = {\n",
    "  'type': 'lora_train_prepare',\n",
    "  'base_model': 'cyberrealistic.safetensors',\n",
    "  'loras_to_apply': ['loraA.safetensors', 'loraB.safetensors'],\n",
    "  'weights': [0.7, 0.3],\n",
    "  'output_name': 'combo_lora.safetensors'\n",
    "}\n",
    "jobfile = Path(LORAS_DIR)/'lora_prep.json'\n",
    "jobfile.write_text(json.dumps(job, indent=2))\n",
    "print('LORA prep job saved to', jobfile)\n",
    "print('Use your kohya runner or LORA blend tool to apply these weights')\n",
    "\n",
    "# Example guarded API call to remote LORA service (if available):\n",
    "# if COMFYUI_API_BASE:\n",
    "#   import requests\n",
    "#   r = requests.post(COMFYUI_API_BASE + '/api/lora/apply', json=job, headers=HEADERS)\n",
    "#   print('Response', r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7328359b",
   "metadata": {},
   "source": [
    "## GPU & Runtime Guidance\n",
    "\n",
    "Recommended runtime choices and why:\n",
    "\n",
    "- Preferred environment: a persistent VM (Ubuntu) with a matching NVIDIA driver and CUDA 12.x for stability and reusability. Colab is convenient for short tests but sessions are ephemeral.\n",
    "- PyTorch wheel must match the runtime CUDA version. The install cell tries CUDA 12.1 -> 12.2 -> CPU wheels automatically. If this fails, pick the correct wheel manually from https://download.pytorch.org/whl/.\n",
    "- Keep a wheel cache in Drive: `DRIVE_ROOT/ComfyUI/wheel_cache`. This avoids re-downloading large binary wheels between sessions.\n",
    "- xFormers is optional. Try installing it for performance improvements; if it fails, ComfyUI still runs without it.\n",
    "- Use the venv-in-Drive pattern (the notebook creates `DRIVE_ROOT/ComfyUI/venv`) so you can start ComfyUI with the venv python and not change the Jupyter kernel.\n",
    "\n",
    "Quick tips:\n",
    "- If you need persistent long-running jobs (training or long renders), run them on a VM and use the Drive-mounted folder or an object store for artifacts.\n",
    "- When in doubt about CUDA/PyTorch compatibility, run the health-check cell after starting ComfyUI and inspect `torch.__version__` and `torch.version.cuda` inside the venv.\n",
    "\n",
    "Where to look:\n",
    "- Wheel cache: `DRIVE_ROOT/ComfyUI/wheel_cache`\n",
    "- Venv python: `DRIVE_ROOT/ComfyUI/venv/bin/python`\n",
    "- ComfyUI run command example (printed by the install cell):\n",
    "\n",
    "```bash\n",
    "/content/drive/MyDrive/ComfyUI/venv/bin/python /content/drive/MyDrive/ComfyUI/main.py --headless --port 8188\n",
    "```\n",
    "\n",
    "If you want, I can add an automated check that prints the venv's `torch.version.cuda` after install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0398e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cache warmup — prefetch torch wheel into Drive wheel_cache (optional)\n",
    "# This cell attempts to download the first available torch wheel into the DRIVE wheel cache\n",
    "# without installing it into the venv. It helps warm the cache for repeated sessions.\n",
    "import os, subprocess, sys\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT', '/content/drive/MyDrive/ComfyUI')\n",
    "WHEEL_CACHE = Path(DRIVE_ROOT)/'ComfyUI'/'wheel_cache'\n",
    "WHEEL_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "candidates = [\n",
    "    ('cu121', 'https://download.pytorch.org/whl/cu121'),\n",
    "    ('cu122', 'https://download.pytorch.org/whl/cu122'),\n",
    "    ('cpu', 'https://download.pytorch.org/whl/cpu'),\n",
    "]\n",
    "\n",
    "print('Prefetching: checking candidates to download a torch wheel into', WHEEL_CACHE)\n",
    "for tag, index in candidates:\n",
    "    try:\n",
    "        print('Attempting to download torch wheel for', tag)\n",
    "        # Use pip download to fetch wheels into cache\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'download', 'torch', 'torchvision', 'torchaudio', '--index-url', index, '--dest', str(WHEEL_CACHE)])\n",
    "        print('Downloaded wheels for', tag)\n",
    "        break\n",
    "    except subprocess.CalledProcessError:\n",
    "        print('Failed to download wheels for', tag, '- trying next')\n",
    "\n",
    "print('Cache warmup complete — check', WHEEL_CACHE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84940a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Venv pip-list verification (shows installed packages in Drive venv)\n",
    "import subprocess, sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT', '/content/drive/MyDrive/ComfyUI')\n",
    "PY = Path(DRIVE_ROOT)/'ComfyUI'/'venv'/'bin'/'python'\n",
    "if PY.exists():\n",
    "    print('Venv python found at', PY)\n",
    "    subprocess.run([str(PY), '-m', 'pip', 'list'])\n",
    "else:\n",
    "    print('Venv python not found — run the install cell first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2422ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Interactive download runner (single model) — guarded and resumable\n",
    "\"\"\"\n",
    "Two-step UI: pick a model from the manifest, preview the resolved filename and size,\n",
    "then confirm to stream-download the file into the suggested directory. Requires\n",
    "CIVITAI_API_TOKEN set by the secure input cell.\n",
    "\"\"\"\n",
    "import os, json, re, requests, math\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "\n",
    "def load_manifest():\n",
    "    if not MANIFEST_PATH.exists():\n",
    "        return {}\n",
    "    return json.loads(MANIFEST_PATH.read_text())\n",
    "\n",
    "manifest = load_manifest()\n",
    "if not manifest:\n",
    "    print('No manifest found at', MANIFEST_PATH)\n",
    "else:\n",
    "    options = []\n",
    "    for k,v in sorted(manifest.items(), key=lambda x:int(x[0])):\n",
    "        label = f\"{k}: {v.get('suggested_formats')}\"\n",
    "        if v.get('resolved_filename'):\n",
    "            label += f\" -> {v.get('resolved_filename')}\"\n",
    "        options.append((label,k))\n",
    "\n",
    "    dropdown = widgets.Dropdown(options=options, description='Model:')\n",
    "    preview_btn = widgets.Button(description='Preview')\n",
    "    confirm_btn = widgets.Button(description='Confirm & Download', button_style='danger')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def expand_dir_template(tpl):\n",
    "        # replace placeholders with notebook globals\n",
    "        mapping = {\n",
    "            '{MODELS_DIR}': globals().get('MODELS_DIR', str(Path(DRIVE_ROOT)/'models')),\n",
    "            '{LORAS_DIR}': globals().get('LORAS_DIR', str(Path(DRIVE_ROOT)/'models'/'loras')),\n",
    "            '{GGUF_DIR}': globals().get('GGUF_DIR', str(Path(DRIVE_ROOT)/'models'/'gguf')),\n",
    "            '{ARTIFACTS_DIR}': globals().get('ARTIFACTS_DIR', str(Path(DRIVE_ROOT)/'artifacts')),\n",
    "        }\n",
    "        for k,v in mapping.items():\n",
    "            tpl = tpl.replace(k, v)\n",
    "        return tpl\n",
    "\n",
    "    current_preview = {'mid':None, 'entry':None, 'final_url':None, 'filename':None, 'size':None}\n",
    "\n",
    "    def on_preview(b):\n",
    "        with out:\n",
    "            clear_output()\n",
    "            mid = dropdown.value\n",
    "            entry = manifest.get(str(mid))\n",
    "            if not entry:\n",
    "                print('Manifest entry not found for', mid)\n",
    "                return\n",
    "            token = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "            if not token:\n",
    "                print('CIVITAI_API_TOKEN not set. Run the secure token cell first.')\n",
    "                return\n",
    "            url = entry.get('download_url','').replace('$CIVITAI_API_TOKEN', token)\n",
    "            print('Resolving URL (following redirects)...')\n",
    "            s = requests.Session()\n",
    "            s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "            try:\n",
    "                r = s.head(url, allow_redirects=True, timeout=20)\n",
    "                if r.status_code >= 400:\n",
    "                    r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
    "                    r.close()\n",
    "                final_url = r.url\n",
    "                cd = r.headers.get('Content-Disposition','')\n",
    "                filename = None\n",
    "                if cd:\n",
    "                    m = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
    "                    if m:\n",
    "                        filename = m.group(1) or m.group(2)\n",
    "                if not filename:\n",
    "                    filename = final_url.split('/')[-1].split('?')[0]\n",
    "                size = r.headers.get('Content-Length')\n",
    "                if size:\n",
    "                    size = int(size)\n",
    "                else:\n",
    "                    size = None\n",
    "                print('Model', mid)\n",
    "                print('Final URL:', final_url)\n",
    "                print('Filename:', filename)\n",
    "                if size:\n",
    "                    mb = size/1024/1024\n",
    "                    print(f'Content-Length: {size} bytes ({mb:.1f} MB)')\n",
    "                    if mb > 2000:\n",
    "                        print('\\nWARNING: file is very large. Consider running on a VM with enough disk space.')\n",
    "                else:\n",
    "                    print('Content-Length header not present')\n",
    "                # store preview info for confirm\n",
    "                current_preview.update({'mid':mid, 'entry':entry, 'final_url':final_url, 'filename':filename, 'size':size})\n",
    "            except Exception as e:\n",
    "                print('Failed to preview URL:', e)\n",
    "\n",
    "    def on_confirm(b):\n",
    "        with out:\n",
    "            clear_output()\n",
    "            if not current_preview['mid']:\n",
    "                print('No preview available — run Preview first')\n",
    "                return\n",
    "            entry = current_preview['entry']\n",
    "            url = current_preview['final_url']\n",
    "            filename = current_preview['filename']\n",
    "            size = current_preview['size']\n",
    "            # determine download dir\n",
    "            tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
    "            target_dir = Path(expand_dir_template(tpl))\n",
    "            target_dir.mkdir(parents=True, exist_ok=True)\n",
    "            target_path = target_dir/filename\n",
    "            # Stream download\n",
    "            s = requests.Session()\n",
    "            s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "            print('Starting streaming download to', str(target_path))\n",
    "            try:\n",
    "                r = s.get(url, stream=True, timeout=30)\n",
    "                r.raise_for_status()\n",
    "                total = r.headers.get('Content-Length')\n",
    "                if total:\n",
    "                    total = int(total)\n",
    "                downloaded = 0\n",
    "                with open(target_path, 'wb') as fh:\n",
    "                    for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                        if chunk:\n",
    "                            fh.write(chunk)\n",
    "                            downloaded += len(chunk)\n",
    "                            if total:\n",
    "                                pct = downloaded/total*100\n",
    "                                print(f'\\rDownloaded {downloaded}/{total} bytes ({pct:.1f}%)', end='')\n",
    "                print('\\nDownload complete')\n",
    "                # update manifest\n",
    "                entry['downloaded_path'] = str(target_path)\n",
    "                manifest[str(current_preview['mid'])] = entry\n",
    "                MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
    "                print('Manifest updated with downloaded_path')\n",
    "            except Exception as e:\n",
    "                print('Download failed:', e)\n",
    "\n",
    "    preview_btn.on_click(on_preview)\n",
    "    confirm_btn.on_click(on_confirm)\n",
    "\n",
    "    display(dropdown, preview_btn, confirm_btn, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Manifest post-processor: infer formats from resolved filenames\n",
    "\"\"\"\n",
    "Reads the manifest, and for entries with 'resolved_filename' attempts to infer format\n",
    "(safetensor, gguf, checkpoint, lora) based on extension and updates manifest['inferred_format'].\n",
    "\"\"\"\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "\n",
    "if not MANIFEST_PATH.exists():\n",
    "    print('Manifest not found at', MANIFEST_PATH)\n",
    "else:\n",
    "    m = json.loads(MANIFEST_PATH.read_text())\n",
    "    changed = False\n",
    "    for mid, entry in m.items():\n",
    "        fn = entry.get('resolved_filename') or entry.get('downloaded_path')\n",
    "        if not fn:\n",
    "            continue\n",
    "        fn_lower = fn.lower()\n",
    "        fmt = None\n",
    "        if fn_lower.endswith('.safetensors'):\n",
    "            fmt = 'SafeTensor'\n",
    "        elif fn_lower.endswith('.gguf'):\n",
    "            fmt = 'GGUF'\n",
    "        elif fn_lower.endswith('.pth') or fn_lower.endswith('.pt') or fn_lower.endswith('.ckpt'):\n",
    "            fmt = 'Checkpoint'\n",
    "        elif fn_lower.endswith('.safetensors.pt'):\n",
    "            fmt = 'SafeTensor'\n",
    "        elif '.safetensors' in fn_lower:\n",
    "            fmt = 'SafeTensor'\n",
    "        elif fn_lower.endswith('.bin'):\n",
    "            # could be HF bin; leave generic\n",
    "            fmt = 'Binary'\n",
    "        elif fn_lower.endswith('.lora') or 'lora' in fn_lower:\n",
    "            fmt = 'LoRA'\n",
    "        if fmt and entry.get('inferred_format') != fmt:\n",
    "            entry['inferred_format'] = fmt\n",
    "            m[mid] = entry\n",
    "            changed = True\n",
    "            print('Inferred', fmt, 'for model', mid, '->', fn)\n",
    "    if changed:\n",
    "        MANIFEST_PATH.write_text(json.dumps(m, indent=2))\n",
    "        print('Manifest updated with inferred formats at', MANIFEST_PATH)\n",
    "    else:\n",
    "        print('No changes to manifest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8221f2",
   "metadata": {},
   "source": [
    "### Quick notes — interactive downloader\n",
    "\n",
    "- Use the secure CIVITAI token cell before attempting downloads.\n",
    "- Steps:\n",
    "  1. Run the manifest resolver cell to populate `resolved_filename` for each model (uses token).\n",
    "  2. Use the Interactive download runner to preview and confirm a single model download.\n",
    "  3. The runner streams the file into Drive and updates the manifest with `downloaded_path`.\n",
    "- If a model is gated beyond token access, download via browser and upload to Drive; then update the manifest manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04235b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Colab-friendly interactive downloader (uses google.colab widgets when available)\n",
    "\"\"\"\n",
    "This cell provides a Colab-optimized UI for the interactive download runner.\n",
    "It prefers Google Colab's native widget layer when available; otherwise it falls\n",
    "back to ipywidgets. Behavior is similar to the earlier interactive runner:\n",
    "- Select a model from manifest\n",
    "- Preview final filename/size\n",
    "- Confirm to download (stream into Drive)\n",
    "\n",
    "Run after mounting Drive and setting CIVITAI_API_TOKEN via the secure input cell.\n",
    "\"\"\"\n",
    "import os, json, re, requests\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "# UI imports (prefer google.colab widgets if available)\n",
    "use_colab_widgets = False\n",
    "try:\n",
    "    import google.colab.widgets as colab_widgets\n",
    "    from google.colab import output as colab_output\n",
    "    use_colab_widgets = True\n",
    "except Exception:\n",
    "    try:\n",
    "        import ipywidgets as widgets\n",
    "        from IPython.display import display, clear_output\n",
    "        use_colab_widgets = False\n",
    "    except Exception:\n",
    "        raise RuntimeError('No UI widget library available (need google.colab or ipywidgets)')\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "\n",
    "if not MANIFEST_PATH.exists():\n",
    "    print('Manifest not found at', MANIFEST_PATH)\n",
    "else:\n",
    "    manifest = json.loads(MANIFEST_PATH.read_text())\n",
    "    keys = sorted(manifest.keys(), key=lambda x:int(x))\n",
    "\n",
    "    def expand_dir_template(tpl):\n",
    "        mapping = {\n",
    "            '{MODELS_DIR}': globals().get('MODELS_DIR', str(Path(DRIVE_ROOT)/'models')),\n",
    "            '{LORAS_DIR}': globals().get('LORAS_DIR', str(Path(DRIVE_ROOT)/'models'/'loras')),\n",
    "            '{GGUF_DIR}': globals().get('GGUF_DIR', str(Path(DRIVE_ROOT)/'models'/'gguf')),\n",
    "            '{ARTIFACTS_DIR}': globals().get('ARTIFACTS_DIR', str(Path(DRIVE_ROOT)/'artifacts')),\n",
    "        }\n",
    "        for k,v in mapping.items():\n",
    "            tpl = tpl.replace(k, v)\n",
    "        return tpl\n",
    "\n",
    "    # Common preview & download functions\n",
    "    def resolve_preview(mid):\n",
    "        entry = manifest.get(str(mid))\n",
    "        token = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "        if not token:\n",
    "            return {'error':'CIVITAI_API_TOKEN not set'}\n",
    "        url = entry.get('download_url','').replace('$CIVITAI_API_TOKEN', token)\n",
    "        s = requests.Session()\n",
    "        s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "        try:\n",
    "            r = s.head(url, allow_redirects=True, timeout=20)\n",
    "            if r.status_code >= 400:\n",
    "                r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
    "                r.close()\n",
    "            final_url = r.url\n",
    "            cd = r.headers.get('Content-Disposition','')\n",
    "            filename = None\n",
    "            if cd:\n",
    "                m = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
    "                if m:\n",
    "                    filename = m.group(1) or m.group(2)\n",
    "            if not filename:\n",
    "                filename = final_url.split('/')[-1].split('?')[0]\n",
    "            size = r.headers.get('Content-Length')\n",
    "            if size:\n",
    "                size = int(size)\n",
    "            return {'final_url': final_url, 'filename': filename, 'size': size}\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "\n",
    "    def stream_download(final_url, target_path):\n",
    "        s = requests.Session()\n",
    "        s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "        r = s.get(final_url, stream=True, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        downloaded = 0\n",
    "        total = r.headers.get('Content-Length')\n",
    "        if total:\n",
    "            total = int(total)\n",
    "        with open(target_path, 'wb') as fh:\n",
    "            for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                if chunk:\n",
    "                    fh.write(chunk)\n",
    "                    downloaded += len(chunk)\n",
    "        return target_path\n",
    "\n",
    "    # Build UI depending on environment\n",
    "    if use_colab_widgets:\n",
    "        # very small colab-friendly UI using simple text inputs and buttons\n",
    "        options = [(f\"{k}  -> {manifest[k].get('resolved_filename','?')}\", k) for k in keys]\n",
    "        dd = colab_widgets.Dropdown(options=options, description='Model')\n",
    "        preview_btn = colab_widgets.Button(description='Preview')\n",
    "        download_btn = colab_widgets.Button(description='Confirm & Download')\n",
    "        status_area = colab_widgets.Textarea(value='Ready', description='Status', layout={'width':'100%'})\n",
    "\n",
    "        def on_preview(widget, event=None):\n",
    "            mid = dd.value\n",
    "            status_area.value = 'Resolving...'\n",
    "            res = resolve_preview(mid)\n",
    "            if 'error' in res:\n",
    "                status_area.value = 'Error: ' + res['error']\n",
    "            else:\n",
    "                size = res['size']\n",
    "                stext = f\"Filename: {res['filename']}\\nURL: {res['final_url']}\\n\"\n",
    "                if size:\n",
    "                    stext += f\"Size: {size} bytes ({size/1024/1024:.1f} MB)\\n\"\n",
    "                status_area.value = stext\n",
    "                # stash preview info in widget attrs\n",
    "                dd._preview = res\n",
    "\n",
    "        def on_download(widget, event=None):\n",
    "            if not hasattr(dd, '_preview'):\n",
    "                status_area.value = 'Run Preview first'\n",
    "                return\n",
    "            res = dd._preview\n",
    "            filename = res['filename']\n",
    "            final_url = res['final_url']\n",
    "            entry = manifest.get(str(dd.value))\n",
    "            tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
    "            target_dir = Path(expand_dir_template(tpl))\n",
    "            target_dir.mkdir(parents=True, exist_ok=True)\n",
    "            target_path = target_dir/filename\n",
    "            status_area.value = f'Starting download to {target_path}\\n'\n",
    "            try:\n",
    "                stream_download(final_url, str(target_path))\n",
    "                status_area.value += 'Download complete\\nComputing SHA256...'\n",
    "                # compute sha256\n",
    "                h = hashlib.sha256()\n",
    "                with open(target_path, 'rb') as fh:\n",
    "                    for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
    "                        h.update(chunk)\n",
    "                sha = h.hexdigest()\n",
    "                entry['downloaded_path'] = str(target_path)\n",
    "                entry['sha256'] = sha\n",
    "                entry['file_size_bytes'] = target_path.stat().st_size\n",
    "                manifest[str(dd.value)] = entry\n",
    "                MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
    "                status_area.value += f\"\\nSHA256: {sha}\\nSaved and manifest updated.\"\n",
    "            except Exception as e:\n",
    "                status_area.value += '\\nDownload failed: ' + str(e)\n",
    "\n",
    "        preview_btn.on_click(lambda w: on_preview(w))\n",
    "        download_btn.on_click(lambda w: on_download(w))\n",
    "        display(dd, preview_btn, download_btn, status_area)\n",
    "\n",
    "    else:\n",
    "        # fallback to ipywidgets UI (previous behavior)\n",
    "        import ipywidgets as widgets\n",
    "        from IPython.display import display, clear_output\n",
    "        options = []\n",
    "        for k in keys:\n",
    "            label = f\"{k}: {manifest[k].get('suggested_formats')}\"\n",
    "            if manifest[k].get('resolved_filename'):\n",
    "                label += f\" -> {manifest[k].get('resolved_filename')}\"\n",
    "            options.append((label,k))\n",
    "        dropdown = widgets.Dropdown(options=options, description='Model:')\n",
    "        preview_btn = widgets.Button(description='Preview')\n",
    "        confirm_btn = widgets.Button(description='Confirm & Download', button_style='danger')\n",
    "        out = widgets.Output()\n",
    "\n",
    "        current_preview = {'mid':None, 'entry':None, 'final_url':None, 'filename':None, 'size':None}\n",
    "\n",
    "        def on_preview(b):\n",
    "            with out:\n",
    "                clear_output()\n",
    "                mid = dropdown.value\n",
    "                entry = manifest.get(str(mid))\n",
    "                if not entry:\n",
    "                    print('Manifest entry not found for', mid)\n",
    "                    return\n",
    "                token = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "                if not token:\n",
    "                    print('CIVITAI_API_TOKEN not set. Run the secure token cell first.')\n",
    "                    return\n",
    "                url = entry.get('download_url','').replace('$CIVITAI_API_TOKEN', token)\n",
    "                print('Resolving URL (following redirects)...')\n",
    "                s = requests.Session()\n",
    "                s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "                try:\n",
    "                    r = s.head(url, allow_redirects=True, timeout=20)\n",
    "                    if r.status_code >= 400:\n",
    "                        r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
    "                        r.close()\n",
    "                    final_url = r.url\n",
    "                    cd = r.headers.get('Content-Disposition','')\n",
    "                    filename = None\n",
    "                    if cd:\n",
    "                        m = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
    "                        if m:\n",
    "                            filename = m.group(1) or m.group(2)\n",
    "                    if not filename:\n",
    "                        filename = final_url.split('/')[-1].split('?')[0]\n",
    "                    size = r.headers.get('Content-Length')\n",
    "                    if size:\n",
    "                        size = int(size)\n",
    "                    print('Model', mid)\n",
    "                    print('Final URL:', final_url)\n",
    "                    print('Filename:', filename)\n",
    "                    if size:\n",
    "                        mb = size/1024/1024\n",
    "                        print(f'Content-Length: {size} bytes ({mb:.1f} MB)')\n",
    "                    else:\n",
    "                        print('Content-Length header not present')\n",
    "                    current_preview.update({'mid':mid, 'entry':entry, 'final_url':final_url, 'filename':filename, 'size':size})\n",
    "                except Exception as e:\n",
    "                    print('Failed to preview URL:', e)\n",
    "\n",
    "        def on_confirm(b):\n",
    "            with out:\n",
    "                clear_output()\n",
    "                if not current_preview['mid']:\n",
    "                    print('No preview available — run Preview first')\n",
    "                    return\n",
    "                entry = current_preview['entry']\n",
    "                url = current_preview['final_url']\n",
    "                filename = current_preview['filename']\n",
    "                tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
    "                target_dir = Path(expand_dir_template(tpl))\n",
    "                target_dir.mkdir(parents=True, exist_ok=True)\n",
    "                target_path = target_dir/filename\n",
    "                print('Starting streaming download to', str(target_path))\n",
    "                try:\n",
    "                    r = requests.get(url, stream=True, timeout=30)\n",
    "                    r.raise_for_status()\n",
    "                    with open(target_path, 'wb') as fh:\n",
    "                        for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                            if chunk:\n",
    "                                fh.write(chunk)\n",
    "                    print('Download complete — computing SHA256...')\n",
    "                    # compute sha256\n",
    "                    h = hashlib.sha256()\n",
    "                    with open(target_path, 'rb') as fh:\n",
    "                        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
    "                            h.update(chunk)\n",
    "                    sha = h.hexdigest()\n",
    "                    entry['downloaded_path'] = str(target_path)\n",
    "                    entry['sha256'] = sha\n",
    "                    entry['file_size_bytes'] = target_path.stat().st_size\n",
    "                    manifest[str(current_preview['mid'])] = entry\n",
    "                    MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
    "                    print('SHA256:', sha)\n",
    "                    print('Manifest updated with downloaded_path and sha256')\n",
    "                except Exception as e:\n",
    "                    print('Download failed:', e)\n",
    "\n",
    "        preview_btn.on_click(on_preview)\n",
    "        confirm_btn.on_click(on_confirm)\n",
    "        display(dropdown, preview_btn, confirm_btn, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Post-download integrity checker & download summary\n",
    "\"\"\"\n",
    "Scans the manifest for entries with `downloaded_path`, computes/validates SHA256 if present,\n",
    "records any mismatches, and produces a simple download_summary.json with totals.\n",
    "Run after you have performed downloads with the interactive downloader.\n",
    "\"\"\"\n",
    "import json, os, hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "SUMMARY_PATH = Path(DRIVE_ROOT)/'manifests'/'download_summary.json'\n",
    "\n",
    "if not MANIFEST_PATH.exists():\n",
    "    print('Manifest not found at', MANIFEST_PATH)\n",
    "else:\n",
    "    manifest = json.loads(MANIFEST_PATH.read_text())\n",
    "    summary = {\n",
    "        'total_files': 0,\n",
    "        'total_bytes': 0,\n",
    "        'entries': {}\n",
    "    }\n",
    "    for mid,entry in manifest.items():\n",
    "        dp = entry.get('downloaded_path')\n",
    "        if not dp:\n",
    "            continue\n",
    "        p = Path(dp)\n",
    "        if not p.exists():\n",
    "            entry['download_status'] = 'missing'\n",
    "            manifest[mid] = entry\n",
    "            continue\n",
    "        size = p.stat().st_size\n",
    "        sha_expected = entry.get('sha256')\n",
    "        # compute sha\n",
    "        h = hashlib.sha256()\n",
    "        with open(p, 'rb') as fh:\n",
    "            for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
    "                h.update(chunk)\n",
    "        sha_actual = h.hexdigest()\n",
    "        ok = True\n",
    "        if sha_expected and sha_expected != sha_actual:\n",
    "            entry.setdefault('integrity',{})\n",
    "            entry['integrity']['expected_sha256'] = sha_expected\n",
    "            entry['integrity']['actual_sha256'] = sha_actual\n",
    "            entry['download_status'] = 'sha_mismatch'\n",
    "            ok = False\n",
    "        else:\n",
    "            entry.setdefault('integrity',{})\n",
    "            entry['integrity']['actual_sha256'] = sha_actual\n",
    "            entry['download_status'] = 'ok'\n",
    "        entry['file_size_bytes'] = size\n",
    "        manifest[mid] = entry\n",
    "\n",
    "        summary['total_files'] += 1\n",
    "        summary['total_bytes'] += size\n",
    "        summary['entries'][mid] = {\n",
    "            'path': str(p),\n",
    "            'size_bytes': size,\n",
    "            'sha256': sha_actual,\n",
    "            'status': entry.get('download_status')\n",
    "        }\n",
    "\n",
    "    MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
    "    SUMMARY_PATH.write_text(json.dumps(summary, indent=2))\n",
    "    print('Integrity check complete. Files:', summary['total_files'], 'Total bytes:', summary['total_bytes'])\n",
    "    print('Summary written to', SUMMARY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download summary UI — show totals and top N largest files\n",
    "\"\"\"\n",
    "Displays the download_summary.json created by the integrity checker in a friendly format.\n",
    "Shows total files, total size, and the top-N largest downloaded files.\n",
    "\"\"\"\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "SUMMARY_PATH = Path(DRIVE_ROOT)/'manifests'/'download_summary.json'\n",
    "\n",
    "if not SUMMARY_PATH.exists():\n",
    "    print('No download_summary.json found. Run the Post-download integrity checker cell first.')\n",
    "else:\n",
    "    data = json.loads(SUMMARY_PATH.read_text())\n",
    "    total_files = data.get('total_files',0)\n",
    "    total_bytes = data.get('total_bytes',0)\n",
    "    def human(n):\n",
    "        for u in ['B','KB','MB','GB','TB']:\n",
    "            if n < 1024:\n",
    "                return f\"{n:.2f}{u}\"\n",
    "            n /= 1024\n",
    "        return f\"{n:.2f}PB\"\n",
    "    print('Downloaded files:', total_files)\n",
    "    print('Total size:', human(total_bytes))\n",
    "    entries = data.get('entries',{})\n",
    "    items = []\n",
    "    for mid,info in entries.items():\n",
    "        size = info.get('size_bytes',0)\n",
    "        items.append((size, mid, info.get('path')))\n",
    "    items.sort(reverse=True)\n",
    "    topn = 10\n",
    "    print('\\nTop files:')\n",
    "    for i,(size, mid, path) in enumerate(items[:topn], start=1):\n",
    "        print(f\"{i}. {mid} — {human(size)} — {path}\")\n",
    "    if len(items) > topn:\n",
    "        print(f\"... and {len(items)-topn} more files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2298f92",
   "metadata": {},
   "source": [
    "# ComfyUI Colab Playground — Overview\n",
    "\n",
    "This notebook mounts Google Drive, installs ComfyUI into Drive, and provides a set of modular cells to:\n",
    "\n",
    "- Install and update ComfyUI (Drive-persistent venv and wheel cache).\n",
    "- Start ComfyUI and optionally expose it via cloudflared/localtunnel.\n",
    "- Resolve and safely download models (Civitai/HF) with a preview step.\n",
    "- Extract embedded ComfyUI flows from showcase images.\n",
    "- Provide example flows (T2I/I2I/T2V/I2V, multi-LoRA and kohya-ss scaffolds).\n",
    "\n",
    "New additions in this revision:\n",
    "\n",
    "- Batch manifest resolver that can be run in your Colab session (uses in-memory CIVITAI_API_TOKEN).\n",
    "- A unified Colab-friendly downloader with \"download queue\" mode, optional server-hash pre-check, progress reporting, and SHA256 validation post-download.\n",
    "- Post-download integrity checker and a human-readable download summary.\n",
    "\n",
    "Run order recommendation:\n",
    "1. Mount Drive cell (if not already mounted) and confirm `DRIVE_ROOT`.\n",
    "2. Run the secure token cell to set `CIVITAI_API_TOKEN` in this runtime.\n",
    "3. Run the Batch manifest resolver cell to populate `resolved_filename` and other metadata.\n",
    "4. Use the Unified Downloader cell to queue and download models (Preview, then Confirm).  \n",
    "5. Run the Post-download integrity checker, then view the Download summary UI.\n",
    "\n",
    "If you want a different UI layout or behavior (pure HTML panel, or Telegram/Slack webhook notifications for completed downloads), tell me and I can add it.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a94b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest not found at \\content\\drive\\MyDrive\\ComfyUI\\manifests\\civitai_model_manifests.json\n"
     ]
    }
   ],
   "source": [
    "#@title Batch manifest resolver — resolve final filenames and headers for manifest entries\n",
    "\"\"\"\n",
    "This cell iterates the manifest entries and attempts to resolve the final download URL, filename\n",
    "(Content-Disposition), content-length, and server-provided checksum (if present in headers or JSON) without\n",
    "downloading the full file. It will update the manifest with resolved_filename, resolved_url, content_length,\n",
    "and server_hash (if found). Run this in Colab after running the secure token input cell.\n",
    "\"\"\"\n",
    "import os, json, re, time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "\n",
    "if not MANIFEST_PATH.exists():\n",
    "    print('Manifest not found at', MANIFEST_PATH)\n",
    "else:\n",
    "    manifest = json.loads(MANIFEST_PATH.read_text())\n",
    "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "    if not token:\n",
    "        print('CIVITAI_API_TOKEN not set in environment. Run the secure token cell first.')\n",
    "    else:\n",
    "        s = requests.Session()\n",
    "        s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "        errors = []\n",
    "        for mid, entry in manifest.items():\n",
    "            url_tpl = entry.get('download_url','')\n",
    "            url = url_tpl.replace('$CIVITAI_API_TOKEN', token)\n",
    "            try:\n",
    "                r = s.head(url, allow_redirects=True, timeout=20)\n",
    "                # fallback to small GET if head fails\n",
    "                if r.status_code >= 400:\n",
    "                    r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
    "                    r.close()\n",
    "                final_url = r.url\n",
    "                cd = r.headers.get('Content-Disposition','')\n",
    "                filename = None\n",
    "                if cd:\n",
    "                    m = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
    "                    if m:\n",
    "                        filename = m.group(1) or m.group(2)\n",
    "                if not filename:\n",
    "                    filename = final_url.split('/')[-1].split('?')[0]\n",
    "                size = r.headers.get('Content-Length')\n",
    "                if size:\n",
    "                    size = int(size)\n",
    "                # server-provided checksum heuristics\n",
    "                server_hash = None\n",
    "                # Check common header fields\n",
    "                for h in ['ETag','Content-MD5','X-Checksum-Sha256','X-Checksum','x-amz-meta-sha256']:\n",
    "                    if r.headers.get(h):\n",
    "                        server_hash = r.headers.get(h)\n",
    "                        break\n",
    "                # If Content-Type is application/json and we did a small GET earlier, try to parse JSON\n",
    "                # to look for 'sha256' or similar in body\n",
    "                entry.update({\n",
    "                    'resolved_url': final_url,\n",
    "                    'resolved_filename': filename,\n",
    "                    'content_length': size,\n",
    "                    'server_hash': server_hash,\n",
    "                    'last_resolved': int(time.time())\n",
    "                })\n",
    "                manifest[mid] = entry\n",
    "                print(f\"Resolved {mid} -> {filename} ({size} bytes)\")\n",
    "            except Exception as e:\n",
    "                errors.append((mid,str(e)))\n",
    "                print(f\"Failed to resolve {mid}: {e}\")\n",
    "        MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
    "        print('Resolver complete. Wrote manifest. Errors:', len(errors))\n",
    "        if errors:\n",
    "            for mid,err in errors:\n",
    "                print(mid, err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e7a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Unified Colab downloader — queue mode, preview, server-hash pre-check, progress\n",
    "\"\"\"\n",
    "Features:\n",
    "- Queue multiple manifest entries for sequential download with progress.\n",
    "- Preview mode that resolves final filenames and sizes.\n",
    "- Optional server-hash pre-check: if the resolver found a server_hash (ETag or similar), compare\n",
    "  that short hash with a best-effort mapping before downloading.\n",
    "- Uses tqdm for progress display if available, otherwise prints simple progress messages.\n",
    "\n",
    "Usage:\n",
    "- Ensure `CIVITAI_API_TOKEN` is set in this runtime (secure token cell).\n",
    "- Run the resolver cell first to fill resolved_filename and server_hash.\n",
    "- Populate `queue_ids` with manifest keys to download, or use the UI dropdown/selection below.\n",
    "\"\"\"\n",
    "import os, json, re, time, hashlib\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    have_tqdm = True\n",
    "except Exception:\n",
    "    have_tqdm = False\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "\n",
    "if not MANIFEST_PATH.exists():\n",
    "    raise FileNotFoundError(f'Manifest not found at {MANIFEST_PATH}')\n",
    "\n",
    "manifest = json.loads(MANIFEST_PATH.read_text())\n",
    "\n",
    "# Simple helper: choose ids to download. Replace or populate programmatically.\n",
    "# Example: queue_ids = ['1', '2']\n",
    "queue_ids = []\n",
    "\n",
    "# Optional: prefer server hash pre-check (will skip download if mismatch in header-derived simple hash)\n",
    "ENABLE_SERVER_HASH_CHECK = True\n",
    "\n",
    "s = requests.Session()\n",
    "s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "\n",
    "\n",
    "def compute_sha256(path):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, 'rb') as fh:\n",
    "        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def download_with_progress(url, target_path):\n",
    "    r = s.get(url, stream=True, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    total = r.headers.get('Content-Length')\n",
    "    if total:\n",
    "        total = int(total)\n",
    "    tmp = str(target_path) + '.part'\n",
    "    with open(tmp, 'wb') as fh:\n",
    "        if have_tqdm and total:\n",
    "            with tqdm(total=total, unit='B', unit_scale=True, desc=str(target_path.name)) as pbar:\n",
    "                for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                    if chunk:\n",
    "                        fh.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "        else:\n",
    "            dl = 0\n",
    "            for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                if chunk:\n",
    "                    fh.write(chunk)\n",
    "                    dl += len(chunk)\n",
    "    Path(tmp).rename(target_path)\n",
    "    return target_path\n",
    "\n",
    "\n",
    "def server_hash_matches(header_hash, path):\n",
    "    # best-effort: compare ETag (may be quoted or not) to file's MD5/sha256 prefix\n",
    "    if not header_hash:\n",
    "        return None\n",
    "    hh = header_hash.strip('\"')\n",
    "    # If header looks like md5 hex length 32, we can compute md5\n",
    "    if re.fullmatch(r'[0-9a-fA-F]{32}', hh):\n",
    "        import hashlib\n",
    "        m = hashlib.md5()\n",
    "        with open(path, 'rb') as fh:\n",
    "            for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
    "                m.update(chunk)\n",
    "        return m.hexdigest() == hh\n",
    "    # If header looks like a sha256 hex (64 chars)\n",
    "    if re.fullmatch(r'[0-9a-fA-F]{64}', hh):\n",
    "        return compute_sha256(path) == hh\n",
    "    # unknown format — return None meaning \"can't decide\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_queue(ids):\n",
    "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "    if not token:\n",
    "        raise RuntimeError('CIVITAI_API_TOKEN not set. Run the secure token cell.')\n",
    "    for mid in ids:\n",
    "        entry = manifest.get(str(mid))\n",
    "        if not entry:\n",
    "            print('Manifest entry missing for', mid)\n",
    "            continue\n",
    "        url_tpl = entry.get('download_url','')\n",
    "        url = url_tpl.replace('$CIVITAI_API_TOKEN', token)\n",
    "        # use resolved_url if present\n",
    "        final_url = entry.get('resolved_url') or url\n",
    "        filename = entry.get('resolved_filename') or final_url.split('/')[-1].split('?')[0]\n",
    "        suggested_tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
    "        mapping = {\n",
    "            '{MODELS_DIR}': globals().get('MODELS_DIR', str(Path(DRIVE_ROOT)/'models')),\n",
    "            '{LORAS_DIR}': globals().get('LORAS_DIR', str(Path(DRIVE_ROOT)/'models'/'loras')),\n",
    "            '{GGUF_DIR}': globals().get('GGUF_DIR', str(Path(DRIVE_ROOT)/'models'/'gguf')),\n",
    "            '{ARTIFACTS_DIR}': globals().get('ARTIFACTS_DIR', str(Path(DRIVE_ROOT)/'artifacts')),\n",
    "        }\n",
    "        for k,v in mapping.items():\n",
    "            suggested_tpl = suggested_tpl.replace(k,v)\n",
    "        target_dir = Path(suggested_tpl)\n",
    "        target_dir.mkdir(parents=True, exist_ok=True)\n",
    "        target_path = target_dir/filename\n",
    "        # preview info\n",
    "        print(f'Downloading {mid} -> {filename}')\n",
    "        # if server hash exists and check enabled, we'll fetch headers and compare quickly after download\n",
    "        header_hash = entry.get('server_hash')\n",
    "        try:\n",
    "            download_with_progress(final_url, target_path)\n",
    "            sha = compute_sha256(target_path)\n",
    "            entry['downloaded_path'] = str(target_path)\n",
    "            entry['sha256'] = sha\n",
    "            entry['file_size_bytes'] = target_path.stat().st_size\n",
    "            # optional: post-download server-hash compare\n",
    "            if ENABLE_SERVER_HASH_CHECK and header_hash:\n",
    "                match = None\n",
    "                try:\n",
    "                    match = server_hash_matches(header_hash, target_path)\n",
    "                except Exception as e:\n",
    "                    print('Server-hash compare failed:', e)\n",
    "                if match is False:\n",
    "                    entry.setdefault('integrity',{})\n",
    "                    entry['integrity']['server_hash'] = header_hash\n",
    "                    entry['integrity']['server_hash_match'] = False\n",
    "                    entry['download_status'] = 'server_hash_mismatch'\n",
    "                    print('Warning: server hash mismatch for', mid)\n",
    "                else:\n",
    "                    entry.setdefault('integrity',{})\n",
    "                    entry['integrity']['server_hash'] = header_hash\n",
    "                    entry['integrity']['server_hash_match'] = True if match is True else 'unknown'\n",
    "            else:\n",
    "                entry['download_status'] = 'ok'\n",
    "            manifest[str(mid)] = entry\n",
    "            MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
    "            print('Downloaded and recorded:', target_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to download', mid, e)\n",
    "\n",
    "# If you want a small UI-based queue selector (Colab 'widgets' or ipywidgets), you can implement\n",
    "# here; for now, run programmatically by setting queue_ids and calling run_queue(queue_ids)\n",
    "\n",
    "print('Manifest keys available:', list(manifest.keys())[:20])\n",
    "print('Set queue_ids = [\"1\",\"2\"] and call run_queue(queue_ids)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfdfca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRIVE_ROOT = /content/drive/MyDrive/ComfyUI\n",
      "Drive root does not exist. Did you mount Drive? Run the Drive mount cell first.\n"
     ]
    }
   ],
   "source": [
    "#@title Manifest locator helper — find possible manifests under DRIVE_ROOT\n",
    "\"\"\"\n",
    "If the Batch manifest resolver failed because the manifest file cannot be found,\n",
    "this helper scans the `DRIVE_ROOT` area for probable manifest JSONs and prints\n",
    "their paths. Run this after mounting Drive.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "print('DRIVE_ROOT =', DRIVE_ROOT)\n",
    "root = Path(DRIVE_ROOT)\n",
    "if not root.exists():\n",
    "    print('Drive root does not exist. Did you mount Drive? Run the Drive mount cell first.')\n",
    "else:\n",
    "    candidates = []\n",
    "    manifests_dir = root / 'manifests'\n",
    "    if manifests_dir.exists():\n",
    "        for p in manifests_dir.glob('*.json'):\n",
    "            candidates.append(p)\n",
    "    # wide search for likely filenames\n",
    "    if not candidates:\n",
    "        for p in root.rglob('*.json'):\n",
    "            name = p.name.lower()\n",
    "            if 'civitai' in name or 'manifest' in name or 'models' in name:\n",
    "                candidates.append(p)\n",
    "    # show top results\n",
    "    if not candidates:\n",
    "        print('No candidate manifest files found under', DRIVE_ROOT)\n",
    "    else:\n",
    "        print('Found candidate manifest files:')\n",
    "        for i,p in enumerate(sorted(set(candidates)), start=1):\n",
    "            print(f'{i}. {p} (size: {p.stat().st_size} bytes)')\n",
    "        print('\\nIf one of these is the manifest you want to use, you can:')\n",
    "        print(' - Copy it to', str(manifests_dir/'civitai_model_manifests.json'))\n",
    "        print(' - Or update the MANIFEST_PATH variable in the resolver/downloader cells to point to the file')\n",
    "        print('\\nExample:')\n",
    "        print(\"MANIFEST_PATH = Path('\" + str(sorted(set(candidates))[0]) + \"')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c43bce3",
   "metadata": {},
   "source": [
    "## README (quick-run instructions)\n",
    "\n",
    "This cell is a short-run README making the key steps explicit. Use it as a quick checklist.\n",
    "\n",
    "1. Mount Google Drive (run the Drive mount cell) and ensure `DRIVE_ROOT` is set to your ComfyUI directory, e.g. `/content/drive/MyDrive/ComfyUI`.\n",
    "2. Run the secure token input cell to put `CIVITAI_API_TOKEN` (and optionally AWS/GCS creds) in environment variables.\n",
    "3. Run the Manifest locator helper if your manifest isn't at the default path.\n",
    "4. Run the Batch manifest resolver to populate `resolved_filename` and `server_hash` fields.\n",
    "5. Use the HTML \"Downloader Panel\" cell below to select entries, Start the queue, monitor progress, and Stop/Cancel if needed.\n",
    "6. After downloads, run the Post-download integrity checker cell and then the Download summary UI cell.\n",
    "\n",
    "Notes:\n",
    "- The HTML panel sends selections to Python callbacks in this notebook. Progress and logs appear in the Python output area. Live updates inside the HTML panel are limited by Colab cross-call constraints, so the Python output is the authoritative log.\n",
    "- Background scheduler: there's a cell below that can run the resolver periodically (for automated refresh). Be careful: Colab sessions can time out; only run this if your session will remain active.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Downloader Panel (HTML multi-select + Start/Stop callbacks)\n",
    "\"\"\"\n",
    "Renders an HTML panel with checkboxes for manifest entries and Start/Stop buttons.\n",
    "On Start it invokes the registered python callback to start the background download worker with selected ids.\n",
    "\"\"\"\n",
    "import json, os\n",
    "from pathlib import Path\n",
    "from google.colab import output\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "\n",
    "if not MANIFEST_PATH.exists():\n",
    "    print('Manifest not found at', MANIFEST_PATH)\n",
    "    print('Run the Manifest locator helper to locate or copy the manifest to the expected path.')\n",
    "else:\n",
    "    manifest = json.loads(MANIFEST_PATH.read_text())\n",
    "    # build a simple table\n",
    "    rows = []\n",
    "    for k, entry in sorted(manifest.items(), key=lambda t: int(t[0])):\n",
    "        name = entry.get('resolved_filename') or entry.get('title') or entry.get('name') or f'model-{k}'\n",
    "        size = entry.get('content_length') or entry.get('file_size_bytes') or ''\n",
    "        rows.append({'id':k,'label':str(name),'size':size})\n",
    "\n",
    "    html_rows = '\\n'.join([f\"<div><label><input type=checkbox value='{r['id']}' /> {r['label']} <small>{r['size']}</small></label></div>\" for r in rows])\n",
    "\n",
    "    panel = f\"\"\"\n",
    "    <div style='font-family: Roboto, Arial, sans-serif; padding: 8px; border: 1px solid #ddd; border-radius: 6px; width: 100%'>\n",
    "      <h3>Downloader Panel</h3>\n",
    "      <div id='manifest-list' style='max-height:300px; overflow:auto; padding:6px'>{html_rows}</div>\n",
    "      <div style='margin-top:8px'>\n",
    "        <button id='start-btn' style='padding:6px 12px; background:#0b74de; color:white; border:none; border-radius:4px'>Start Queue</button>\n",
    "        <button id='stop-btn' style='padding:6px 12px; margin-left:8px; background:#d9534f; color:white; border:none; border-radius:4px'>Stop Queue</button>\n",
    "        <label style='margin-left:12px'><input type='checkbox' id='retry-check' /> Enable retries</label>\n",
    "        <label style='margin-left:12px'>Retries: <input id='retry-count' type='number' value='2' style='width:60px'></label>\n",
    "      </div>\n",
    "      <div id='panel-status' style='margin-top:10px; font-size:0.9em; color:#333'></div>\n",
    "    </div>\n",
    "    <script>\n",
    "    const getChecked = () => Array.from(document.querySelectorAll('#manifest-list input:checked')).map(x=>x.value);\n",
    "    document.getElementById('start-btn').onclick = () => {\n",
    "        const ids = getChecked();\n",
    "        const retry = document.getElementById('retry-check').checked;\n",
    "        const rcount = parseInt(document.getElementById('retry-count').value || '2');\n",
    "        document.getElementById('panel-status').innerText = 'Starting queue: ' + ids.join(', ');\n",
    "        google.colab.kernel.invokeFunction('notebook.start_queue', [ids, retry, rcount], {});\n",
    "    };\n",
    "    document.getElementById('stop-btn').onclick = () => {\n",
    "        document.getElementById('panel-status').innerText = 'Stopping queue...';\n",
    "        google.colab.kernel.invokeFunction('notebook.stop_queue', [], {});\n",
    "    };\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    output.eval_js('console.clear()')\n",
    "    display_html = output._repr_html_(panel)\n",
    "    display(display_html)\n",
    "\n",
    "# Register callbacks — the actual implementation is provided in the Background worker cell below\n",
    "\n",
    "def _no_op(*args, **kwargs):\n",
    "    print('Callback not registered yet')\n",
    "\n",
    "# register placeholder so kernel.invokeFunction calls won't fail if background worker not loaded\n",
    "output.register_callback('notebook.start_queue', _no_op)\n",
    "output.register_callback('notebook.stop_queue', _no_op)\n",
    "print('Downloader Panel rendered. Use the checkboxes, then Start Queue. Logs will appear in the Python output area.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Background queue worker and control functions (start/stop, retries, progress)\n",
    "\"\"\"\n",
    "This cell provides the background worker implementation and registers the callbacks\n",
    "used by the HTML panel. The worker uses a stop event so the queue can be stopped.\n",
    "It supports per-item retries and records results in the manifest.\n",
    "\"\"\"\n",
    "import threading, time, json, os, traceback\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import hashlib\n",
    "from queue import Queue, Empty\n",
    "from google.colab import output\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "\n",
    "# worker state\n",
    "worker_thread = None\n",
    "worker_stop_event = threading.Event()\n",
    "worker_lock = threading.Lock()\n",
    "\n",
    "# simple download helper reused from previous cells\n",
    "def compute_sha256(path):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, 'rb') as fh:\n",
    "        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "# improved header hash normalization & heuristics\n",
    "def normalize_header_hash(hdr):\n",
    "    if not hdr:\n",
    "        return None\n",
    "    h = str(hdr).strip().strip('\"')\n",
    "    # if it's an etag with dashes (multipart) — can't reliably compare\n",
    "    if '-' in h:\n",
    "        return {'value':h, 'type':'etag-multipart'}\n",
    "    if len(h) == 32 and all(c in '0123456789abcdefABCDEF' for c in h):\n",
    "        return {'value':h.lower(), 'type':'md5'}\n",
    "    if len(h) == 64 and all(c in '0123456789abcdefABCDEF' for c in h):\n",
    "        return {'value':h.lower(), 'type':'sha256'}\n",
    "    return {'value':h, 'type':'unknown'}\n",
    "\n",
    "\n",
    "# robust per-item downloader with retries\n",
    "def download_item(mid, entry, retry_count=2, stop_event=None):\n",
    "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "    s = requests.Session()\n",
    "    s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "    url_tpl = entry.get('download_url')\n",
    "    if not url_tpl:\n",
    "        print(f'No download_url for {mid}')\n",
    "        return False\n",
    "    url = url_tpl.replace('$CIVITAI_API_TOKEN', token)\n",
    "    final_url = entry.get('resolved_url') or url\n",
    "    filename = entry.get('resolved_filename') or final_url.split('/')[-1].split('?')[0]\n",
    "    suggested_tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
    "    mapping = {\n",
    "        '{MODELS_DIR}': globals().get('MODELS_DIR', str(Path(DRIVE_ROOT)/'models')),\n",
    "        '{LORAS_DIR}': globals().get('LORAS_DIR', str(Path(DRIVE_ROOT)/'models'/'loras')),\n",
    "        '{GGUF_DIR}': globals().get('GGUF_DIR', str(Path(DRIVE_ROOT)/'models'/'gguf')),\n",
    "        '{ARTIFACTS_DIR}': globals().get('ARTIFACTS_DIR', str(Path(DRIVE_ROOT)/'artifacts')),\n",
    "    }\n",
    "    for k,v in mapping.items():\n",
    "        suggested_tpl = suggested_tpl.replace(k,v)\n",
    "    target_dir = Path(suggested_tpl)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    target_path = target_dir/filename\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts <= retry_count:\n",
    "        if stop_event and stop_event.is_set():\n",
    "            print('Stop requested — aborting', mid)\n",
    "            return False\n",
    "        try:\n",
    "            r = s.get(final_url, stream=True, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            tmp = str(target_path) + '.part'\n",
    "            with open(tmp, 'wb') as fh:\n",
    "                for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                    if chunk:\n",
    "                        fh.write(chunk)\n",
    "            Path(tmp).rename(target_path)\n",
    "            sha = compute_sha256(target_path)\n",
    "            entry['downloaded_path'] = str(target_path)\n",
    "            entry['sha256'] = sha\n",
    "            entry['file_size_bytes'] = target_path.stat().st_size\n",
    "            entry['download_status'] = 'ok'\n",
    "            # server hash check heuristics\n",
    "            hdr = entry.get('server_hash')\n",
    "            sh = normalize_header_hash(hdr)\n",
    "            if sh:\n",
    "                if sh['type'] == 'sha256':\n",
    "                    entry.setdefault('integrity',{})\n",
    "                    entry['integrity']['server_hash'] = sh['value']\n",
    "                    entry['integrity']['server_hash_match'] = (sha == sh['value'])\n",
    "                elif sh['type'] == 'md5':\n",
    "                    import hashlib\n",
    "                    m = hashlib.md5()\n",
    "                    with open(target_path, 'rb') as fh:\n",
    "                        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
    "                            m.update(chunk)\n",
    "                    entry.setdefault('integrity',{})\n",
    "                    entry['integrity']['server_hash'] = sh['value']\n",
    "                    entry['integrity']['server_hash_match'] = (m.hexdigest() == sh['value'])\n",
    "                else:\n",
    "                    entry.setdefault('integrity',{})\n",
    "                    entry['integrity']['server_hash'] = sh['value']\n",
    "                    entry['integrity']['server_hash_match'] = 'unknown'\n",
    "            # persist manifest incrementally\n",
    "            with open(MANIFEST_PATH, 'r', encoding='utf-8') as fh:\n",
    "                m = json.load(fh)\n",
    "            m[str(mid)] = entry\n",
    "            with open(MANIFEST_PATH, 'w', encoding='utf-8') as fh:\n",
    "                json.dump(m, fh, indent=2)\n",
    "            print('Downloaded', mid, '->', target_path)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(f'Attempt {attempts} failed for {mid}:', e)\n",
    "            if attempts > retry_count:\n",
    "                entry['download_status'] = 'failed'\n",
    "                with open(MANIFEST_PATH, 'r', encoding='utf-8') as fh:\n",
    "                    m = json.load(fh)\n",
    "                m[str(mid)] = entry\n",
    "                with open(MANIFEST_PATH, 'w', encoding='utf-8') as fh:\n",
    "                    json.dump(m, fh, indent=2)\n",
    "                return False\n",
    "            time.sleep(2)\n",
    "    return False\n",
    "\n",
    "# worker runner\n",
    "\n",
    "def worker_main(id_list, retry_count=2, stop_event=None):\n",
    "    print('Worker started for ids:', id_list)\n",
    "    for mid in id_list:\n",
    "        if stop_event and stop_event.is_set():\n",
    "            print('Stop event detected — exiting worker')\n",
    "            break\n",
    "        try:\n",
    "            with open(MANIFEST_PATH, 'r', encoding='utf-8') as fh:\n",
    "                m = json.load(fh)\n",
    "            entry = m.get(str(mid))\n",
    "            if not entry:\n",
    "                print('No manifest entry for', mid)\n",
    "                continue\n",
    "            success = download_item(mid, entry, retry_count=retry_count, stop_event=stop_event)\n",
    "            if not success:\n",
    "                print('Failed to download', mid)\n",
    "        except Exception as e:\n",
    "            print('Worker error for', mid, e)\n",
    "            traceback.print_exc()\n",
    "    print('Worker finished')\n",
    "\n",
    "# control functions registered as kernel callbacks\n",
    "\n",
    "def start_queue_callback(ids, enable_retries=False, retry_count=2):\n",
    "    global worker_thread, worker_stop_event\n",
    "    with worker_lock:\n",
    "        if worker_thread and worker_thread.is_alive():\n",
    "            print('A worker is already running')\n",
    "            return\n",
    "        worker_stop_event = threading.Event()\n",
    "        worker_thread = threading.Thread(target=worker_main, args=(ids, retry_count, worker_stop_event), daemon=True)\n",
    "        worker_thread.start()\n",
    "        print('Started worker thread with ids:', ids)\n",
    "\n",
    "\n",
    "def stop_queue_callback():\n",
    "    global worker_thread, worker_stop_event\n",
    "    with worker_lock:\n",
    "        if worker_thread and worker_thread.is_alive():\n",
    "            worker_stop_event.set()\n",
    "            worker_thread.join(timeout=5)\n",
    "            print('Worker stopped')\n",
    "        else:\n",
    "            print('No active worker')\n",
    "\n",
    "# register callbacks so the HTML panel can call them\n",
    "output.register_callback('notebook.start_queue', start_queue_callback)\n",
    "output.register_callback('notebook.stop_queue', stop_queue_callback)\n",
    "print('Background worker callbacks registered: notebook.start_queue, notebook.stop_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Nightly manifest resolver (background scheduler)\n",
    "\"\"\"\n",
    "Starts a background scheduler that runs the Batch manifest resolver every `interval_seconds`.\n",
    "Note: Colab sessions often time out — only use this if your session stays alive.\n",
    "\"\"\"\n",
    "import threading, time, json\n",
    "from pathlib import Path\n",
    "from google.colab import output\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "\n",
    "scheduler_thread = None\n",
    "scheduler_stop_event = threading.Event()\n",
    "\n",
    "\n",
    "def run_resolver_once():\n",
    "    # import code from the resolver cell or re-implement minimal resolver here\n",
    "    import requests, re, time\n",
    "    if not MANIFEST_PATH.exists():\n",
    "        print('Manifest missing, cannot run resolver')\n",
    "        return\n",
    "    m = json.loads(MANIFEST_PATH.read_text())\n",
    "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "    if not token:\n",
    "        print('CIVITAI_API_TOKEN not set. Run secure token cell first.')\n",
    "        return\n",
    "    s = requests.Session()\n",
    "    s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "    for mid,entry in m.items():\n",
    "        try:\n",
    "            url = entry.get('download_url','').replace('$CIVITAI_API_TOKEN', token)\n",
    "            r = s.head(url, allow_redirects=True, timeout=20)\n",
    "            if r.status_code >= 400:\n",
    "                r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
    "                r.close()\n",
    "            final_url = r.url\n",
    "            cd = r.headers.get('Content-Disposition','')\n",
    "            filename = None\n",
    "            if cd:\n",
    "                mm = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
    "                if mm:\n",
    "                    filename = mm.group(1) or mm.group(2)\n",
    "            if not filename:\n",
    "                filename = final_url.split('/')[-1].split('?')[0]\n",
    "            size = r.headers.get('Content-Length')\n",
    "            if size:\n",
    "                size = int(size)\n",
    "            server_hash = None\n",
    "            for h in ['ETag','Content-MD5','X-Checksum-Sha256','X-Checksum','x-amz-meta-sha256']:\n",
    "                if r.headers.get(h):\n",
    "                    server_hash = r.headers.get(h)\n",
    "                    break\n",
    "            entry.update({'resolved_url':final_url,'resolved_filename':filename,'content_length':size,'server_hash':server_hash,'last_resolved':int(time.time())})\n",
    "            m[mid] = entry\n",
    "        except Exception as e:\n",
    "            print('Resolver failed for', mid, e)\n",
    "    MANIFEST_PATH.write_text(json.dumps(m, indent=2))\n",
    "    print('Resolver pass complete')\n",
    "\n",
    "\n",
    "def scheduler_start(interval_seconds=24*3600):\n",
    "    global scheduler_thread, scheduler_stop_event\n",
    "    if scheduler_thread and scheduler_thread.is_alive():\n",
    "        print('Scheduler already running')\n",
    "        return\n",
    "    scheduler_stop_event = threading.Event()\n",
    "    def loop():\n",
    "        while not scheduler_stop_event.is_set():\n",
    "            run_resolver_once()\n",
    "            # sleep with small increments to allow stop signal to be responsive\n",
    "            remaining = interval_seconds\n",
    "            while remaining > 0 and not scheduler_stop_event.is_set():\n",
    "                t = min(10, remaining)\n",
    "                time.sleep(t)\n",
    "                remaining -= t\n",
    "    scheduler_thread = threading.Thread(target=loop, daemon=True)\n",
    "    scheduler_thread.start()\n",
    "    print('Scheduler started with interval', interval_seconds)\n",
    "\n",
    "\n",
    "def scheduler_stop():\n",
    "    global scheduler_stop_event\n",
    "    if scheduler_stop_event:\n",
    "        scheduler_stop_event.set()\n",
    "        print('Scheduler stop requested')\n",
    "    else:\n",
    "        print('Scheduler not running')\n",
    "\n",
    "# register callbacks so user can start/stop from UI if desired\n",
    "output.register_callback('notebook.start_scheduler', lambda interval: scheduler_start(interval))\n",
    "output.register_callback('notebook.stop_scheduler', lambda : scheduler_stop())\n",
    "print('Scheduler helpers registered (start_scheduler, stop_scheduler)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d044823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Artifact upload helper (S3 / GCS) — optional: upload completed artifacts to private bucket\n",
    "\"\"\"\n",
    "Upload a downloaded artifact to S3 or GCS. If credentials are present in environment, the helper will attempt\n",
    "an upload and record the uploaded URL into the manifest under 'uploaded_url'.\n",
    "Set AWS_* env vars for S3 or set GOOGLE_APPLICATION_CREDENTIALS for GCS.\n",
    "\"\"\"\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "\n",
    "\n",
    "def upload_artifact(path, provider='s3', bucket=None, object_name=None):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(path)\n",
    "    if provider == 's3':\n",
    "        try:\n",
    "            import boto3\n",
    "            s3 = boto3.client('s3')\n",
    "            if not bucket:\n",
    "                raise ValueError('bucket required for s3')\n",
    "            obj = object_name or p.name\n",
    "            s3.upload_file(str(p), bucket, obj)\n",
    "            url = f's3://{bucket}/{obj}'\n",
    "            return url\n",
    "        except Exception as e:\n",
    "            print('S3 upload failed:', e)\n",
    "            raise\n",
    "    elif provider == 'gcs':\n",
    "        try:\n",
    "            from google.cloud import storage\n",
    "            if not bucket:\n",
    "                raise ValueError('bucket required for gcs')\n",
    "            client = storage.Client()\n",
    "            bucket_obj = client.bucket(bucket)\n",
    "            blob = bucket_obj.blob(object_name or p.name)\n",
    "            blob.upload_from_filename(str(p))\n",
    "            return f'gs://{bucket}/{blob.name}'\n",
    "        except Exception as e:\n",
    "            print('GCS upload failed:', e)\n",
    "            raise\n",
    "    else:\n",
    "        raise ValueError('Unknown provider')\n",
    "\n",
    "\n",
    "def upload_and_record(mid, provider='s3', bucket=None, object_name=None):\n",
    "    if not MANIFEST_PATH.exists():\n",
    "        raise FileNotFoundError('Manifest missing')\n",
    "    m = json.loads(MANIFEST_PATH.read_text())\n",
    "    entry = m.get(str(mid))\n",
    "    if not entry or not entry.get('downloaded_path'):\n",
    "        raise ValueError('No downloaded_path for manifest entry')\n",
    "    path = entry['downloaded_path']\n",
    "    url = upload_artifact(path, provider=provider, bucket=bucket, object_name=object_name)\n",
    "    entry['uploaded_url'] = url\n",
    "    m[str(mid)] = entry\n",
    "    MANIFEST_PATH.write_text(json.dumps(m, indent=2))\n",
    "    print('Uploaded', mid, '->', url)\n",
    "    return url\n",
    "\n",
    "print('Upload helper loaded. Use upload_and_record(mid, provider, bucket) to upload and record in manifest.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Advanced persistent queue worker (resume, backoff retries, progress persistence)\n",
    "\"\"\"\n",
    "This worker improves upon the earlier implementation by:\n",
    "- Persisting queue state to DRIVE_ROOT/.queue_state.json so the queue can be resumed after kernel reconnects\n",
    "- Per-item progress tracking (bytes downloaded and percent when content-length present)\n",
    "- Exponential backoff retry strategy configurable per-call\n",
    "- get_queue_status callback to return the current queue state for the UI to poll\n",
    "\n",
    "Usage: use the rich HTML dashboard below which polls `notebook.get_queue_status` and calls\n",
    "`notebook.start_queue` and `notebook.stop_queue` to control the worker.\n",
    "\"\"\"\n",
    "import threading, time, json, os, traceback\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import hashlib\n",
    "from google.colab import output\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
    "QUEUE_STATE_PATH = Path(DRIVE_ROOT)/'.queue_state.json'\n",
    "\n",
    "worker_thread = None\n",
    "worker_stop_event = threading.Event()\n",
    "worker_lock = threading.Lock()\n",
    "\n",
    "# Helper: read/write queue state\n",
    "\n",
    "def load_queue_state():\n",
    "    if QUEUE_STATE_PATH.exists():\n",
    "        try:\n",
    "            return json.loads(QUEUE_STATE_PATH.read_text())\n",
    "        except Exception:\n",
    "            return {'items':{}}\n",
    "    return {'items':{}}\n",
    "\n",
    "def write_queue_state(state):\n",
    "    QUEUE_STATE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    QUEUE_STATE_PATH.write_text(json.dumps(state, indent=2))\n",
    "\n",
    "# initialize state if missing\n",
    "if not QUEUE_STATE_PATH.exists():\n",
    "    write_queue_state({'items':{}})\n",
    "\n",
    "# improved header normalization\n",
    "\n",
    "def normalize_header_hash(hdr):\n",
    "    if not hdr:\n",
    "        return None\n",
    "    h = str(hdr).strip().strip('\"')\n",
    "    if '-' in h:\n",
    "        return {'value':h,'type':'etag-multipart'}\n",
    "    if len(h) == 32 and all(c in '0123456789abcdefABCDEF' for c in h):\n",
    "        return {'value':h.lower(),'type':'md5'}\n",
    "    if len(h) == 64 and all(c in '0123456789abcdefABCDEF' for c in h):\n",
    "        return {'value':h.lower(),'type':'sha256'}\n",
    "    # provider-specific heuristics (very basic): strip surrounding 'W/' or other prefixes\n",
    "    h2 = h.replace('W/','').strip()\n",
    "    if len(h2) in (32,64) and all(c in '0123456789abcdefABCDEF' for c in h2):\n",
    "        t = 'md5' if len(h2)==32 else 'sha256'\n",
    "        return {'value':h2.lower(),'type':t}\n",
    "    return {'value':h,'type':'unknown'}\n",
    "\n",
    "# download with progress and state updates\n",
    "\n",
    "def compute_sha256(path):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, 'rb') as fh:\n",
    "        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def update_item_state(mid, **kwargs):\n",
    "    state = load_queue_state()\n",
    "    items = state.setdefault('items',{})\n",
    "    item = items.setdefault(str(mid), {})\n",
    "    item.update(kwargs)\n",
    "    write_queue_state(state)\n",
    "\n",
    "\n",
    "def download_item_with_progress(mid, entry, retry_count=2, stop_event=None):\n",
    "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
    "    s = requests.Session()\n",
    "    s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
    "    url_tpl = entry.get('download_url','')\n",
    "    if not url_tpl:\n",
    "        update_item_state(mid, status='no_url')\n",
    "        return False\n",
    "    url = url_tpl.replace('$CIVITAI_API_TOKEN', token)\n",
    "    final_url = entry.get('resolved_url') or url\n",
    "    filename = entry.get('resolved_filename') or final_url.split('/')[-1].split('?')[0]\n",
    "    suggested_tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
    "    mapping = {\n",
    "        '{MODELS_DIR}': globals().get('MODELS_DIR', str(Path(DRIVE_ROOT)/'models')),\n",
    "        '{LORAS_DIR}': globals().get('LORAS_DIR', str(Path(DRIVE_ROOT)/'models'/'loras')),\n",
    "        '{GGUF_DIR}': globals().get('GGUF_DIR', str(Path(DRIVE_ROOT)/'models'/'gguf')),\n",
    "        '{ARTIFACTS_DIR}': globals().get('ARTIFACTS_DIR', str(Path(DRIVE_ROOT)/'artifacts')),\n",
    "    }\n",
    "    for k,v in mapping.items():\n",
    "        suggested_tpl = suggested_tpl.replace(k,v)\n",
    "    target_dir = Path(suggested_tpl)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    target_path = target_dir/filename\n",
    "\n",
    "    attempts = 0\n",
    "    backoff_base = 2\n",
    "    while attempts <= retry_count:\n",
    "        if stop_event and stop_event.is_set():\n",
    "            update_item_state(mid, status='cancelled')\n",
    "            return False\n",
    "        try:\n",
    "            update_item_state(mid, status='starting', attempts=attempts+1, filename=str(target_path))\n",
    "            r = s.get(final_url, stream=True, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            total = r.headers.get('Content-Length')\n",
    "            if total:\n",
    "                total = int(total)\n",
    "            tmp = str(target_path) + '.part'\n",
    "            downloaded = 0\n",
    "            with open(tmp, 'wb') as fh:\n",
    "                for chunk in r.iter_content(chunk_size=256*1024):\n",
    "                    if chunk:\n",
    "                        fh.write(chunk)\n",
    "                        downloaded += len(chunk)\n",
    "                        # update progress\n",
    "                        if total:\n",
    "                            pct = int(downloaded*100/total)\n",
    "                        else:\n",
    "                            pct = None\n",
    "                        update_item_state(mid, status='downloading', bytes=downloaded, bytes_total=total, percent=pct)\n",
    "                        if stop_event and stop_event.is_set():\n",
    "                            update_item_state(mid, status='cancelled')\n",
    "                            return False\n",
    "            Path(tmp).rename(target_path)\n",
    "            sha = compute_sha256(target_path)\n",
    "            entry['downloaded_path'] = str(target_path)\n",
    "            entry['sha256'] = sha\n",
    "            entry['file_size_bytes'] = target_path.stat().st_size\n",
    "            entry['download_status'] = 'ok'\n",
    "            # server hash check\n",
    "            hdr = entry.get('server_hash')\n",
    "            sh = normalize_header_hash(hdr)\n",
    "            if sh:\n",
    "                if sh['type'] == 'sha256':\n",
    "                    entry.setdefault('integrity',{})\n",
    "                    entry['integrity']['server_hash'] = sh['value']\n",
    "                    entry['integrity']['server_hash_match'] = (sha == sh['value'])\n",
    "                elif sh['type'] == 'md5':\n",
    "                    import hashlib as _hashlib\n",
    "                    m = _hashlib.md5()\n",
    "                    with open(target_path, 'rb') as fh:\n",
    "                        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
    "                            m.update(chunk)\n",
    "                    entry.setdefault('integrity',{})\n",
    "                    entry['integrity']['server_hash'] = sh['value']\n",
    "                    entry['integrity']['server_hash_match'] = (m.hexdigest() == sh['value'])\n",
    "                else:\n",
    "                    entry.setdefault('integrity',{})\n",
    "                    entry['integrity']['server_hash'] = sh['value']\n",
    "                    entry['integrity']['server_hash_match'] = 'unknown'\n",
    "            # persist manifest incrementally\n",
    "            if MANIFEST_PATH.exists():\n",
    "                try:\n",
    "                    with open(MANIFEST_PATH, 'r', encoding='utf-8') as fh:\n",
    "                        m = json.load(fh)\n",
    "                except Exception:\n",
    "                    m = {}\n",
    "            else:\n",
    "                m = {}\n",
    "            m[str(mid)] = entry\n",
    "            with open(MANIFEST_PATH, 'w', encoding='utf-8') as fh:\n",
    "                json.dump(m, fh, indent=2)\n",
    "            update_item_state(mid, status='ok', sha256=sha, file_size=entry['file_size_bytes'])\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            last_err = str(e)\n",
    "            update_item_state(mid, status='error', last_error=last_err, attempts=attempts)\n",
    "            if attempts > retry_count:\n",
    "                update_item_state(mid, status='failed', last_error=last_err)\n",
    "                # persist failed state in manifest\n",
    "                if MANIFEST_PATH.exists():\n",
    "                    try:\n",
    "                        with open(MANIFEST_PATH, 'r', encoding='utf-8') as fh:\n",
    "                            m = json.load(fh)\n",
    "                    except Exception:\n",
    "                        m = {}\n",
    "                    ent = m.get(str(mid), {})\n",
    "                    ent['download_status'] = 'failed'\n",
    "                    ent.setdefault('integrity',{})\n",
    "                    ent['integrity']['last_error'] = last_err\n",
    "                    m[str(mid)] = ent\n",
    "                    with open(MANIFEST_PATH, 'w', encoding='utf-8') as fh:\n",
    "                        json.dump(m, fh, indent=2)\n",
    "                return False\n",
    "            # exponential backoff\n",
    "            sleep_for = backoff_base ** attempts\n",
    "            update_item_state(mid, status='retrying', next_wait=sleep_for)\n",
    "            time.sleep(sleep_for)\n",
    "    return False\n",
    "\n",
    "# worker loop that persists state\n",
    "\n",
    "def worker_main(ids, retry_count=2, stop_event=None):\n",
    "    print('Worker started for ids:', ids)\n",
    "    state = load_queue_state()\n",
    "    for mid in ids:\n",
    "        if stop_event and stop_event.is_set():\n",
    "            print('Stop requested — exiting worker')\n",
    "            break\n",
    "        # initialize state entry\n",
    "        update_item_state(mid, status='queued', attempts=0)\n",
    "    for mid in ids:\n",
    "        # load latest manifest entry\n",
    "        try:\n",
    "            if MANIFEST_PATH.exists():\n",
    "                with open(MANIFEST_PATH, 'r', encoding='utf-8') as fh:\n",
    "                    manifest = json.load(fh)\n",
    "            else:\n",
    "                manifest = {}\n",
    "            entry = manifest.get(str(mid), {})\n",
    "            download_item_with_progress(mid, entry, retry_count=retry_count, stop_event=stop_event)\n",
    "        except Exception as e:\n",
    "            print('Worker error for', mid, e)\n",
    "            traceback.print_exc()\n",
    "    print('Worker finished')\n",
    "\n",
    "# control functions\n",
    "\n",
    "def start_queue_callback(ids, enable_retries=False, retry_count=2):\n",
    "    global worker_thread, worker_stop_event\n",
    "    with worker_lock:\n",
    "        if worker_thread and worker_thread.is_alive():\n",
    "            print('A worker is already running')\n",
    "            return\n",
    "        worker_stop_event = threading.Event()\n",
    "        # ensure ids is a simple list of strings\n",
    "        ids = [str(x) for x in ids]\n",
    "        # persist initial queue state and items order\n",
    "        st = load_queue_state()\n",
    "        st['order'] = ids\n",
    "        for i in ids:\n",
    "            st.setdefault('items',{})\n",
    "            st['items'].setdefault(str(i), {'status':'queued'})\n",
    "        write_queue_state(st)\n",
    "        worker_thread = threading.Thread(target=worker_main, args=(ids, retry_count, worker_stop_event), daemon=True)\n",
    "        worker_thread.start()\n",
    "        print('Started worker thread with ids:', ids)\n",
    "\n",
    "\n",
    "def stop_queue_callback():\n",
    "    global worker_thread, worker_stop_event\n",
    "    with worker_lock:\n",
    "        if worker_thread and worker_thread.is_alive():\n",
    "            worker_stop_event.set()\n",
    "            worker_thread.join(timeout=5)\n",
    "            print('Worker stopped')\n",
    "        else:\n",
    "            print('No active worker')\n",
    "\n",
    "\n",
    "def get_queue_status_callback():\n",
    "    st = load_queue_state()\n",
    "    return st\n",
    "\n",
    "# register callbacks\n",
    "output.register_callback('notebook.start_queue', start_queue_callback)\n",
    "output.register_callback('notebook.stop_queue', stop_queue_callback)\n",
    "output.register_callback('notebook.get_queue_status', get_queue_status_callback)\n",
    "print('Advanced persistent worker callbacks registered: start_queue, stop_queue, get_queue_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Downloader Dashboard — rich HTML UI with per-item progress\n",
    "\"\"\"\n",
    "Renders a richer HTML dashboard that polls `notebook.get_queue_status` for per-item progress\n",
    "and displays progress bars. It also exposes Start/Stop and retry controls.\n",
    "\n",
    "Note: polling frequency is limited to avoid spamming the kernel. The authoritative logs\n",
    "and the final state are saved to DRIVE_ROOT/.queue_state.json — the UI reflects that state.\n",
    "\"\"\"\n",
    "from google.colab import output\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "MANIFEST_PATH = f\"{DRIVE_ROOT}/manifests/civitai_model_manifests.json\"\n",
    "\n",
    "# Build the HTML template with a placeholder for the list; the UI will ask Python for the manifest\n",
    "html = r'''\n",
    "<div style=\"font-family: Roboto, Arial; padding:10px; border:1px solid #ddd; border-radius:6px;\">\n",
    "  <h3>Downloader Dashboard</h3>\n",
    "  <div style=\"margin-bottom:8px\">\n",
    "    <button id=\"dd-start\">Start Selected</button>\n",
    "    <button id=\"dd-stop\">Stop</button>\n",
    "    <label style=\"margin-left:10px\">Retries: <input id=\"dd-retries\" type=\"number\" value=\"2\" style=\"width:50px\"></label>\n",
    "  </div>\n",
    "  <div id=\"dd-list\" style=\"max-height:360px; overflow:auto; border-top:1px solid #eee; padding-top:8px\"></div>\n",
    "  <div id=\"dd-status\" style=\"margin-top:8px; font-size:0.9em; color:#333\"></div>\n",
    "</div>\n",
    "<script>\n",
    "async function fetchManifest() {\n",
    "  // request the Python side for current manifest keys + resolved filenames\n",
    "  const resp = await google.colab.kernel.invokeFunction('notebook.get_queue_status', [], {});\n",
    "  const state = resp.data['application/json'];\n",
    "  const items = state.items || {};\n",
    "  const list = document.getElementById('dd-list');\n",
    "  list.innerHTML = '';\n",
    "  for (const id of Object.keys(items)){\n",
    "    const it = items[id];\n",
    "    const div = document.createElement('div');\n",
    "    div.style.padding = '6px 4px';\n",
    "    div.style.borderBottom = '1px solid #f4f4f4';\n",
    "    const title = document.createElement('div');\n",
    "    title.innerHTML = `<strong>${id}</strong> — ${it.filename || ''}`;\n",
    "    div.appendChild(title);\n",
    "    const bar = document.createElement('div');\n",
    "    bar.style.height = '10px';\n",
    "    bar.style.width = '100%';\n",
    "    bar.style.background = '#eee';\n",
    "    bar.style.borderRadius = '6px';\n",
    "    const inner = document.createElement('div');\n",
    "    inner.style.height = '100%';\n",
    "    inner.style.width = (it.percent? it.percent+'%': '0%');\n",
    "    inner.style.background = (it.status==='ok'? '#4caf50' : (it.status==='failed'? '#d9534f' : '#0b74de'));\n",
    "    inner.style.borderRadius = '6px';\n",
    "    inner.style.transition = 'width 0.4s ease';\n",
    "    bar.appendChild(inner);\n",
    "    div.appendChild(bar);\n",
    "    const meta = document.createElement('div');\n",
    "    meta.style.fontSize='0.85em';\n",
    "    meta.style.color='#666';\n",
    "    meta.innerText = `Status: ${it.status || 'n/a'} | Attempts: ${it.attempts || 0} | ${it.bytes || 0}/${it.bytes_total || 0}`;\n",
    "    div.appendChild(meta);\n",
    "    list.appendChild(div);\n",
    "  }\n",
    "}\n",
    "\n",
    "// initial poll\n",
    "fetchManifest();\n",
    "// poll periodically\n",
    "setInterval(fetchManifest, 2000);\n",
    "\n",
    "// start/stop handlers with simple selection of queued ids (transition: select all with status queued)\n",
    "document.getElementById('dd-start').onclick = async () => {\n",
    "  const reps = await google.colab.kernel.invokeFunction('notebook.get_queue_status', [], {});\n",
    "  const st = reps.data['application/json'];\n",
    "  const ids = Object.keys(st.items || {});\n",
    "  const retries = parseInt(document.getElementById('dd-retries').value || '2');\n",
    "  google.colab.kernel.invokeFunction('notebook.start_queue', [ids, true, retries], {});\n",
    "  document.getElementById('dd-status').innerText = 'Started queue for ids: ' + ids.join(', ');\n",
    "};\n",
    "\n",
    "document.getElementById('dd-stop').onclick = () => {\n",
    "  google.colab.kernel.invokeFunction('notebook.stop_queue', [], {});\n",
    "  document.getElementById('dd-status').innerText = 'Stop requested';\n",
    "};\n",
    "</script>\n",
    "'''\n",
    "\n",
    "display(HTML(html))\n",
    "print('Downloader Dashboard rendered — it polls queue state and shows progress bars. Use Start/Stop to control the worker.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce41c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Guarded subprocess utilities (replace shell-magic with subprocess wrappers)\n",
    "\"\"\"\n",
    "Provides helper functions to run shell commands in a guarded way so static checkers\n",
    "and Python linters don't complain about Jupyter bang (!) commands. These helpers\n",
    "capture stdout/stderr, enforce timeouts, and optionally run as background processes.\n",
    "\"\"\"\n",
    "import subprocess, shlex, threading, time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def run_cmd(cmd, timeout=600, shell=False, env=None, cwd=None):\n",
    "    \"\"\"Run a command and return (returncode, stdout, stderr).\"\"\"\n",
    "    if isinstance(cmd, str) and not shell:\n",
    "        cmd = shlex.split(cmd)\n",
    "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env, cwd=cwd, shell=shell)\n",
    "    try:\n",
    "        out, err = proc.communicate(timeout=timeout)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        proc.kill()\n",
    "        out, err = proc.communicate()\n",
    "        return proc.returncode or -9, out, err\n",
    "    return proc.returncode, out, err\n",
    "\n",
    "\n",
    "def run_cmd_background(cmd, on_stdout=None, on_stderr=None, env=None, cwd=None):\n",
    "    \"\"\"Run a command in background and stream stdout/stderr to callbacks.\n",
    "    Returns a handle with a terminate() method.\"\"\"\n",
    "    if isinstance(cmd, str):\n",
    "        cmd = shlex.split(cmd)\n",
    "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env, cwd=cwd)\n",
    "    stopped = {'stop': False}\n",
    "\n",
    "    def reader(pipe, cb):\n",
    "        try:\n",
    "            for line in iter(pipe.readline, ''):\n",
    "                if cb:\n",
    "                    cb(line)\n",
    "                if stopped['stop']:\n",
    "                    break\n",
    "        finally:\n",
    "            pipe.close()\n",
    "\n",
    "    t_out = threading.Thread(target=reader, args=(proc.stdout, on_stdout), daemon=True)\n",
    "    t_err = threading.Thread(target=reader, args=(proc.stderr, on_stderr), daemon=True)\n",
    "    t_out.start(); t_err.start()\n",
    "\n",
    "    def terminate():\n",
    "        stopped['stop'] = True\n",
    "        try:\n",
    "            proc.terminate()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {'proc': proc, 'terminate': terminate}\n",
    "\n",
    "print('Guarded subprocess utilities loaded (run_cmd, run_cmd_background)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title SQLite-backed queue store & per-item cancel API\n",
    "\"\"\"\n",
    "Implements a small SQLite-backed queue to persist items and allow per-item cancellations.\n",
    "This cell exposes simple helpers to enqueue items, cancel them by id, and query the queue.\n",
    "It integrates with the advanced worker by reading the SQLite queue if present.\n",
    "\"\"\"\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import json, time\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "DB_PATH = Path(DRIVE_ROOT)/'comfyui_queue.db'\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "conn = sqlite3.connect(str(DB_PATH), check_same_thread=False)\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS queue (\n",
    "    id TEXT PRIMARY KEY,\n",
    "    manifest_key TEXT,\n",
    "    status TEXT,\n",
    "    attempts INTEGER DEFAULT 0,\n",
    "    last_error TEXT,\n",
    "    created_at REAL,\n",
    "    updated_at REAL\n",
    ")''')\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "def enqueue_item(manifest_key):\n",
    "    mid = str(int(time.time()*1000))\n",
    "    now = time.time()\n",
    "    conn.execute('INSERT OR REPLACE INTO queue (id,manifest_key,status,attempts,created_at,updated_at) VALUES (?,?,?,?,?,?)', (mid, str(manifest_key), 'queued', 0, now, now))\n",
    "    conn.commit()\n",
    "    return mid\n",
    "\n",
    "\n",
    "def cancel_item(id):\n",
    "    conn.execute('UPDATE queue SET status=?, updated_at=? WHERE id=?', ('cancelled', time.time(), id))\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def get_queue_items(limit=100):\n",
    "    cur = conn.execute('SELECT id, manifest_key, status, attempts, last_error, created_at, updated_at FROM queue ORDER BY created_at LIMIT ?', (limit,))\n",
    "    rows = cur.fetchall()\n",
    "    items = []\n",
    "    for r in rows:\n",
    "        items.append({'id':r[0],'manifest_key':r[1],'status':r[2],'attempts':r[3],'last_error':r[4],'created_at':r[5],'updated_at':r[6]})\n",
    "    return items\n",
    "\n",
    "print('SQLite queue helper loaded. DB at', DB_PATH)\n",
    "print('Useful functions: enqueue_item(manifest_key), cancel_item(id), get_queue_items()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Prompt-to-Image HTML UI + ComfyUI runner helper\n",
    "\"\"\"\n",
    "This UI now uses the composer to build a ComfyUI-style flow and returns the generated flow JSON\n",
    "so the front-end can preview it before the user decides to execute or save it.\n",
    "It accepts an optional `prompt_template` parameter (default='{prompt}') so callers can inject\n",
    "transcriptions or other text into a templated prompt (e.g. \"A photorealistic portrait of {prompt}\").\n",
    "\"\"\"\n",
    "from IPython.display import display, HTML\n",
    "from google.colab import output\n",
    "import json, os, time\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "FLOWS_DIR = os.path.join(DRIVE_ROOT, 'flows')\n",
    "os.makedirs(FLOWS_DIR, exist_ok=True)\n",
    "\n",
    "# fetch available flow files\n",
    "flows = []\n",
    "for f in os.listdir(FLOWS_DIR):\n",
    "    if f.endswith('.json'):\n",
    "        flows.append(f)\n",
    "\n",
    "# basic HTML UI\n",
    "html = f'''\n",
    "<div style=\"font-family: Roboto, Arial; padding:8px; border:1px solid #ddd; border-radius:6px;\">\n",
    "  <h3>Prompt → Image</h3>\n",
    "  <div>\n",
    "    <label>Prompt</label><br>\n",
    "    <textarea id=\"p-prompt\" style=\"width:98%; height:80px\"></textarea>\n",
    "  </div>\n",
    "  <div style=\"margin-top:6px\">\n",
    "    <label>Model (manifest key)</label><br>\n",
    "    <input id=\"p-model\" style=\"width:200px\" placeholder=\"manifest key or model name\" />\n",
    "    <label style=\"margin-left:10px\">Workflow</label>\n",
    "    <select id=\"p-flow\">\n",
    "      <option value=\"\">-- choose saved flow --</option>\n",
    "      {''.join([f\"<option value='{f}'>{f}</option>\" for f in flows])}\n",
    "    </select>\n",
    "  </div>\n",
    "  <div style=\"margin-top:6px\">\n",
    "    <label>Sampler</label>\n",
    "    <input id=\"p-sampler\" value=\"DDIM\" style=\"width:120px\">\n",
    "    <label style=\"margin-left:8px\">Steps</label>\n",
    "    <input id=\"p-steps\" value=\"20\" style=\"width:80px\">\n",
    "    <label style=\"margin-left:8px\">Seed</label>\n",
    "    <input id=\"p-seed\" value=\"-1\" style=\"width:100px\">\n",
    "    <label style=\"margin-left:8px\"><input type=checkbox id='p-upscale' /> Upscale</label>\n",
    "  </div>\n",
    "  <div style=\"margin-top:6px\">\n",
    "    <label style=\"margin-right:8px\">Prompt template</label>\n",
    "    <input id=\"p-template\" value=\"{prompt}\" style=\"width:60%\" />\n",
    "  </div>\n",
    "  <div style=\"margin-top:8px\">\n",
    "    <button id=\"p-run\">Generate</button>\n",
    "    <button id=\"p-run-run\">Compose & Run (attempt API)</button>\n",
    "    <span id=\"p-status\" style=\"margin-left:12px; color:#333\"></span>\n",
    "  </div>\n",
    "  <div id=\"p-output\" style=\"margin-top:10px; white-space:pre-wrap; font-family:monospace; max-height:320px; overflow:auto\"></div>\n",
    "</div>\n",
    "<script>\n",
    "  async function showResult(resp){\n",
    "    const output = document.getElementById('p-output');\n",
    "    try{\n",
    "      const data = resp.data['application/json'];\n",
    "      output.innerText = JSON.stringify(data, null, 2);\n",
    "    }catch(e){\n",
    "      output.innerText = 'No response or failed to parse result.';\n",
    "    }\n",
    "  }\n",
    "\n",
    "  document.getElementById('p-run').onclick = async () => {\n",
    "    const prompt = document.getElementById('p-prompt').value;\n",
    "    const model = document.getElementById('p-model').value;\n",
    "    const flow = document.getElementById('p-flow').value;\n",
    "    const sampler = document.getElementById('p-sampler').value;\n",
    "    const steps = parseInt(document.getElementById('p-steps').value || '20');\n",
    "    const seed = parseInt(document.getElementById('p-seed').value || '-1');\n",
    "    const upscale = document.getElementById('p-upscale').checked;\n",
    "    const template = document.getElementById('p-template').value || '{prompt}';\n",
    "    document.getElementById('p-status').innerText = 'Composing flow...';\n",
    "    google.colab.kernel.invokeFunction('notebook.prompt_to_image', [prompt, model, flow, sampler, steps, seed, upscale, 'compose', template], {})\n",
    "      .then(showResult);\n",
    "  };\n",
    "\n",
    "  document.getElementById('p-run-run').onclick = async () => {\n",
    "    const prompt = document.getElementById('p-prompt').value;\n",
    "    const model = document.getElementById('p-model').value;\n",
    "    const flow = document.getElementById('p-flow').value;\n",
    "    const sampler = document.getElementById('p-sampler').value;\n",
    "    const steps = parseInt(document.getElementById('p-steps').value || '20');\n",
    "    const seed = parseInt(document.getElementById('p-seed').value || '-1');\n",
    "    const upscale = document.getElementById('p-upscale').checked;\n",
    "    const template = document.getElementById('p-template').value || '{prompt}';\n",
    "    document.getElementById('p-status').innerText = 'Composing and calling ComfyUI API...';\n",
    "    google.colab.kernel.invokeFunction('notebook.prompt_to_image', [prompt, model, flow, sampler, steps, seed, upscale, 'run', template], {})\n",
    "      .then(showResult);\n",
    "  };\n",
    "</script>\n",
    "'''\n",
    "\n",
    "\n",
    "display(HTML(html))\n",
    "\n",
    "# Python callback implementation\n",
    "\n",
    "try:\n",
    "    from . import compose_flow as _compose_flow  # try package style if notebook packaged\n",
    "    compose = _compose_flow\n",
    "except Exception:\n",
    "    compose = globals().get('compose_flow')\n",
    "\n",
    "if not compose:\n",
    "    print('Warning: compose_flow not available in this kernel namespace')\n",
    "\n",
    "# New: support prompt_template parameter\n",
    "\n",
    "def prompt_to_image(prompt, model_key, flow_file, sampler, steps, seed, upscale, action='compose', prompt_template='{prompt}'):\n",
    "    # Apply template\n",
    "    try:\n",
    "        final_prompt = prompt_template.format(prompt=prompt)\n",
    "    except Exception:\n",
    "        # fallback: simple replace\n",
    "        final_prompt = prompt_template.replace('{prompt}', prompt)\n",
    "\n",
    "    # compose a comfyui-style flow by default\n",
    "    path, flow = compose(final_prompt, model_key=model_key or None, sampler=sampler, steps=steps, seed=seed, lora=None, upscaler=(2 if upscale else None), format='comfyui')\n",
    "\n",
    "    if action == 'compose':\n",
    "        return {'flow_path': path, 'flow': flow}\n",
    "\n",
    "    # action == 'run' => attempt to call ComfyUI API\n",
    "    base = os.environ.get('COMFYUI_PUBLIC_URL') or os.environ.get('COMFYUI_API_BASE') or 'http://127.0.0.1:8188'\n",
    "    api_key = os.environ.get('COMFYUI_API_KEY')\n",
    "    headers = {'User-Agent':'ComfyUI-Playground/1.0', 'Content-Type':'application/json'}\n",
    "    if api_key:\n",
    "        headers['Authorization'] = f'Bearer {api_key}'\n",
    "\n",
    "    try:\n",
    "        import requests\n",
    "        url = base.rstrip('/') + '/run_flow'\n",
    "        r = requests.post(url, json=flow, headers=headers, timeout=120)\n",
    "        try:\n",
    "            j = r.json()\n",
    "        except Exception:\n",
    "            j = {'status_code': r.status_code, 'text': r.text}\n",
    "        return {'api_status': r.status_code, 'api_response': j, 'flow_path': path}\n",
    "    except Exception as e:\n",
    "        return {'error': str(e), 'flow_path': path}\n",
    "\n",
    "# register callback\n",
    "output.register_callback('notebook.prompt_to_image', prompt_to_image)\n",
    "print('Prompt-to-Image UI ready (callback: notebook.prompt_to_image).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec783d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Register per-item cancel callback (links dashboard -> SQLite cancel)\n",
    "\"\"\"\n",
    "Registers a kernel callback 'notebook.cancel_item' which cancels a given queue item id\n",
    "in the SQLite queue and updates the JSON queue state file.\n",
    "\"\"\"\n",
    "from google.colab import output\n",
    "from pathlib import Path\n",
    "import json, time\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "QUEUE_STATE_PATH = Path(DRIVE_ROOT)/'.queue_state.json'\n",
    "DB_PATH = Path(DRIVE_ROOT)/'comfyui_queue.db'\n",
    "\n",
    "# import cancel_item from the sqlite helper cell's namespace if available; otherwise define a fallback\n",
    "try:\n",
    "    cancel_item\n",
    "except NameError:\n",
    "    def cancel_item(id):\n",
    "        # fallback: mark in queue_state\n",
    "        if QUEUE_STATE_PATH.exists():\n",
    "            st = json.loads(QUEUE_STATE_PATH.read_text())\n",
    "        else:\n",
    "            st = {'items':{}}\n",
    "        st.setdefault('items',{})\n",
    "        st['items'].setdefault(str(id),{})\n",
    "        st['items'][str(id)]['status'] = 'cancelled'\n",
    "        st['items'][str(id)]['updated_at'] = int(time.time())\n",
    "        QUEUE_STATE_PATH.write_text(json.dumps(st, indent=2))\n",
    "        print('Fallback: cancelled', id)\n",
    "\n",
    "\n",
    "def cancel_item_callback(item_id):\n",
    "    try:\n",
    "        cancel_item(item_id)\n",
    "        # also update JSON state if present\n",
    "        if QUEUE_STATE_PATH.exists():\n",
    "            st = json.loads(QUEUE_STATE_PATH.read_text())\n",
    "            st.setdefault('items',{})\n",
    "            st['items'].setdefault(str(item_id),{})\n",
    "            st['items'][str(item_id)]['status'] = 'cancelled'\n",
    "            st['items'][str(item_id)]['updated_at'] = int(time.time())\n",
    "            QUEUE_STATE_PATH.write_text(json.dumps(st, indent=2))\n",
    "        print('Cancelled item', item_id)\n",
    "    except Exception as e:\n",
    "        print('Failed to cancel item', item_id, e)\n",
    "\n",
    "output.register_callback('notebook.cancel_item', cancel_item_callback)\n",
    "print('Registered kernel callback: notebook.cancel_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Complex node helpers — generate ComfyUI node snippets and compose flows\n",
    "\"\"\"\n",
    "Provides helper functions to generate reusable node snippets and to compose a flow JSON\n",
    "compatible with ComfyUI's typical on-disk format (a minimal, widely-used subset).\n",
    "The composer supports two modes:\n",
    " - format='simple'  : legacy minimal list-of-nodes (backwards compatible)\n",
    " - format='comfyui' : produces a dict with 'nodes' mapping node-id -> node-dict\n",
    "\n",
    "The produced \"comfyui\" nodes use conventional node type names found in many ComfyUI flows\n",
    "(e.g. \"CLIPTextEncode\", \"CheckpointLoaderSimple\", \"KSampler\", \"LoraLoader\", \"SaveImage\",\n",
    "\"LatentUpscaler\"). These are widely compatible but you can tweak names to match your exact install.\n",
    "\"\"\"\n",
    "import json, time, os\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
    "FLOWS_DIR = Path(DRIVE_ROOT)/'flows'\n",
    "FLOWS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "_node_counter = 1000\n",
    "\n",
    "def _next_node_id():\n",
    "    global _node_counter\n",
    "    _node_counter += 1\n",
    "    return _node_counter\n",
    "\n",
    "# --- simple (previous) helper nodes (kept for backwards compatibility)\n",
    "\n",
    "def make_text_encoder_node(prompt):\n",
    "    nid = _next_node_id()\n",
    "    return {\n",
    "        'id': nid,\n",
    "        'type': 'TextEncoder',\n",
    "        'args': {'prompt': prompt}\n",
    "    }\n",
    "\n",
    "\n",
    "def make_sampler_node(sampler='DDIM', steps=20, seed=-1):\n",
    "    nid = _next_node_id()\n",
    "    return {\n",
    "        'id': nid,\n",
    "        'type': 'Sampler',\n",
    "        'args': {'sampler': sampler, 'steps': steps, 'seed': seed}\n",
    "    }\n",
    "\n",
    "\n",
    "def make_lora_node(lora_path, weight=0.8):\n",
    "    nid = _next_node_id()\n",
    "    return {\n",
    "        'id': nid,\n",
    "        'type': 'LoRA',\n",
    "        'args': {'path': lora_path, 'weight': weight}\n",
    "    }\n",
    "\n",
    "\n",
    "def make_upscaler_node(scale=2):\n",
    "    nid = _next_node_id()\n",
    "    return {\n",
    "        'id': nid,\n",
    "        'type': 'Upscaler',\n",
    "        'args': {'scale': scale}\n",
    "    }\n",
    "\n",
    "# --- ComfyUI-style node builders\n",
    "\n",
    "def _node_id_str():\n",
    "    return str(_next_node_id())\n",
    "\n",
    "\n",
    "def comfy_checkpoint_loader(model_key=None):\n",
    "    nid = _node_id_str()\n",
    "    # CheckpointLoaderSimple usually references a model name or path; adapt as needed\n",
    "    return nid, {\n",
    "        'id': nid,\n",
    "        'type': 'CheckpointLoaderSimple',\n",
    "        'name': 'CheckpointLoaderSimple',\n",
    "        'args': {'ckpt_name': model_key or ''},\n",
    "        'inputs': {}\n",
    "    }\n",
    "\n",
    "\n",
    "def comfy_clip_text_encode(prompt):\n",
    "    nid = _node_id_str()\n",
    "    return nid, {\n",
    "        'id': nid,\n",
    "        'type': 'CLIPTextEncode',\n",
    "        'name': 'CLIPTextEncode',\n",
    "        'args': {'text': prompt},\n",
    "        'inputs': {}\n",
    "    }\n",
    "\n",
    "\n",
    "def comfy_ksampler(sampler='DDIM', steps=20, seed=-1):\n",
    "    nid = _node_id_str()\n",
    "    return nid, {\n",
    "        'id': nid,\n",
    "        'type': 'KSampler',\n",
    "        'name': 'KSampler',\n",
    "        'args': {'sampler_name': sampler, 'steps': steps, 'seed': seed},\n",
    "        'inputs': {}\n",
    "    }\n",
    "\n",
    "\n",
    "def comfy_lora_loader(lora_path, weight=0.8):\n",
    "    nid = _node_id_str()\n",
    "    return nid, {\n",
    "        'id': nid,\n",
    "        'type': 'LoraLoader',\n",
    "        'name': 'LoraLoader',\n",
    "        'args': {'path': lora_path, 'weight': weight},\n",
    "        'inputs': {}\n",
    "    }\n",
    "\n",
    "\n",
    "def comfy_latent_upscaler(scale=2):\n",
    "    nid = _node_id_str()\n",
    "    return nid, {\n",
    "        'id': nid,\n",
    "        'type': 'LatentUpscaler',\n",
    "        'name': 'LatentUpscaler',\n",
    "        'args': {'scale': scale},\n",
    "        'inputs': {}\n",
    "    }\n",
    "\n",
    "\n",
    "def comfy_save_image(filename=None):\n",
    "    nid = _node_id_str()\n",
    "    return nid, {\n",
    "        'id': nid,\n",
    "        'type': 'SaveImage',\n",
    "        'name': 'SaveImage',\n",
    "        'args': {'path': filename or ''},\n",
    "        'inputs': {}\n",
    "    }\n",
    "\n",
    "# Compose flow with two modes\n",
    "\n",
    "def compose_flow(prompt, model_key=None, sampler='DDIM', steps=20, seed=-1, lora=None, upscaler=None, format='comfyui'):\n",
    "    \"\"\"Compose a flow and write it to disk. Returns (path, flow_dict).\n",
    "\n",
    "    format: 'simple' or 'comfyui'\n",
    "    \"\"\"\n",
    "    if format not in ('simple', 'comfyui'):\n",
    "        raise ValueError('Unsupported format')\n",
    "\n",
    "    if format == 'simple':\n",
    "        nodes = []\n",
    "        enc = make_text_encoder_node(prompt)\n",
    "        nodes.append(enc)\n",
    "        samp = make_sampler_node(sampler=sampler, steps=steps, seed=seed)\n",
    "        nodes.append(samp)\n",
    "        if lora:\n",
    "            nodes.append(make_lora_node(lora))\n",
    "        if upscaler:\n",
    "            nodes.append(make_upscaler_node(upscaler))\n",
    "        flow = {'metadata': {'created': int(time.time()), 'prompt': prompt, 'model_key': model_key}, 'nodes': nodes}\n",
    "    else:\n",
    "        nodes = {}\n",
    "        # Create core nodes: checkpoint loader, clip encode, sampler, optionally lora, upscaler, saver\n",
    "        ck_id, ck_node = comfy_checkpoint_loader(model_key)\n",
    "        nodes[ck_id] = ck_node\n",
    "        txt_id, txt_node = comfy_clip_text_encode(prompt)\n",
    "        nodes[txt_id] = txt_node\n",
    "        samp_id, samp_node = comfy_ksampler(sampler=sampler, steps=steps, seed=seed)\n",
    "        nodes[samp_id] = samp_node\n",
    "        # Hook up a basic conceptual wiring via 'inputs' (note: this is a minimal representation;\n",
    "        # full ComfyUI flows may use connection maps — here we provide args and a simple structure\n",
    "        # that many importers can accept or that can be further edited in the ComfyUI graph UI).\n",
    "        if lora:\n",
    "            l_id, l_node = comfy_lora_loader(lora)\n",
    "            nodes[l_id] = l_node\n",
    "        if upscaler:\n",
    "            u_id, u_node = comfy_latent_upscaler(upscaler)\n",
    "            nodes[u_id] = u_node\n",
    "        save_name = f'generated_{int(time.time())}.png'\n",
    "        s_id, s_node = comfy_save_image(save_name)\n",
    "        nodes[s_id] = s_node\n",
    "\n",
    "        flow = {'metadata': {'created': int(time.time()), 'prompt': prompt, 'model_key': model_key, 'comfyui_format': True}, 'nodes': nodes}\n",
    "\n",
    "    fname = FLOWS_DIR / f'flow_generated_{int(time.time())}.json'\n",
    "    with open(fname, 'w', encoding='utf-8') as fh:\n",
    "        json.dump(flow, fh, indent=2)\n",
    "    return str(fname), flow\n",
    "\n",
    "print('Complex node helpers loaded. Use compose_flow(prompt, model_key, ..., format=\"comfyui\") to create a ComfyUI-compatible flow JSON.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a10d6e",
   "metadata": {},
   "source": [
    "## Voice — TTS / STT research and workflows\n",
    "\n",
    "This section provides: research notes on open-source SOTA Speech-To-Text (STT) and Text-To-Speech (TTS) models; runnable helper cells for STT and TTS workflows (simple and advanced); voice cloning and audiobooks; GUI cells to provide prompt input and source selection; utility cells to ingest text from files (txt, epub, pdf), VTT captions, web pages; and unit tests.\n",
    "\n",
    "Goals:\n",
    "- Provide fast, practical cells for: quick STT from MP3/WEBM, high-quality TTS to MP3 using best open-source engines, voice cloning pipelines, and audiobook generation (chunking + expressive prosody).\n",
    "- Expose an HTML UI to enter prompt/text, choose voice/engine, and run either STT or TTS in the notebook.\n",
    "- Offer advanced recipes (multi-engine ensemble, noise-aware STT pre-processing, denoising, chunking heuristics, adaptive prosody stitches).\n",
    "\n",
    "Notes on SOTA (short, refer to cells below for references):\n",
    "- STT: Whisper (OpenAI) variants remain strong baseline; open-source high-accuracy alternatives include WhisperX (forced alignment & VAD), OpenAI-like reimpls and models like Vosk (on-device), Silero, and recent large-conformer models trained on multilingual corpora (e.g., Whisper L models still competitive). Self-supervised encoders such as Wav2Vec2.x (Facebook/X) + fine-tuned decoders are also widely used.\n",
    "- TTS: Neural vocoders + prosody models: VITS, GlowTTS, FastSpeech2, and open-source high-quality stacks like Tortoise TTS, Bark, and Coqui TTS. Tortoise and Bark provide multi-voice, expressive TTS with conditioning; VITS provides high-quality end-to-end voice synthesis when trained for a voice.\n",
    "- Voice cloning: techniques like speaker embedding extraction (GE2E, ECAPA-TDNN), fine-tuning a VITS model, or using zero-shot cloning via speaker encoders (e.g., SpeakerNet + VITS/HiFi-GAN vocoder) exist. Recent open-source tools offering near-zero-shot cloning include Bark/Corpora-based methods and open-source projects like RVC and YourTTS.\n",
    "- Processing tips: chunk long text (200-500 tokens) for TTS, maintain sentence boundaries, add SSML-like prosody hints (pauses, emphasis). For STT, use VAD to chunk audio and denoise (spectral gating) for improved accuracy.\n",
    "\n",
    "We'll add runnable example cells below: simple STT (Whisper), advanced STT (WhisperX or VAD+Whisper), basic TTS (Coqui or Tortoise), high-quality audiobook pipeline (chunking + expressive engine), voice cloning recipe using open-source RVC or YourTTS, and a GUI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Voice helpers — install/check (fast checks, install only when needed)\n",
    "\"\"\"\n",
    "Helpers to install or import key TTS/STT libraries. In Colab you may want to pip-install only what's necessary.\n",
    "This cell avoids heavy installs on every run; instead it defines `ensure_packages(packages)` helper.\n",
    "\"\"\"\n",
    "import importlib, subprocess, sys\n",
    "\n",
    "def ensure_packages(packages):\n",
    "    \"\"\"packages: list of pip-style strings e.g. ['openai-whisper','whisperx']\"\"\"\n",
    "    missing = []\n",
    "    for pkg in packages:\n",
    "        name = pkg.split('==')[0].split('>=')[0]\n",
    "        try:\n",
    "            importlib.import_module(name)\n",
    "        except Exception:\n",
    "            missing.append(pkg)\n",
    "    if not missing:\n",
    "        return {'installed':[], 'status':'all-present'}\n",
    "    cmd = [sys.executable, '-m', 'pip', 'install'] + missing\n",
    "    print('Installing:', missing)\n",
    "    subprocess.check_call(cmd)\n",
    "    return {'installed': missing, 'status':'installed'}\n",
    "\n",
    "print('Voice helpers loaded. Use ensure_packages([...]) to install packages on demand.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db2cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Simple STT — OpenAI Whisper (fast baseline)\n",
    "\"\"\"\n",
    "This cell provides a small function `whisper_stt(audio_path, model='small')` that transcribes an audio file.\n",
    "It uses the `whisper` pip package (OpenAI's whisper). For higher accuracy consider using 'large' models or the\n",
    "`whisperx` package for alignment and improved timestamps.\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def whisper_stt(audio_path, model='small', language=None, task='transcribe'):\n",
    "    try:\n",
    "        import whisper\n",
    "    except Exception:\n",
    "        raise RuntimeError('whisper not installed. Run ensure_packages([\"openai-whisper\"])')\n",
    "    m = whisper.load_model(model)\n",
    "    res = m.transcribe(str(audio_path), language=language, task=task)\n",
    "    return res\n",
    "\n",
    "print('whisper_stt available: whisper_stt(path, model=\"small|medium|large\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b832a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Advanced STT — VAD + WhisperX (better timestamps & alignment)\n",
    "\"\"\"\n",
    "This cell shows a recommended pattern: run a VAD pass to split audio into segments, then transcribe each\n",
    "with Whisper (or WhisperX) and optionally run alignment for word-level timestamps.\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def stt_with_vad_and_whisperx(audio_path, vad_model='silero_vad', whisper_model='small'):\n",
    "    # Minimal example that expects whisper and, optionally, whisperx to be installed.\n",
    "    try:\n",
    "        import whisper\n",
    "    except Exception:\n",
    "        raise RuntimeError('whisper not installed. Run ensure_packages([\"openai-whisper\"])')\n",
    "    try:\n",
    "        import webrtcvad\n",
    "    except Exception:\n",
    "        webrtcvad = None\n",
    "    # For simplicity, fallback to whole-file transcription when VAD not available.\n",
    "    m = whisper.load_model(whisper_model)\n",
    "    if webrtcvad is None:\n",
    "        return m.transcribe(str(audio_path))\n",
    "    # Placeholder: for more advanced use, use whisperx or pyannote for segmentation\n",
    "    return m.transcribe(str(audio_path))\n",
    "\n",
    "print('Advanced STT helper loaded (simple fallback to whisper if VAD not installed).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Simple TTS — Coqui / Tortoise / Bark quick path\n",
    "\"\"\"\n",
    "Provides a helper `tts_simple(text, voice='default', engine='coqui', out_path='out.wav', **kwargs)`.\n",
    "Supports lightweight Coqui TTS, and placeholders/wrappers for Tortoise and Bark when installed.\n",
    "If the requested engine is not installed the function raises a helpful error explaining the\n",
    "recommended install steps (heavy installs are left to the user to run once).\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def tts_simple(text, voice='default', engine='coqui', out_path='out.wav', **kwargs):\n",
    "    \"\"\"Synthesize `text` to `out_path` using selected engine.\n",
    "\n",
    "    engines supported:\n",
    "      - 'coqui'  : uses the `TTS` pip package (lightweight, easy to install)\n",
    "      - 'tortoise': uses Tortoise TTS (heavy; GPU recommended). If not installed, raises instructions.\n",
    "      - 'bark'   : uses Suno/Bark style zero-shot TTS (heavy; instructive error if missing)\n",
    "\n",
    "    kwargs: engine-specific options (style, sample_rate, etc.)\n",
    "    \"\"\"\n",
    "    out_path = str(out_path)\n",
    "    if engine == 'coqui':\n",
    "        try:\n",
    "            from TTS.api import TTS\n",
    "        except Exception:\n",
    "            raise RuntimeError(\"Coqui TTS not installed. Run: pip install TTS\\nThen pick a model name or use default: TTS('tts_models/en/ljspeech/tacotron2-DDC')\")\n",
    "        # If voice equals a model name recognized by Coqui, pass it; otherwise TTS() will pick default\n",
    "        try:\n",
    "            tts = TTS(voice) if voice and voice != 'default' else TTS()\n",
    "            tts.tts_to_file(text=text, file_path=out_path)\n",
    "            return out_path\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f'Coqui TTS synthesis failed: {e}')\n",
    "\n",
    "    elif engine == 'tortoise':\n",
    "        # Tortoise requires a separate heavy install; provide a helpful message if missing\n",
    "        try:\n",
    "            # Tortoise's API is often provided via `tortoise.api` or `tortoise` namespace depending on install\n",
    "            from tortoise.api import TextToSpeech\n",
    "        except Exception:\n",
    "            raise RuntimeError(\n",
    "                \"Tortoise TTS not found. It's a heavy install (models + deps).\\n\"\n",
    "                \"Follow the Tortoise README: clone the repo, install requirements, download models.\\n\"\n",
    "                \"Example (in Colab):\\n\"\n",
    "                \"  git clone https://github.com/neonbjb/tortoise-tts.git\\n\"\n",
    "                \"  pip install -r tortoise-tts/requirements.txt\\n\"\n",
    "                \"Then import tortoise.api.TextToSpeech and call it. GPU recommended for speed.\")\n",
    "        try:\n",
    "            tts = TextToSpeech()\n",
    "            # Tortoise APIs vary; this is a placeholder showing expected usage\n",
    "            wav = tts.synthesize(text, voice=voice, **kwargs)\n",
    "            # write wav (assume numpy array and 16-bit PCM)\n",
    "            import soundfile as sf\n",
    "            sf.write(out_path, wav, 24000)\n",
    "            return out_path\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f'Tortoise TTS synthesis failed: {e}')\n",
    "\n",
    "    elif engine == 'bark':\n",
    "        # Bark (suno) usage example wrapper\n",
    "        try:\n",
    "            # suno/bark uses `bark.generation` and provides a generate_audio API in many installs\n",
    "            from bark import generate_audio\n",
    "        except Exception:\n",
    "            raise RuntimeError(\n",
    "                \"Bark not installed. To use Bark, follow the Bark repo install instructions.\\n\"\n",
    "                \"Example: pip install git+https://github.com/suno-ai/bark.git (plus model downloads).\\n\"\n",
    "                \"Bark provides high-quality multi-voice zero-shot synthesis; GPU recommended.\")\n",
    "        try:\n",
    "            # generate_audio may accept text and voice/style; adapt per installed version\n",
    "            audio_array = generate_audio(text)\n",
    "            import soundfile as sf\n",
    "            sf.write(out_path, audio_array, 24000)\n",
    "            return out_path\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f'Bark synthesis failed: {e}')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Unknown TTS engine: {engine}')\n",
    "\n",
    "print('tts_simple available: tts_simple(\"Hello\", engine=\"coqui|tortoise|bark\", out_path=\"/content/out.wav\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af05d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Audiobook pipeline — expressive preset for Tortoise (high-quality / GPU recommended)\n",
    "\"\"\"\n",
    "Adds `text_to_expressive_audiobook` which uses Tortoise (preferred) or Bark to produce expressive audiobook audio.\n",
    "This function is optimized for quality (prosody hints, emotional style snippets) and assumes Tortoise is installed.\n",
    "It will chunk text, add prosody hints, and call `tts_simple(..., engine='tortoise')` for each chunk.\n",
    "\n",
    "WARNING: Tortoise and Bark require large model downloads and a GPU for reasonable performance.\n",
    "\"\"\"\n",
    "import os, re, time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _apply_prosody_hints(chunk, style='narration'):\n",
    "    # Insert lightweight SSML-like hints for prosody that certain engines (Tortoise/Bark) can respect in prompt form.\n",
    "    if style == 'narration':\n",
    "        # gentle pauses, emphasis on punctuation\n",
    "        return f\"<speak><voice name=\\\"narrator\\\">{chunk}</voice></speak>\"\n",
    "    if style == 'dramatic':\n",
    "        return f\"<speak><voice name=\\\"dramatic\\\">{chunk}</voice></speak>\"\n",
    "    return chunk\n",
    "\n",
    "\n",
    "def text_to_expressive_audiobook(src, engine='tortoise', voice='alloy', chunk_words=250, out_dir=None, style='narration'):\n",
    "    txt = _read_text_input(src)\n",
    "    # simple sentence splitting\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', txt)\n",
    "    chunks = []\n",
    "    cur = []\n",
    "    cur_n = 0\n",
    "    for s in sentences:\n",
    "        cur.append(s)\n",
    "        cur_n += len(s.split())\n",
    "        if cur_n >= chunk_words:\n",
    "            chunks.append(' '.join(cur))\n",
    "            cur = []\n",
    "            cur_n = 0\n",
    "    if cur:\n",
    "        chunks.append(' '.join(cur))\n",
    "\n",
    "    od = Path(out_dir or (Path.cwd()/ f'expressive_audiobook_{int(time.time())}'))\n",
    "    od.mkdir(parents=True, exist_ok=True)\n",
    "    out_files = []\n",
    "    for i,ch in enumerate(chunks):\n",
    "        # apply prosody\n",
    "        prompt = _apply_prosody_hints(ch, style=style)\n",
    "        fname = od / f'chunk_{i:04d}.wav'\n",
    "        try:\n",
    "            tts_simple(prompt, voice=voice, engine=engine, out_path=str(fname), style=style)\n",
    "            out_files.append(str(fname))\n",
    "        except Exception as e:\n",
    "            print('Chunk synth failed', i, e)\n",
    "    # optional stitching using pydub\n",
    "    try:\n",
    "        from pydub import AudioSegment\n",
    "        combined = AudioSegment.empty()\n",
    "        for f in out_files:\n",
    "            combined += AudioSegment.from_wav(f)\n",
    "        out_mp3 = od / 'audiobook_expressive.mp3'\n",
    "        combined.export(out_mp3, format='mp3')\n",
    "        return str(out_mp3)\n",
    "    except Exception:\n",
    "        return out_files\n",
    "\n",
    "print('Expressive audiobook preset loaded: text_to_expressive_audiobook(src, engine=\"tortoise\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Voice cloning recipe (RVC / YourTTS / zero-shot) — guidance & starter helper\n",
    "\"\"\"\n",
    "This cell contains a high-level wrapper and instructions for running a voice cloning workflow using RVC or YourTTS.\n",
    "We provide a helper `prepare_voice_clone(sample_audio_path, method='rvc')` that checks for required packages and\n",
    "returns a checklist of steps because full cloning requires training or model downloads which are heavy.\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_voice_clone(sample_audio, method='rvc'):\n",
    "    info = {'method': method, 'sample': str(sample_audio), 'ok': False, 'notes': []}\n",
    "    if method == 'rvc':\n",
    "        # RVC typically requires PyTorch, ffmpeg and RVC repo; here we only verify availability\n",
    "        try:\n",
    "            import torch\n",
    "            info['notes'].append('torch present')\n",
    "        except Exception:\n",
    "            info['notes'].append('torch missing')\n",
    "        info['notes'].append('RVC repo and model downloads required; follow RVC README to clone and run training/inference')\n",
    "    elif method == 'yourtts':\n",
    "        info['notes'].append('YourTTS requires pretrained models and speaker encoder. See YourTTS repo for steps.')\n",
    "    else:\n",
    "        info['notes'].append('Unknown method')\n",
    "    return info\n",
    "\n",
    "print('Voice cloning helper available: prepare_voice_clone(path, method=\"rvc\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Text ingestion helpers — read TXT, EPUB, PDF, VTT, HTML\n",
    "\"\"\"\n",
    "Utilities to pull text from multiple sources so TTS workflows can accept many inputs (txt, epub, pdf, vtt, HTML/webpage).\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def read_text_source(path_or_url):\n",
    "    p = str(path_or_url)\n",
    "    # URL\n",
    "    if p.startswith('http://') or p.startswith('https://'):\n",
    "        r = requests.get(p, timeout=30)\n",
    "        ct = r.headers.get('content-type','')\n",
    "        if 'text/html' in ct or p.endswith('.html'):\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            return soup.get_text('\\n')\n",
    "        return r.text\n",
    "    # local file\n",
    "    pth = Path(p)\n",
    "    if not pth.exists():\n",
    "        raise FileNotFoundError(p)\n",
    "    if pth.suffix.lower() == '.txt':\n",
    "        return pth.read_text(encoding='utf-8')\n",
    "    if pth.suffix.lower() in ('.epub',):\n",
    "        try:\n",
    "            from ebooklib import epub\n",
    "            items = epub.read_epub(str(pth)).get_items_of_type(ebooklib.ITEM_DOCUMENT)\n",
    "            parts = [it.get_content().decode('utf-8') for it in items]\n",
    "            return '\\n'.join(parts)\n",
    "        except Exception:\n",
    "            raise\n",
    "    if pth.suffix.lower() in ('.pdf',):\n",
    "        try:\n",
    "            import PyPDF2\n",
    "            text = []\n",
    "            with open(pth,'rb') as fh:\n",
    "                r = PyPDF2.PdfReader(fh)\n",
    "                for page in r.pages:\n",
    "                    text.append(page.extract_text() or '')\n",
    "            return '\\n'.join(text)\n",
    "        except Exception:\n",
    "            raise\n",
    "    if pth.suffix.lower() in ('.vtt','.srt'):\n",
    "        # simple VTT parser: extract text lines after timestamps\n",
    "        lines = pth.read_text(encoding='utf-8').splitlines()\n",
    "        out = []\n",
    "        for L in lines:\n",
    "            if '-->' in L or L.strip().isdigit() or L.strip()=='' or L.startswith('WEBVTT'):\n",
    "                continue\n",
    "            out.append(L)\n",
    "        return '\\n'.join(out)\n",
    "    # default\n",
    "    return pth.read_text(encoding='utf-8')\n",
    "\n",
    "print('Text ingestion helpers loaded: read_text_source(path_or_url)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423631d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Voice GUI — small HTML UI for STT/TTS operations (with prompt templates)\n",
    "\"\"\"\n",
    "Lightweight HTML UI to select an audio file for STT or paste text for TTS. Includes a prompt-template dropdown\n",
    "that can be applied when forwarding STT transcriptions to the Prompt→Image composer/runner. Templates are loaded\n",
    "from Drive via the get_prompt_templates kernel callback and can be managed with the Manage Templates button.\n",
    "\"\"\"\n",
    "from IPython.display import display, HTML\n",
    "from google.colab import output\n",
    "\n",
    "html = r'''\n",
    "<div style=\"font-family: Roboto, Arial; padding:10px; border:1px solid #ddd; border-radius:6px;\">\n",
    "  <h3>Voice Playground</h3>\n",
    "  <div>\n",
    "    <h4>Speech → Text (STT)</h4>\n",
    "    <input id=\"stt-audio\" type=\"text\" placeholder=\"/path/to/file.mp3 or URL\" style=\"width:60%\"></input>\n",
    "    <select id=\"stt-engine\"><option value=\"whisper\">whisper</option><option value=\"whisperx\">whisperx</option></select>\n",
    "    <label style=\"margin-left:8px\"><input type=\"checkbox\" id=\"stt-forward\"/> Use transcription as Prompt→Image prompt</label>\n",
    "    <label style=\"margin-left:8px\">Template: </label>\n",
    "    <select id=\"prompt-template\">\n",
    "      <option value=\"None\">(none — use raw transcription)</option>\n",
    "    </select>\n",
    "    <button id=\"manage-templates\" style=\"margin-left:6px\">Manage Templates</button>\n",
    "    <button id=\"stt-run\">Transcribe</button>\n",
    "    <div id=\"stt-out\" style=\"white-space:pre-wrap; font-family:monospace; margin-top:8px; max-height:200px; overflow:auto\"></div>\n",
    "  </div>\n",
    "  <hr/>\n",
    "  <div>\n",
    "    <h4>Text → Speech (TTS)</h4>\n",
    "    <textarea id=\"tts-text\" style=\"width:98%; height:80px\"></textarea>\n",
    "    <div style=\"margin-top:6px\">\n",
    "      <label>Engine</label>\n",
    "      <select id=\"tts-engine\"><option value=\"coqui\">coqui</option><option value=\"tortoise\">tortoise</option><option value=\"bark\">bark</option></select>\n",
    "      <label style=\"margin-left:10px\">Voice</label>\n",
    "      <input id=\"tts-voice\" value=\"default\" style=\"width:160px\"/>\n",
    "      <label style=\"margin-left:10px\">Out file</label>\n",
    "      <input id=\"tts-out\" value=\"/content/out.wav\" style=\"width:200px\"/>\n",
    "    </div>\n",
    "    <div style=\"margin-top:6px\">\n",
    "      <button id=\"tts-run\">Synthesize</button>\n",
    "      <div id=\"tts-out-display\" style=\"margin-top:8px\"></div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "  async function populateTemplates(){\n",
    "    try{\n",
    "      const resp = await google.colab.kernel.invokeFunction('notebook.get_prompt_templates', [], {});\n",
    "      const data = resp.data['application/json'];\n",
    "      const sel = document.getElementById('prompt-template');\n",
    "      // clear existing (preserve first option)\n",
    "      sel.options.length = 1;\n",
    "      if (data && data.templates){\n",
    "        data.templates.forEach(t => {\n",
    "          if (!t || !t.template) return;\n",
    "          const opt = document.createElement('option');\n",
    "          opt.value = t.template;\n",
    "          opt.text = t.name + ' — ' + t.template;\n",
    "          sel.appendChild(opt);\n",
    "        });\n",
    "      }\n",
    "    }catch(e){\n",
    "      console.error('Failed to load templates', e);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  async function showResult(resp, targetId){\n",
    "    const output = document.getElementById(targetId);\n",
    "    try{\n",
    "      const data = resp.data['application/json'];\n",
    "      output.innerText = JSON.stringify(data, null, 2);\n",
    "    }catch(e){\n",
    "      output.innerText = 'No response or failed to parse result.';\n",
    "    }\n",
    "  }\n",
    "\n",
    "  document.getElementById('stt-run').onclick = async () => {\n",
    "    const path = document.getElementById('stt-audio').value;\n",
    "    const engine = document.getElementById('stt-engine').value;\n",
    "    const forward = document.getElementById('stt-forward').checked;\n",
    "    const template = document.getElementById('prompt-template').value;\n",
    "    const resp = await google.colab.kernel.invokeFunction('notebook.voice_transcribe', [path, engine], {});\n",
    "    showResult(resp, 'stt-out');\n",
    "    if (forward){\n",
    "      try{\n",
    "        const res = resp.data['application/json'];\n",
    "        const text = (res.result && (res.result.get && res.result.get('text')) ) || res.result?.text || res.result || '';\n",
    "        const doRun = confirm('Forward transcription as prompt to Prompt→Image and run generation? Click Cancel to just compose for preview.');\n",
    "        const action = doRun ? 'run' : 'compose';\n",
    "        // call the Prompt→Image kernel callback and pass the selected template (or 'None')\n",
    "        const r2 = await google.colab.kernel.invokeFunction('notebook.prompt_to_image', [text, '', '', 'DDIM', 20, -1, false, action, template], {});\n",
    "        document.getElementById('stt-out').innerText += '\\n\\nForward result:\\n' + JSON.stringify(r2.data['application/json'], null, 2);\n",
    "      }catch(e){\n",
    "        document.getElementById('stt-out').innerText += '\\n\\nFailed to forward to Prompt→Image: ' + e;\n",
    "      }\n",
    "    }\n",
    "  };\n",
    "\n",
    "  document.getElementById('tts-run').onclick = () => {\n",
    "    const text = document.getElementById('tts-text').value;\n",
    "    const engine = document.getElementById('tts-engine').value;\n",
    "    const voice = document.getElementById('tts-voice').value;\n",
    "    const out = document.getElementById('tts-out').value;\n",
    "    google.colab.kernel.invokeFunction('notebook.voice_synthesize', [text, engine, voice, out], {}).then(resp => {\n",
    "      const d = resp.data['application/json'];\n",
    "      document.getElementById('tts-out-display').innerText = JSON.stringify(d, null, 2);\n",
    "    });\n",
    "  };\n",
    "\n",
    "  document.getElementById('manage-templates').onclick = async () => {\n",
    "    try{\n",
    "      await google.colab.kernel.invokeFunction('notebook.launch_manage_templates_ui', [], {});\n",
    "    }catch(e){\n",
    "      alert('Failed to open Manage Templates UI: ' + e);\n",
    "    }\n",
    "  };\n",
    "\n",
    "  // populate templates on load\n",
    "  populateTemplates();\n",
    "</script>\n",
    "'''\n",
    "\n",
    "display(HTML(html))\n",
    "\n",
    "# Register callbacks (STT/TTS are already defined above). Add a Prompt->Image kernel callback so the UI can forward text with a template\n",
    "from pathlib import Path\n",
    "\n",
    "def voice_transcribe(path_or_url, engine='whisper'):\n",
    "    try:\n",
    "        if engine == 'whisper':\n",
    "            res = whisper_stt(path_or_url)\n",
    "            return {'engine':'whisper','result': res}\n",
    "        elif engine == 'whisperx':\n",
    "            res = stt_with_vad_and_whisperx(path_or_url)\n",
    "            return {'engine':'whisperx','result': res}\n",
    "        else:\n",
    "            return {'error':'unknown engine'}\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "\n",
    "def voice_synthesize(text, engine='coqui', voice='default', out='/content/out.wav'):\n",
    "    try:\n",
    "        p = tts_simple(text, voice=voice, engine=engine, out_path=out)\n",
    "        return {'engine':engine, 'out': p}\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# New: prompt_to_image bridge — accepts transcription, optional template, composes a flow and optionally runs it via COMFYUI API\n",
    "def prompt_to_image(prompt_text, model_key='', lora='', sampler='DDIM', steps=20, seed=-1, upscaler=False, action='compose', prompt_template=None):\n",
    "    try:\n",
    "        # apply template if provided\n",
    "        pt = prompt_template if prompt_template and prompt_template != 'None' else None\n",
    "        if pt:\n",
    "            try:\n",
    "                prompt = pt.replace('{prompt}', str(prompt_text))\n",
    "            except Exception:\n",
    "                prompt = str(prompt_text)\n",
    "        else:\n",
    "            prompt = str(prompt_text)\n",
    "        # Compose a flow JSON using existing composer helper\n",
    "        path, flow = compose_flow(prompt, model_key=model_key or None, sampler=sampler, steps=steps, seed=seed, lora=(lora or None), upscaler=(upscaler or None), format='comfyui')\n",
    "        result = {'flow_path': path, 'flow': flow, 'prompt': prompt}\n",
    "        # If action is 'run', attempt to POST to ComfyUI API if available\n",
    "        if action == 'run' and globals().get('USE_COMFYUI_API', False):\n",
    "            try:\n",
    "                import requests\n",
    "                base = globals().get('COMFYUI_API_BASE','http://127.0.0.1:8188').rstrip('/')\n",
    "                headers = globals().get('HEADERS', {})\n",
    "                # attempt a guarded POST to /api/graph or similar endpoint — many ComfyUI setups provide an endpoint to run flows\n",
    "                url = base + '/api/flow/run'\n",
    "                r = requests.post(url, json={'flow': flow}, headers=headers, timeout=60)\n",
    "                result['api_status'] = r.status_code\n",
    "                try:\n",
    "                    result['api_response'] = r.json()\n",
    "                except Exception:\n",
    "                    result['api_response'] = r.text[:500]\n",
    "            except Exception as e:\n",
    "                result['api_error'] = str(e)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "output.register_callback('notebook.voice_transcribe', voice_transcribe)\n",
    "output.register_callback('notebook.voice_synthesize', voice_synthesize)\n",
    "output.register_callback('notebook.prompt_to_image', prompt_to_image)\n",
    "print('Voice GUI registered (voice_transcribe, voice_synthesize, prompt_to_image)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage Templates UI + callbacks — persisted under DRIVE_ROOT/config/prompt_templates.json\n",
    "from IPython.display import display, HTML\n",
    "from google.colab import output\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Path for templates inside DRIVE_ROOT\n",
    "TEMPLATES_PATH = Path(globals().get('DRIVE_ROOT', '/content/drive/MyDrive/ComfyUI')) / 'config' / 'prompt_templates.json'\n",
    "\n",
    "def ensure_templates_file():\n",
    "    TEMPLATES_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if not TEMPLATES_PATH.exists():\n",
    "        defaults = [\n",
    "            {\"name\": \"Photorealistic\", \"template\": \"Photorealistic photo of {prompt}\"},\n",
    "            {\"name\": \"Cinematic\", \"template\": \"Cinematic poster of {prompt}\"},\n",
    "            {\"name\": \"Studio Portrait\", \"template\": \"Studio portrait of {prompt}\"},\n",
    "            {\"name\": \"Fantasy\", \"template\": \"Fantasy illustration of {prompt}\"},\n",
    "            {\"name\": \"Minimal\", \"template\": \"{prompt}\"}\n",
    "        ]\n",
    "        with open(TEMPLATES_PATH, 'w', encoding='utf-8') as f:\n",
    "            json.dump(defaults, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def get_prompt_templates():\n",
    "    try:\n",
    "        ensure_templates_file()\n",
    "        with open(TEMPLATES_PATH, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        return {'templates': data}\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "def save_prompt_templates(templates):\n",
    "    try:\n",
    "        ensure_templates_file()\n",
    "        # templates expected as a list of dicts\n",
    "        with open(TEMPLATES_PATH, 'w', encoding='utf-8') as f:\n",
    "            json.dump(templates, f, indent=2, ensure_ascii=False)\n",
    "        return {'ok': True}\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "output.register_callback('notebook.get_prompt_templates', get_prompt_templates)\n",
    "output.register_callback('notebook.save_prompt_templates', save_prompt_templates)\n",
    "\n",
    "# Launcher for the Manage Templates HTML UI (so the main Voice GUI can open it)\n",
    "def launch_manage_templates_ui():\n",
    "    # Build the UI HTML and register callbacks for save\n",
    "    html = r'''\n",
    "<div style=\"font-family: Roboto, Arial; padding:10px; border:1px solid #ddd; border-radius:6px; width:720px;background:#fff\">\n",
    "  <h3>Manage Prompt Templates</h3>\n",
    "  <div>\n",
    "    <table id=\"tpl-table\" style=\"width:100%; border-collapse:collapse;\">\n",
    "      <thead><tr><th style=\"text-align:left\">Name</th><th style=\"text-align:left\">Template</th><th></th></tr></thead>\n",
    "      <tbody></tbody>\n",
    "    </table>\n",
    "    <div style=\"margin-top:8px\">\n",
    "      <input id=\"new-name\" placeholder=\"Name\" style=\"width:20%\"/>\n",
    "      <input id=\"new-template\" placeholder=\"Template (use {prompt})\" style=\"width:60%\"/>\n",
    "      <button id=\"add-tpl\">Add</button>\n",
    "      <button id=\"save-tpl\" style=\"margin-left:12px\">Save to Drive</button>\n",
    "    </div>\n",
    "    <div id=\"msg\" style=\"margin-top:8px;color:green\"></div>\n",
    "  </div>\n",
    "</div>\n",
    "<script>\n",
    "  async function loadTemplates(){\n",
    "    const resp = await google.colab.kernel.invokeFunction('notebook.get_prompt_templates', [], {});\n",
    "    const data = resp.data['application/json'];\n",
    "    const tbody = document.querySelector('#tpl-table tbody');\n",
    "    tbody.innerHTML = '';\n",
    "    if (!data || !data.templates) return;\n",
    "    data.templates.forEach((t, idx) => {\n",
    "      const tr = document.createElement('tr');\n",
    "      tr.innerHTML = `<td><input class='nm' value='${(t.name||'').replace(/'/g,\"\\\\'\")}' style='width:95%'/></td><td><input class='tpl' value='${(t.template||'').replace(/'/g,\"\\\\'\")}' style='width:98%'/></td><td><button class='del'>Delete</button></td>`;\n",
    "      tbody.appendChild(tr);\n",
    "    });\n",
    "    Array.from(document.querySelectorAll('.del')).forEach((b,i)=>b.onclick = ()=>{tbody.removeChild(b.closest('tr'))});\n",
    "  }\n",
    "  \n",
    "  document.getElementById('add-tpl').onclick = () => {\n",
    "    const name = document.getElementById('new-name').value;\n",
    "    const tpl = document.getElementById('new-template').value;\n",
    "    if (!tpl) return alert('Template required');\n",
    "    const tbody = document.querySelector('#tpl-table tbody');\n",
    "    const tr = document.createElement('tr');\n",
    "    tr.innerHTML = `<td><input class='nm' value='${name.replace(/'/g,\"\\\\'\")}' style='width:95%'/></td><td><input class='tpl' value='${tpl.replace(/'/g,\"\\\\'\")}' style='width:98%'/></td><td><button class='del'>Delete</button></td>`;\n",
    "    tbody.appendChild(tr);\n",
    "    Array.from(document.querySelectorAll('.del')).forEach((b,i)=>b.onclick = ()=>{tbody.removeChild(b.closest('tr'))});\n",
    "    document.getElementById('new-name').value=''; document.getElementById('new-template').value='';\n",
    "  }\n",
    "\n",
    "  document.getElementById('save-tpl').onclick = async () => {\n",
    "    const rows = Array.from(document.querySelectorAll('#tpl-table tbody tr'));\n",
    "    const out = rows.map(r=>({name: r.querySelector('.nm').value, template: r.querySelector('.tpl').value}));\n",
    "    const resp = await google.colab.kernel.invokeFunction('notebook.save_prompt_templates', [out], {});\n",
    "    const d = resp.data['application/json'];\n",
    "    const msg = document.getElementById('msg');\n",
    "    if (d && d.ok) {\n",
    "      msg.innerText = 'Saved templates to Drive.';\n",
    "      // notify main UI to refresh\n",
    "      try{ await google.colab.kernel.invokeFunction('notebook.get_prompt_templates', [], {}); }catch(e){}\n",
    "    } else {\n",
    "      msg.style.color = 'red'; msg.innerText = 'Failed to save: ' + JSON.stringify(d);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  loadTemplates();\n",
    "</script>\n",
    "'''\n",
    "    display(HTML(html))\n",
    "    return {'ok': True}\n",
    "\n",
    "output.register_callback('notebook.launch_manage_templates_ui', launch_manage_templates_ui)\n",
    "print('Manage Templates callbacks registered (get_prompt_templates, save_prompt_templates, launch_manage_templates_ui)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Heavy-install runner (Tortoise, Bark, Alltalk) — RUN THIS TO PERFORM HEAVY INSTALLS\n",
    "# WARNING: This cell performs large downloads and installs. Run only in a GPU-enabled Colab runtime with sufficient disk space.\n",
    "RUN_HEAVY_INSTALL = False  # set to True and re-run cell to execute installs\n",
    "if not RUN_HEAVY_INSTALL:\n",
    "    print('RUN_HEAVY_INSTALL is False — set to True to execute heavy installs')\n",
    "else:\n",
    "    import subprocess, sys, os, shutil\n",
    "    def run(cmd, cwd=None):\n",
    "        print('>',' '.join(cmd))\n",
    "        p = subprocess.Popen(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        for line in p.stdout:\n",
    "            print(line, end='')\n",
    "        p.wait()\n",
    "        if p.returncode != 0:\n",
    "            raise RuntimeError(f'Command failed: {cmd}')\n",
    "    # 1) Tortoise TTS\n",
    "    if not os.path.exists('tortoise-tts'):\n",
    "        run(['git','clone','https://github.com/neonbjb/tortoise-tts.git'])\n",
    "    run([sys.executable,'-m','pip','install','-r','tortoise-tts/requirements.txt'])\n",
    "    # 2) Bark\n",
    "    run([sys.executable,'-m','pip','install','git+https://github.com/suno-ai/bark.git'])\n",
    "    # 3) Alltalk TTS (user requested branch alltalkbeta)\n",
    "    if not os.path.exists('alltalk_tts'):\n",
    "        run(['git','clone','--branch','alltalkbeta','https://github.com/erew123/alltalk_tts.git','alltalk_tts'])\n",
    "    # install requirements if present\n",
    "    req = 'alltalk_tts/requirements.txt'\n",
    "    if os.path.exists(req):\n",
    "        run([sys.executable,'-m','pip','install','-r',req])\n",
    "    # misc utilities\n",
    "    run([sys.executable,'-m','pip','install','pydub','soundfile','PyPDF2','ebooklib','requests','beautifulsoup4'])\n",
    "    print('Heavy installs completed. Follow repository READMEs for model downloads and runtime configuration.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download XTTS-v2 finetuned voice files from Hugging Face and create xtts.py runner\n",
    "from pathlib import Path\n",
    "import os, requests, sys\n",
    "DR = Path(globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')) / 'models' / 'xtts_v2'\n",
    "DR.mkdir(parents=True, exist_ok=True)\n",
    "files = ['model.pth','config.json','vocab.json','speakers_xtts.pth']\n",
    "base = 'https://huggingface.co/drewThomasson/fineTunedTTSModels/resolve/main/xtts-v2/eng/ScarlettJohansson/'\n",
    "token = os.environ.get('HUGGINGFACE_TOKEN','')\n",
    "headers = {'Authorization': f'Bearer {token}'} if token else {}\n",
    "for fn in files:\n",
    "    url = base + fn\n",
    "    outp = DR / fn\n",
    "    if outp.exists():\n",
    "        print(fn, 'already exists — skipping')\n",
    "        continue\n",
    "    print('Downloading', url, '->', outp)\n",
    "    r = requests.get(url, headers=headers, stream=True, timeout=60)\n",
    "    if r.status_code == 200:\n",
    "        with open(outp, 'wb') as fh:\n",
    "            for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                if chunk:\n",
    "                    fh.write(chunk)\n",
    "        print('Saved', outp)\n",
    "    else:\n",
    "        print('Failed to download', url, 'status', r.status_code)\n",
    "# create xtts.py runner\n",
    "script = r\"\"\"from TTS.api import TTS\n",
    "\n",
    "# Load XTTS v2 from local directory\n",
    "tts = TTS(model_path=\"xtts_v2/model.pth\", config_path=\"xtts_v2/config.json\", progress_bar=True)\n",
    "\n",
    "# Example synthesis\n",
    "tts.tts_to_file(\n",
    "    text=\"Hello world. This is a test from the finetuned XTTS v2 model. Replace with your text.\",\n",
    "    speaker_wav=[\"your_voice_sample.wav\"],\n",
    "    language=\"en\",\n",
    "    file_path=\"output.wav\"\n",
    ")\n",
    "\n",
    "print(\"Synthesis attempted — check output.wav\")\"\"\"\n",
    "runner_path = DR / 'xtts.py'\n",
    "with open(runner_path, 'w', encoding='utf-8') as fh:\n",
    "    fh.write(script)\n",
    "print('Created', runner_path)\n",
    "print('To run: cd', str(DR), 'then: python xtts.py (ensure TTS package is installed and you have a speaker WAV file)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Alltalk TTS quick-setup notes and test run (post-install)\n",
    "import os, shutil\n",
    "print('If you cloned the Alltalk repo via the heavy-installer, it should be in ./alltalk_tts')\n",
    "if os.path.exists('alltalk_tts'):\n",
    "    print('Found alltalk_tts folder — list top-level files:')\n",
    "    print(os.listdir('alltalk_tts')[:50])\n",
    "    print('\n",
    "Typical next steps:')\n",
    "    print('1) Inspect alltalk_tts/README.md for usage and model download links')\n",
    "    print('2) If the repo provides an examples/ or scripts/ folder, run example synth scripts after installing requirements')\n",
    "else:\n",
    "    print('alltalk_tts not present — run the heavy-install cell with RUN_HEAVY_INSTALL=True to clone and install it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bca5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run lightweight unit tests (composer + voice smoke)\n",
    "print('Running composer unit test (fast)')\n",
    "try:\n",
    "    path, flow = compose_flow('unit test prompt', model_key='test-model', sampler='DDIM', steps=5, seed=123, lora=None, upscaler=None, format='comfyui')\n",
    "    print('compose_flow produced path:', path)\n",
    "    assert isinstance(flow, dict) and 'nodes' in flow\n",
    "    print('Composer minimal check: PASS')\n",
    "except Exception as e:\n",
    "    print('Composer minimal check: FAIL', e)\n",
    "\n",
    "print('Running voice ingestion smoke test')\n",
    "from pathlib import Path\n",
    "p = Path('voice_test_tmp2.txt')\n",
    "p.write_text('Quick voice test for ingestion')\n",
    "try:\n",
    "    txt = read_text_source(str(p))\n",
    "    assert 'Quick voice test' in txt\n",
    "    print('Text ingestion smoke test: PASS')\n",
    "except Exception as e:\n",
    "    print('Text ingestion smoke test: FAIL', e)\n",
    "p.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Voice unit tests (quick smoke tests)\n",
    "\"\"\"\n",
    "Run small smoke tests: test text ingestion, TTS stub (no install), and STT stub (no install).\n",
    "These tests are light-weight and will not install heavy models.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "# Test read_text_source with a small temp file\n",
    "p = Path('voice_test_tmp.txt')\n",
    "p.write_text('Hello world. This is a quick test for the voice section.')\n",
    "try:\n",
    "    txt = read_text_source(str(p))\n",
    "    assert 'Hello world' in txt\n",
    "    print('Text ingestion: PASS')\n",
    "except Exception as e:\n",
    "    print('Text ingestion: FAIL', e)\n",
    "\n",
    "# test composer exists\n",
    "try:\n",
    "    assert callable(compose_flow)\n",
    "    print('compose_flow present: PASS')\n",
    "except Exception as e:\n",
    "    print('compose_flow present: FAIL', e)\n",
    "\n",
    "p.unlink()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c312420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Heavy-install helper (Tortoise & Bark) — safe instructions (do not auto-run)\n",
    "\"\"\"\n",
    "This cell provides safe, copy-paste install steps for Tortoise and Bark. It does not execute anything automatically.\n",
    "Run these commands manually in a Colab cell if you accept the heavy installs.\n",
    "\"\"\"\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "text = '''\n",
    "## Heavy install instructions (Tortoise TTS and Bark)\n",
    "\n",
    "NOTE: These are large installs. Use GPU runtime. Run commands manually in a new notebook cell.\n",
    "\n",
    "# Tortoise (recommended for expressive audiobooks)\n",
    "!git clone https://github.com/neonbjb/tortoise-tts.git\n",
    "%cd tortoise-tts\n",
    "!pip install -r requirements.txt\n",
    "# Download Tortoise models as instructed in tortoise README (models can be large >1GB)\n",
    "\n",
    "# Bark (zero-shot style, from Suno)\n",
    "!pip install git+https://github.com/suno-ai/bark.git\n",
    "# Bark will download models on first run; ensure sufficient disk space.\n",
    "\n",
    "# Additional helpful tools\n",
    "!pip install pydub soundfile PyPDF2 ebooklib requests beautifulsoup4\n",
    "\n",
    "Run these commands only if you have GPU runtime and sufficient disk space. '''\n",
    "\n",
    "print('Heavy-install instructions inserted. Copy the commands from the printed block and run them in a new cell when ready.')\n",
    "display(Markdown(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
